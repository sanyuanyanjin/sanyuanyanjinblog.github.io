<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>SanYuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="SanYuan">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="SanYuan">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SanYuan">
  
    <link rel="alternate" href="/atom.xml" title="SanYuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SanYuan</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-CentOS-6-x-Moodle" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-6-x-Moodle/" class="article-date">
  <time datetime="2016-12-15T03:03:19.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-6-x-Moodle/">CentOS 6.x Moodle</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>10.6.0.76<br>[root@sztzuchi opt]# tar -zxvf moodle-latest-28.tgz<br>[root@sztzuchi opt]# mv moodle /opt/lampp/htdocs/<br>[root@tzuchi opt]# chmod -R 777 /opt/lampp/<br>sz^215Tzuchi</p>
<p>[root@tzuchi ~]# vim /opt/lampp/htdocs/moodle/config.php<br>// $CFG-&gt;wwwroot = ‘<a href="http://tzuchi.elearning/moodle" target="_blank" rel="external">http://tzuchi.elearning/moodle</a>‘;<br>$CFG-&gt;wwwroot = ‘<a href="http://10.6.0.20/moodle" target="_blank" rel="external">http://10.6.0.20/moodle</a>‘;<br>$CFG-&gt;dataroot = ‘/opt/lampp/moodledata’;<br>$CFG-&gt;admin = ‘admin’;</p>
<p>$CFG-&gt;directorypermissions = 0777;</p>
<p>scp -r root@10.6.0.75:/backup/backup/moodle /opt<br>scp -r root@10.6.0.75:/backup/backup/moodledata /opt<br>scp -r root@10.6.0.75:/backup/backup/moodle.sql /opt</p>
<p>[root@sztzuchi opt]# cd /opt/lampp/htdocs/<br>[root@sztzuchi htdocs]# ls<br>applications.html dashboard img moodle xampp<br>bitnami.css favicon.ico index.php webalizer<br>[root@sztzuchi htdocs]# mkdir /backup<br>[root@sztzuchi htdocs]# mv moodle/ /backup/<br>[root@sztzuchi htdocs]# ls /backup/<br>moodle<br>[root@sztzuchi htdocs]# cd ..<br>[root@sztzuchi lampp]# ls<br>apache2 etc lib modules properties.ini var<br>bin htdocs libexec moodledata RELEASENOTES xampp<br>build icons licenses mysql sbin<br>cgi-bin img logs pear share<br>ctlscript.sh include man php temp<br>docs info manager-linux-x64.run phpmyadmin uninstall<br>error lampp manual proftpd uninstall.dat<br>[root@sztzuchi lampp]# mv moodledata/ /backup/<br>[root@sztzuchi lampp]# cd htdocs/<br>[root@sztzuchi htdocs]# mv /opt/moodle .<br>[root@sztzuchi htdocs]# cd ..<br>[root@sztzuchi lampp]# mv /opt/moodledata/ .<br>[root@sztzuchi lampp]# vim /opt/lampp/htdocs/moodle/config.php<br>$CFG-&gt;dbuser = ‘root’;<br>$CFG-&gt;dbpass = ‘sztzuchi’;<br>$CFG-&gt;wwwroot = ‘<a href="http://10.6.0.20/moodle" target="_blank" rel="external">http://10.6.0.20/moodle</a>‘;</p>
<p>[root@sztzuchi opt]# vim moodle.sql<br>:1,$s/10.6.0.76/10.6.0.20/g</p>
<p>/opt/lampp/bin/mysql -uroot -psztzuchi<br>drop database moodle;:<br>create database moodle;<br>SHOW DATABASES; /<em>这可以查看到所有的数据库名称</em>/<br>exit</p>
<p>/opt/lampp/bin/mysql -uroot -p moodle &lt; /opt/moodle.sql</p>
<p>[root@sztzuchi opt]# chmod 777 -R /opt/lampp/<br>/opt/lampp/bin/mysqldump -uroot -p’sztzuchi’ moodle&gt;/backup/moodle.sql 2&gt;/dev/null</p>
<p>10.6.0.75<br>[root@tzuchi ~]# /opt/lampp/bin/mysqladmin -u root password yanjin</p>
<p>[root@tzuchi ~]# vim /opt/lampp/htdocs/moodle/config.php<br>$CFG-&gt;dbuser = ‘root’;<br>$CFG-&gt;dbpass = ‘yanjin’;<br>$CFG-&gt;prefix = ‘mdl_’;</p>
<p>crontab -e<br><em>/5 </em> <em> </em> * /opt/lampp/bin/php /opt/lampp/htdocs/moodle/admin/cli/cron.php &gt;/dev/null</p>
<p>[root@tzuchi backup]# cat copy.sh</p>
<p>#!/bin/bash<br>cp -r /opt/lampp/htdocs/moodle/ /backup/backup<br>cp -r /opt/lampp/moodledata /backup/backup<br>/opt/lampp/bin/mysqldump -uroot -p’yanjin’ moodle&gt;/backup/backup/moodle.sql 2&gt;/dev/null</p>
<p>vim copy.sh</p>
<p>#!/bin/bash<br>cp -r /opt/lampp/htdocs/moodle/ /home/backup<br>cp -r /opt/lampp/moodledata/ /home/backup<br>/opt/lampp/bin/mysqldump -uroot -p’sztzuchi’ moodle&gt;/home/backup/moodle.sql 2&gt;/dev/null</p>
<p>[root@tzuchi backup]# vim elearningbackup.sh</p>
<p>#!/bin/bash<br>host=”10.6.0.73”<br>id=”ctzapc”<br>pw=”htw001c9”<br>basedir=”/home/“<br>remotedir=”/backup_Elearning”<br>tar -cjPf $basedir/elearning.$(date +%Y-%m-%d).tar.bz2 /home/backup/<br>backupfile=elearning.$(date +%Y-%m-%d).tar.bz2<br>rmfile=elearning.$(date +%Y-%m-%d –date -7day).tar.bz2<br>ftp -n “$host” &lt;&lt;EOF<br>user $id $pw<br>binary<br>cd $remotedir<br>lcd $basedir<br>put $backupfile<br>bye<br>EOF<br>rm -f $basedir/$rmfile<br>[root@tzuchi backup]#</p>
<p>crontab -e<br>00 03 <em> </em> <em> sh /root/copy.sh<br>00 06 </em> <em> </em> sh /root/elearningbackup.sh</p>
<p>[root@sztzuchi ~]# vim /opt/lampp/phpmyadmin/config.inc.php<br>$cfg[‘Servers’][$i][‘auth_type’] = ‘cookie’;<br>$cfg[‘Servers’][$i][‘user’] = ‘root’;<br>$cfg[‘Servers’][$i][‘password’] = ‘yanjin’;</p>
<p>[root@sztzuchi ~]# vim /opt/lampp/phpmyadmin/libraries/config.default.php<br>$cfg[‘CheckConfigurationPermissions’] = true;<br>$cfg[‘CheckConfigurationPermissions’] = false;</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-6-x-Moodle/" data-id="ciwps8im8000850cy7ctuxbz8" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-6-x-SmokePing" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-6-x-SmokePing/" class="article-date">
  <time datetime="2016-12-15T02:57:25.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-6-x-SmokePing/">CentOS 6.x SmokePing</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>SmokePing 是一款开源的网络质量监控的工具。<br>CentOS<br>o    准备<br>o    安装源<br>o    安装依赖<br>o    安装SmokePing<br>o    配置SmokePing<br>§  创建 cache、data、var 数据目录<br>§  创建日志<br>§  授权<br>§  修改配置文件<br>§  修改 Apache 配置<br>§  无密码<br>§  设密码<br>§  自动启动 SmokePing、Apache 服务<br>§  添加监控列表<br>§  Apache 开端口<br>§  树状目录权限报错<br>配 IP 地址。<br>vim  /etc/sysconfig/network-scripts/ifcfg-ethx<br>然后把 SELinux 禁用：<br>vim /etc/selinux/config<br>SELINUX = disabled<br>安装源<br>rpm -Uvh <a href="http://apt.sw.be/redhat/el6/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm" target="_blank" rel="external">http://apt.sw.be/redhat/el6/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm</a><br>rpm -Uvh <a href="http://apt.sw.be/redhat/el6/en/i386/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.i686.rpm" target="_blank" rel="external">http://apt.sw.be/redhat/el6/en/i386/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.i686.rpm</a><br>根据自己的版本安装，5/7 的自己把 el 后的数字改掉。<br>安装依赖<br>yum -y install perl perl-Net-Telnet perl-Net-DNS perl-LDAP perl-libwww-perl perl-RadiusPerl perl-IO-Socket-SSL perl-Socket6 perl-CGI-SpeedyCGI perl-FCGI perl-CGI-SpeedCGI perl-Time-HiRes perl-ExtUtils-MakeMaker perl-RRD-Simple rrdtool rrdtool-perl curl fping echoping  httpd httpd-devel gcc make  wget libxml2-devel libpng-devel glib pango pango-devel freetype freetype-devel fontconfig cairo cairo-devel libart_lgpl libart_lgpl-devel mod_fastcgi<br>安装SmokePing<br>wget <a href="http://oss.oetiker.ch/SmokePing/pub/SmokePing-2.6.11.tar.gz" target="_blank" rel="external">http://oss.oetiker.ch/SmokePing/pub/SmokePing-2.6.11.tar.gz</a><br>tar zxvf SmokePing-2.6.11.tar.gz<br>cd SmokePing-2.6.11<br>./configure –prefix=/usr/local/SmokePing<br>./setup/build-perl-modules.sh /usr/local/SmokePing/thirdparty<br>./configure –prefix=/usr/local/SmokePing<br>/usr/bin/gmake install<br>注意下载下来的压缩包是安装文件，不要改名后直接扔目录，会有冲突。<br>其中 ./setup/build-perl-modules.sh /usr/local/SmokePing/thirdparty 这一条是个大坑，会从 cpan.org 下载文件安装，但是 cpan.org 国内并不稳定，建议使用网易的镜像，教程在这，但我按教程来没效果，你也可以爬梯子或者多试两遍。<br>配置 SmokePing<br>创建 cache、data、var 数据目录<br>cd /usr/local/SmokePing<br>mkdir cache data var<br>创建日志<br>touch /var/log/SmokePing.log<br>授权<br>chown apache:apache cache data var<br>chown apache:apache /var/log/SmokePing.log<br>修改配置文件<br>cd /usr/local/SmokePing/htdocs/<br>mv SmokePing.fcgi.dist SmokePing.fcgi<br>cd /usr/local/SmokePing/etc<br>mv config.dist config<br>vimm config<br>cgiurl = <a href="http://some.url/SmokePing.cgi" target="_blank" rel="external">http://some.url/SmokePing.cgi</a><br>…<br>step = 300<br>ping = 5<br>将 some.url 改成你的 IP 或者是域名。<br>这里 step、ping 意思是每 300 秒时间，ping 5 次。<br>配完保存给密码文件权限：<br>chmod 600 /usr/local/SmokePing/etc/SmokePing_secrets.dist<br>修改 Apache 配置<br>无密码<br>vim /etc/httpd/conf/httpd.conf<br>Alias /cache “/usr/local/SmokePing/cache/“<br>Alias /cropper “/usr/local/SmokePing/htdocs/cropper/“<br>Alias /SmokePing “/usr/local/SmokePing/htdocs/SmokePing.fcgi”</p>
<p><directory "="" usr="" local="" smokeping"=""><br>AllowOverride None<br>Options All<br>AddHandler cgi-script .fcgi .cgi<br>Order allow,deny<br>Allow from all<br>DirectoryIndex SmokePing.fcgi<br></directory><br>设密码<br>如果要让登录 SmokePing 时需要验证用户，则 Apache 添加内容为<br>vim /etc/httpd/conf/httpd.conf<br>Alias /cache “/usr/local/SmokePing/cache/“<br>Alias /cropper “/usr/local/SmokePing/htdocs/cropper/“<br>Alias /SmokePing “/usr/local/SmokePing/htdocs/SmokePing.fcgi”</p>
<p><directory "="" usr="" local="" smokeping"=""><br>AllowOverride None<br>Options All<br>AddHandler cgi-script .fcgi .cgi<br>AllowOverride AuthConfig<br>Order allow,deny<br>Allow from all<br>AuthName “SmokePing”<br>AuthType Basic<br>AuthUserFile /usr/local/SmokePing/htdocs/htpasswd<br>Require valid-user<br>DirectoryIndex SmokePing.fcgi<br></directory><br>然后命令行输入，点回车，会要你输密码：<br>htpasswd -c /usr/local/SmokePing/htdocs/htpasswd admin<br>自动启动 SmokePing、Apache 服务<br>echo “/usr/local/SmokePing/bin/SmokePing –logfile=/var/log/SmokePing.log 2&gt;&amp;1 &amp;” &gt;&gt; /etc/rc.local<br>chkconfig httpd on<br>添加监控列表<br>vimm /usr/local/SmokePing/etc/config<br>Apache 开端口<br>iptables -I INPUT -p TCP –dport 80 -j ACCEPT<br>/etc/init.d/iptables save<br>重启设备后进入 <a href="http://127.0.0.1/SmokePing" target="_blank" rel="external">http://127.0.0.1/SmokePing</a> 应该就能看到图表了<br><a href="http://192.168.57.135/SmokePing" target="_blank" rel="external">http://192.168.57.135/SmokePing</a><br>树状目录权限报错<br>如果点击列表看不到图，提示什么权限不足，要按照报错新建对应目录，然后给权限<br>mkdir /usr/local/SmokePing/data/IDC //IDC 根据实际情况修改<br>chmod 655 /usr/local/SmokePing/data/IDC</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-6-x-SmokePing/" data-id="ciwps8imb000b50cy8w3oif1s" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-1-刷固件" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/1-刷固件/" class="article-date">
  <time datetime="2016-12-15T02:54:01.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/1-刷固件/">1.刷固件</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/1-刷固件/" data-id="ciwps8ilk000050cyq1v7bhvt" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Linaro-12-11-Hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/Linaro-12-11-Hadoop/" class="article-date">
  <time datetime="2016-12-15T02:52:38.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/Linaro-12-11-Hadoop/">Linaro 12.11 Hadoop</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1.刷固件</p>
<p>出厂的Cubieboard是Android系统，需要Linux系统安装Hadoop，到此网址下载：</p>
<p><a href="http://dl.cubieboard.org/software/a20-cubietruck/lubuntu/" target="_blank" rel="external">http://dl.cubieboard.org/software/a20-cubietruck/lubuntu/</a></p>
<p>①．使用PhoenixSuit一键刷机，并选择 lubuntu 系统镜像</p>
<p>②．电脑一方先接上 USB 线，将Cubieboard电源，电池全部拔除，按住Cubieboard FEL 按钮（此按钮在 RESET 按钮的边上）不放，此时将另外一端的 mini USB 和 Cubieboard 连接，这时候会弹出一个强制升级的提示对话框，然后就可以松开 FEL 按钮了。</p>
<p>③．提示对话框上选 Yes 开始刷系统。</p>
<p>④．刷完系统之后，拿掉和电脑连接的 USB 线，然后接上电源和网线。</p>
<p>2.系统配置</p>
<p>①．使用 linaro 用户登录上去，设置 root 的密码：</p>
<p>$ sudo passwd root</p>
<p>②．cubieboard nand 重新分区扩容</p>
<p>安装分区工具 nand-part (sunxi-tools)</p>
<p>#apt-get install git</p>
<p>#apt-get install build-essential</p>
<p>#apt-get install pkg-config libusb-1.0</p>
<p>#git clone <a href="https://github.com/linux-sunxi/sunxi-tools.git" target="_blank" rel="external">https://github.com/linux-sunxi/sunxi-tools.git</a></p>
<p>#cd sunxi-tools</p>
<p>#make all</p>
<p>现在我们查看一下 nandflash：</p>
<h1 id="ls-dev-nand-l"><a href="#ls-dev-nand-l" class="headerlink" title="ls /dev/nand* -l"></a>ls /dev/nand* -l</h1><p>brw-rw—- 1 root disk 93, 0 Jan 1 2010 /dev/nand</p>
<p>brw-rw—- 1 root disk 93, 1 Jan 1 2010 /dev/nanda</p>
<p>brw-rw—- 1 root disk 93, 2 Jan 1 2010 /dev/nandb</p>
<p>brw-rw—- 1 root disk 93, 3 Jan 1 2010 /dev/nandc</p>
<p>这里的 nand 表示了整个 nandflash，nanda、nandb、nandc 则为其 3 个分区，其中：</p>
<p>nanda 中包含 bootlogo、script.bin、uEnv.txt 等</p>
<p>nandb 中为 rootfs</p>
<p>nandc 有 5G 左右的空间，我觉得把它合并到 nandb 似乎是一个好的想法。敲击命令 nand-part 大概能看到如下信息（只列出主要部分）：</p>
<p>partition 1: class = DISK, name = bootloader, partition start = 32768, partition size = 131072 user_type=0</p>
<p>partition 2: class = DISK, name = rootfs, partition start = 163840, partition size = 4194304 user_type=0</p>
<p>partition 3: class = DISK, name = UDISK, partition start = 4358144, partition size = 10584064 user_type=0</p>
<p>我们可以看到各个分区的大小，这样我们就可以重新规划一下：</p>
<h1 id="nand-part-f-a20-dev-nand-32768-‘bootloader-131072’-‘rootfs-14778368’"><a href="#nand-part-f-a20-dev-nand-32768-‘bootloader-131072’-‘rootfs-14778368’" class="headerlink" title="nand-part -f a20 /dev/nand 32768 ‘bootloader 131072’ ‘rootfs 14778368’"></a>nand-part -f a20 /dev/nand 32768 ‘bootloader 131072’ ‘rootfs 14778368’</h1><p>此命令执行后输出：</p>
<p>ready to write new partition tables:</p>
<p>mbr: version 0x00000200, magic softw411</p>
<p>2 partitions</p>
<p>partition 1: class = DISK, name = bootloader, partition start = 32768, partition size = 131072 user_type=0</p>
<p>partition 2: class = DISK, name = rootfs, partition start = 163840, partition size = 14778368 user_type=0</p>
<p>我们看到 bootloader（nanda）的大小未发生变化，rootfs（nandb）和 UDISK（nandc）合并了（4194304 + 10584064 = 14778368）。然后，我们重启一下系统，再敲击命令来完成 nandb 的扩展：</p>
<h1 id="resize2fs-dev-nandb"><a href="#resize2fs-dev-nandb" class="headerlink" title="resize2fs /dev/nandb"></a>resize2fs /dev/nandb</h1><p>需要说明的是，这个重分区的过程不会破坏任何数据的。</p>
<p>处理完 nand 就可以开始处理我的 HDD 硬盘了。使用命令 fdisk 来查看 HDD 硬盘是否存在，执行 fdisk -l</p>
<p>分区fdisk /dev/sda</p>
<p>格式化mkfs.ext4 /dev/sda1</p>
<p>挂载mount /dev/sda1 /data</p>
<p>配置启动时挂载vim /etc/fstab</p>
<p>/dev/sda1 /data ext4 defaults 1 2</p>
<p>允许root用户SSH远程登录</p>
<p>安装OpenSSH server：</p>
<ol>
<li>使用apt命令安装openssh server</li>
</ol>
<p>$ sudo apt-get install openssh-server</p>
<ol>
<li>可以对 openssh server进行配置</li>
</ol>
<p>$ sudo vi /etc/ssh/sshd_config</p>
<p>找到PermitRootLogin no一行，改为PermitRootLogin yes</p>
<ol>
<li>重启 openssh server</li>
</ol>
<p>$ sudo service ssh restart</p>
<ol>
<li>客户端如果是ubuntu的话，则已经安装好ssh client,可以用下面的命令连接远程服务器。</li>
</ol>
<p>$ ssh xxx.xxx.xxx.xxx</p>
<p>如果是windows系统的话，可以使用SSH Secure Shell等ssh软件进行远程连接。</p>
<p>3.安装Hadoop</p>
<p>Java</p>
<p>vim ~/.bashrc</p>
<p>export JAVA_HOME=/usr/lib/java/jdk1.7.0_71</p>
<p>export JRE_HOME=${JAVA_HOME}/jre</p>
<p>export CLASS_PATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib</p>
<p>export PATH=${JAVA_HOME}/bin:$PATH</p>
<p>export PATH=${JAVA_HOME}/bin:/usr/local/hadoop/hadoop-2.2.0/bin:$PATH</p>
<p>source ~/.bashrc</p>
<p>hadoop-env.sh</p>
<p>export JAVA_HOME=/usr/lib/java/jdk1.7.0_71</p>
<p>export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}/lib/native</p>
<p>export HADOOP_OPTS=”-Djava.library.path=$HADOOP_PREFIX/lib”</p>
<p>/etc/hostname</p>
<p>/etc/hosts</p>
<p>ssh-keygen -t rsa -P “”</p>
<p>root@m1:/home/hadoop# scp -r root@m2:/root/.ssh/id_rsa.pub ~/.ssh/m2.pub</p>
<p>root@m1:/home/hadoop# scp -r root@s1:/root/.ssh/id_rsa.pub ~/.ssh/s1.pub</p>
<p>root@m1:/home/hadoop# scp -r root@s2:/root/.ssh/id_rsa.pub ~/.ssh/s2.pub</p>
<p>root@m1:/home/hadoop# cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p>
<p>root@m1:/home/hadoop# cat ~/.ssh/m2.pub &gt;&gt; ~/.ssh/authorized_keys</p>
<p>root@m1:/home/hadoop# cat ~/.ssh/s1.pub &gt;&gt; ~/.ssh/authorized_keys</p>
<p>root@m1:/home/hadoop# cat ~/.ssh/s2.pub &gt;&gt; ~/.ssh/authorized_keys</p>
<p>root@m1:/home/hadoop# scp -r ~/.ssh/authorized_keys root@m2:~/.ssh/</p>
<p>root@m1:/home/hadoop# scp -r ~/.ssh/authorized_keys root@s1:~/.ssh/</p>
<p>root@m1:/home/hadoop# scp -r ~/.ssh/authorized_keys root@s2:~/.ssh/</p>
<p>core-site.xml</p>
  <property><br><br>  <name>fs.defaultFS</name><br><br>  <value>hdfs://master:9000/</value><br><br>  <description>The name of the default file system</description><br><br>  </property>

  <property><br><br>  <name>hadoop.tmp.dir</name><br><br>  <value>/usr/local/hadoop/hadoop-2.2.0/tmp</value><br><br>  <description>A base for other temporary directories</description><br><br>  </property>


<p>hdfs-site.xml</p>
  <property><br><br>  <name>dfs.replication</name><br><br>  <value>2</value><br><br>  </property>

  <property><br><br>  <name>dfs.namenode.name.dir</name><br><br>  <value>/usr/local/hadoop/hadoop-2.2.0/dfs/name</value><br><br>  </property>

  <property><br><br>  <name>dfs.datanode.data.dir</name><br><br>  <value>/usr/local/hadoop/hadoop-2.2.0/dfs/data</value><br><br>  </property>



<p>mapred-site.xml</p>
  <property><br><br>  <name>mapreduce.framework.name</name><br><br>  <value>yarn</value><br><br>  </property>



<p>yarn-site.xml</p>
  <property><br><br>  <name>yarn.resourcemanager.hostname</name><br><br>  <value>master</value><br><br>  </property>

  <property><br><br>  <name>yarn.nodemanager.aux-services</name><br><br>  <value>mapreduce_shuffle</value><br><br>  </property>


<p>slaves</p>
<p>slave001</p>
<p>slave002</p>
<p>scp -r hadoop-2.2.0/ hadoop@slave001:/usr/local/hadoop/</p>
<p>scp -r hadoop-2.2.0/ hadoop@slave002:/usr/local/hadoop/</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ scp -r /usr/lib/java/jdk1.7.0_71/ hadoop@slave001:/usr/lib/java/</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ scp -r /usr/lib/java/jdk1.7.0_71/ hadoop@slave002:/usr/lib/java/</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop namenode -format</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ ./start-dfs.sh</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ jps</p>
<p>3197 NameNode</p>
<p>3387 SecondaryNameNode</p>
<p>4236 Jps</p>
<p>hadoop@slave001:/usr/lib/java$ jps</p>
<p>6129 DataNode</p>
<p>6199 Jps</p>
<p>hadoop@slave002:/usr/lib/java$ jps</p>
<p>5229 DataNode</p>
<p>5301 Jps</p>
<p><a href="http://10.6.4.226:50070/dfshealth.jsp" target="_blank" rel="external">http://10.6.4.226:50070/dfshealth.jsp</a></p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ ./start-yarn.sh</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ jps</p>
<p>3197 NameNode</p>
<p>3387 SecondaryNameNode</p>
<p>4557 Jps</p>
<p>4310 ResourceManager</p>
<p>hadoop@slave001:/usr/lib/java$ jps</p>
<p>6129 DataNode</p>
<p>6377 NodeManager</p>
<p>6492 Jps</p>
<p>hadoop@slave002:/usr/lib/java$ jps</p>
<p>5229 DataNode</p>
<p>5478 NodeManager</p>
<p>5592 Jps</p>
<p><a href="http://10.6.4.226:8088/cluster" target="_blank" rel="external">http://10.6.4.226:8088/cluster</a></p>
<p><a href="http://10.6.4.227:8042/node" target="_blank" rel="external">http://10.6.4.227:8042/node</a></p>
<p><a href="http://10.6.4.228:8042/node" target="_blank" rel="external">http://10.6.4.228:8042/node</a></p>
<p>/usr/local/hadoop/hadoop-2.2.0/sbin# ./mr-jobhistory-daemon.sh start historyserver</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/sbin$ jps</p>
<p>3197 NameNode</p>
<p>3387 SecondaryNameNode</p>
<p>4609 JobHistoryServer</p>
<p>4310 ResourceManager</p>
<p>4665 Jps</p>
<p><a href="http://10.6.4.226:19888/jobhistory" target="_blank" rel="external">http://10.6.4.226:19888/jobhistory</a></p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop fs -mkdir -p /data/wordcount</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop fs -mkdir -p /output/</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop fs -put ../etc/hadoop/*.xml /data/wordcount/</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop fs -ls /data/wordcount</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop jar ../share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /data/wordcount /output/wordcount</p>
<p>hadoop@master:/usr/local/hadoop/hadoop-2.2.0/bin$ hadoop fs -cat /output/wordcount/part-r-00000 |head</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/Linaro-12-11-Hadoop/" data-id="ciwps8imo000l50cyl7hvyhyd" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-6-x-CDH" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-6-x-CDH/" class="article-date">
  <time datetime="2016-12-15T02:50:28.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-6-x-CDH/">CentOS 6.x CDH</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="http://www.jianshu.com/p/57179e03795f" target="_blank" rel="external">http://www.jianshu.com/p/57179e03795f</a><br>namenode reboot<br>/opt/cm-5.1.3/etc/init.d/cloudera-scm-server stop<br>/opt/cm-5.1.3/etc/init.d/cloudera-scm-agent stop</p>
<p>/opt/cm-5.1.3/etc/init.d/cloudera-scm-server start<br>/opt/cm-5.1.3/etc/init.d/cloudera-scm-agent start<br>hadoop-fuse-dfs dfs://n10:8022 /mnt/hdfs/<br>umount -l /mnt/hdfs</p>
<p>数据同步脚本<br>crontab -e<br>00 06 <em> </em> * python /root/syncdir.py /home/smbhdfs/zy/ /mnt/hdfs/zy/ 2&gt; /dev/null &gt; /dev/null<br>python /root/syncdir.py /home/smbhdfs/jinyan/ /mnt/hdfs/jinyan/<br>python /root/syncdir.py /home/smbhdfs/wqf/ /mnt/hdfs/wqf/</p>
<p>关闭防火墙：<br>service iptables stop （临时关闭）<br>chkconfig iptables off （重启后生效）</p>
<p>关闭SELINUX<br>vim /etc/selinux/config<br>SELINUX=disabled</p>
<p>最小化安装<br>yum -y install openssh-server<br>vim /etc/ssh/sshd_config<br>PermitRootLogin yes<br>service sshd restart<br>yum install openssh-clients -y</p>
<p>yum groupinstall ‘X Window System’ -y<br>yum -y install bind-utils<br>yum -y install cyrus-sasl-gssapi<br>yum -y install cyrus-sasl-plain<br>yum -y install fuse*<br>yum -y install portmap<br>yum -y install redhat-lsb</p>
<p>yum groupinstall ‘Desktop Platform Development’ -y</p>
<p>mkdir -p /root/.ssh/</p>
<p>cat /etc/sysconfig/network-scripts/ifcfg-eth0<br>DEVICE=”eth0”<br>BOOTPROTO=none<br>NM_CONTROLLED=”yes”<br>ONBOOT=”yes”<br>TYPE=”Ethernet”<br>UUID=”735675de-800d-47c3-bcbb-f61abbd19cf2”<br>IPADDR=10.6.0.211<br>PREFIX=24<br>GATEWAY=10.6.0.128<br>DNS1=61.177.7.1<br>DOMAIN=223.5.5.5<br>DEFROUTE=yes<br>IPV4_FAILURE_FATAL=yes<br>IPV6INIT=no<br>NAME=”System eth0”<br>HWADDR=DE:A9:01:8A:18:34<br>LAST_CONNECT=1438477375</p>
<p>vim /etc/sysconfig/network<br>NETWORKING=yes<br>HOSTNAME=n4</p>
<p><a href="http://www.cloudera.com/content/www/zh-CN/documentation/enterprise/5-3-x/topics/cm_sg_s1_install_cm_cdh.html" target="_blank" rel="external">http://www.cloudera.com/content/www/zh-CN/documentation/enterprise/5-3-x/topics/cm_sg_s1_install_cm_cdh.html</a></p>
<p>vim /etc/hosts<br>10.6.0.211 n1<br>10.6.0.212 n2<br>10.6.0.213 n3<br>10.6.0.214 n4<br>10.6.0.215 n5<br>10.6.0.216 n6<br>10.6.0.217 n7<br>10.6.0.218 n8<br>10.6.0.219 n9<br>10.6.0.220 n10<br>10.6.0.221 n11</p>
<p>ssh-keygen -t rsa<br>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<br>chmod 600 ~/.ssh/authorized_keys</p>
<p>scp ~/.ssh/authorized_keys root@n2:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n3:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n4:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n5:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n6:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n7:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n8:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n9:~/.ssh/<br>scp ~/.ssh/authorized_keys root@n1:~/.ssh/</p>
<p>yum install ntp -y<br>chkconfig ntpd on<br>chkconfig –list ntpd<br>vim /etc/ntp.conf<br>19行<br>server n10<br>ntpdate -u n10<br>service ntpd start</p>
<p>rpm -qa | grep java</p>
<p>rpm -e –nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64<br>rpm -e –nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64<br>rpm -e –nodeps tzdata-java-2013g-1.el6.noarch</p>
<p>rpm -ivh oracle-j2sdk1.7-1.7.0+update55-2.x86_64.rpm<br>rpm -ivh jdk-6u31-linux-amd64.rpm<br>mkdir /usr/java/latest/<br>cp -a /usr/java/jdk1.6.0_31/* /usr/java/latest/<br>echo “JAVA_HOME=/usr/java/latest/“ &gt;&gt; /etc/environment<br>java -version</p>
<p>rpm -ivh cloudera-manager-daemons-5.1.3-1.cm513.p0.155.el6.x86_64.rpm<br>rpm -ivh cloudera-manager-agent-5.1.3-1.cm513.p0.155.el6.x86_64.rpm</p>
<p>echo 0 &gt; /proc/sys/vm/swappiness</p>
<p>向群集添加新主机</p>
<p>[root@n5 ~]#<br>/etc/rc.d/init.d/cloudera-scm-agent stop</p>
<p>yum install mysql-server -y<br>chkconfig mysqld on<br>service mysqld start<br>mysqladmin -u root password yanjin<br>mysql -uroot -pyanjin<br>create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;<br>grant all privileges on <em>.</em> to ‘root’@’n10’ identified by ‘yanjin’ with grant option;<br>flush privileges;</p>
<p>yum install ntp -y<br>chkconfig ntpd on<br>chkconfig –list ntpd<br>ntpdate -u 202.120.2.101<br>n10<br>vim /etc/ntp.conf<br>server 202.120.2.101 prefer<br>service ntpd start<br>ntpstat</p>
<p>n2-4<br>vim /etc/ntp.conf<br>server n10<br>ntpdate -u n1<br>service ntpd start<br><a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html" target="_blank" rel="external">http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/introduction.html</a><br><a href="http://archive.cloudera.com/cm5/cm/5/cloudera-manager-el5-cm5.3.6_x86_64.tar.gz" target="_blank" rel="external">http://archive.cloudera.com/cm5/cm/5/cloudera-manager-el5-cm5.3.6_x86_64.tar.gz</a><br><a href="http://archive.cloudera.com/cdh5/parcels/latest/" target="_blank" rel="external">http://archive.cloudera.com/cdh5/parcels/latest/</a><br><a href="http://archive.cloudera.com/cdh5/parcels/latest/CDH-5.3.6-1.cdh5.3.6.p0.11-el6.parcel" target="_blank" rel="external">http://archive.cloudera.com/cdh5/parcels/latest/CDH-5.3.6-1.cdh5.3.6.p0.11-el6.parcel</a><br><a href="http://archive.cloudera.com/cdh5/parcels/latest/CDH-5.3.6-1.cdh5.3.6.p0.11-el6.parcel.sha1" target="_blank" rel="external">http://archive.cloudera.com/cdh5/parcels/latest/CDH-5.3.6-1.cdh5.3.6.p0.11-el6.parcel.sha1</a><br><a href="http://archive.cloudera.com/cdh5/parcels/latest/manifest.json" target="_blank" rel="external">http://archive.cloudera.com/cdh5/parcels/latest/manifest.json</a><br><a href="http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.3.6/RPMS/x86_64/" target="_blank" rel="external">http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.3.6/RPMS/x86_64/</a></p>
<p><a href="http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.1.3/RPMS/x86_64/" target="_blank" rel="external">http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.1.3/RPMS/x86_64/</a><br>cd /opt/<br>mv /home/cloudera-manager-el6-cm5.1.3_x86_64.tar.gz .<br>tar -zxvf cloudera-manager-el6-cm5.1.3_x86_64.tar.gz<br>ls<br>cd cm-5.1.3/share/cmf/lib/<br>cp /home/mysql-connector-java-5.1.33-bin.jar .<br>ls<br>ls mysql-connector-java-5.1.33-bin.jar<br>cd /opt/<br>useradd –system –home=/opt/cm-5.1.3/run/cloudera-scm-server/ –no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm<br>/opt/cm-5.1.3/share/cmf/schema/scm_prepare_database.sh mysql cm -hlocalhost -uroot -pyanjin –scm-host localhost scm scm scm<br>vim cm-5.1.3/etc/cloudera-scm-agent/config.ini<br>server_host=n10<br>scp -r /opt/cm-5.1.3/ root@n2:/opt/<br>scp -r /opt/cm-5.1.3/ root@n3:/opt/<br>scp -r /opt/cm-5.1.3/ root@n4:/opt/</p>
<p>[root@n1 opt]# cd cloudera/parcel-repo/<br>mv /home/CDH-5.1.3-1.cdh5.1.3.p0.12-el6.parcel .<br>mv /home/CDH-5.1.3-1.cdh5.1.3.p0.12-el6.parcel.sha .<br>mv /home/manifest.json .<br>ls<br>/opt/cm-5.1.3/etc/init.d/cloudera-scm-server start<br>/opt/cm-5.1.3/etc/init.d/cloudera-scm-agent start<br>echo 0 &gt; /proc/sys/vm/swappiness</p>
<p>安装服务前<br>cp /opt/cm-5.1.3/share/cmf/lib/mysql-connector-java-5.1.33-bin.jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hive/lib/</p>
<p>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 10 100</p>
<p>hadoop fs -mkdir -p /data/wordcount<br>sudo -u hadoop fs -mkdir -p /data/wordcount<br>sudo -u hdfs hadoop fs -mkdir -p /data/wordcount<br>sudo -u hdfs hadoop fs -mkdir -p /output/<br>sudo -u hdfs hadoop fs -put /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop/etc/hadoop/*.xml /data/wordcount/<br>sudo -u hdfs hadoop fs -ls /data/wordcount/<br>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /data/wordcount /output/wordcount<br>sudo -u hdfs hadoop fs -cat /output/wordcount/part-r-00000 |head</p>
<p>mkdir -p /mnt/hdfs<br>hadoop-fuse-dfs dfs://n10:8022 /mnt/hdfs/<br>df -h /mnt/hdfs/</p>
<p>yum -y install vsftpd<br>vim /etc/vsftpd/vsftpd.conf<br>useradd -g ftp -d /mnt/hdfs/ -M ftphdfs<br>passwd ftphdfs<br>sztzuchi<br>service vsftpd restart</p>
<p>ftpuser<br>ftpuser<br>[root@n10 smbhdfs]# useradd -g ftp -d /home/smbhdfs/ -M ftpsmb<br>[root@n10 smbhdfs]# passwd ftpsmb</p>
<p>10.6.0.24<br>chmod -R 777 /home/</p>
<p>[root@n1 nfs]# useradd -g ftp -d /home/nfs/ -M ftpnfs<br>[root@n1 nfs]# passwd ftpnfs<br>更改用户 ftpnfs 的密码 。<br>新的 密码：<br>重新输入新的 密码：<br>passwd： 所有的身份验证令牌已经成功更新。<br>[root@n1 nfs]# service vsftpd restart<br>关闭 vsftpd：[确定]<br>为 vsftpd 启动 vsftpd：[确定]</p>
<p>yum install samba samba-client samba-swat -y<br>vim /etc/samba/smb.conf<br>[hdfs]<br>  comment = The hdfs<br>  path = /mnt/hdfs/<br>  browseable = yes<br>  writable = yes<br>useradd smbhdfs<br>smbpasswd -a smbhdfs<br>sztzuchi<br>service smbd restart<br>/etc/init.d/smb start<br>/etc/init.d/nmb start<br>service smb status<br>chkconfig –level 35 smb on</p>
<p>[root@n1 ~]# cp /opt/cm-5.1.3/share/cmf/lib/mysql-connector-java-5.1.33-bin.jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/sqoop/lib/<br>[root@n1 ~]# sqoop list-databases –connect jdbc:mysql://localhost:3306/ –username root –password yanjin</p>
<p>基准测试<br>TestDFSIO基准测试HDFS<br>[root@n1 ~]# su hdfs<br>[hdfs@n1 root]$ cd<br>[hdfs@n1 ~]$ pwd<br>/var/lib/hadoop-hdfs<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -write -nrFiles 10 -fileSize 1000<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -read -nrFiles 10 -fileSize 1000<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -clean</p>
<p>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -write -nrFiles 10 -fileSize 1000<br>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -read -nrFiles 10 -fileSize 1000<br>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-test-2.3.0-mr1-cdh5.1.3.jar TestDFSIO -clean</p>
<p>用sort排序测试MapReduce<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar randomwriter random-data<br> sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar randomwriter random-data</p>
<p>TeraSort 基准测试实验<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar teragen 1000000 terasort/1000000-input<br>hadoop fs -ls terasort/1000000-input<br>hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar terasort terasort/1000000-input terasort/1000000-output<br>hadoop fs -ls terasort/1000000-output<br>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar teragen 1000000 terasort/1000000-input<br>sudo -u hdfs hadoop fs -ls terasort/1000000-input<br>sudo -u hdfs hadoop jar /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/lib/hadoop-0.20-mapreduce/hadoop-examples-2.3.0-mr1-cdh5.1.3.jar terasort terasort/1000000-input terasort/1000000-output<br>sudo -u hdfs hadoop fs -ls terasort/1000000-output</p>
<p>[hdfs@n1 ~]$ hdfs dfsadmin<br>Usage: java DFSAdmin<br>Note: Administrative commands can only be run as the HDFS superuser.<br>  [-report]<br>  [-safemode enter | leave | get | wait]</p>
<p>manual ha<br>[hdfs@n1 ~]$ hdfs haadmin -getServiceState namenode121<br>standby<br>You have new mail in /var/spool/mail/root<br>[hdfs@n1 ~]$ hdfs haadmin -getServiceState namenode84<br>active</p>
<p>[hdfs@n1 ~]$ hdfs haadmin<br>Usage: DFSHAAdmin [-ns <nameserviceid>]<br>  [-transitionToActive <serviceid>]<br>  [-transitionToStandby <serviceid>]<br>  [-failover [–forcefence] [–forceactive] <serviceid> <serviceid>]<br>  [-getServiceState <serviceid>]<br>  [-checkHealth <serviceid>]<br>  [-help <command>]</serviceid></serviceid></serviceid></serviceid></serviceid></serviceid></nameserviceid></p>
<p>[hdfs@n2 ~]$ hdfs zkfc -formatZK<br>[hdfs@n2 ~]$ hdfs haadmin -failover –forceactive namenode84 namenode121<br>[root@n2 ~]# /opt/cloudera/parcels/CDH-5.1.3-1.cdh5.1.3.p0.12/etc/rc.d/init.d/hadoop-hdfs-namenode restart</p>
<p>[hdfs@n1 ~]$ hdfs zkfc -formatZK<br>[hdfs@n1 ~]$ hdfs haadmin -failover –forceactive namenode121 namenode84</p>
<p>AUTO HA<br>vim /etc/hadoop/conf.cloudera.hdfs/core-site.xml<br>  <property><br>  <name>ha.zookeeper.quorum</name><br>  <value>n1:2181,n2:2181,n3:2181</value><br>  </property><br>hdfs zkfc -formatZK</p>
<p>增加根目录空间</p>
<p>创建一个GPT label啊<br>安装的时候按ctrl+alt+f2进入另外一个console，输入parted<br>然后mklable gpt /dev/sda<br>然后你可以输入print /dev/sda确认lable正确<br>然后quit<br>再按ctrl+alt+f6 返回分区上一步继续安装</p>
<p>fuser -m /home 终止占用进程</p>
<p>umount /home/<br>vgdisplay<br>lvreduce -L 10G /dev/mapper/vg_nx-lv_home<br>vgdisplay<br>lvextend -L +937409 /dev/mapper/vg_nx-lv_root<br>resize2fs -p /dev/mapper/vg_nx-lv_root<br>df -h<br>vgdisplay<br>lvextend -L +703056 /dev/mapper/vg_nx-lv_root<br>resize2fs -p /dev/mapper/vg_nx-lv_root</p>
<p>rpm -qa | grep lvm<br>yum install -y lvm2</p>
<p>df -h<br>e2fsck -f /dev/mapper/vg_n9-lv_home<br>resize2fs -p /dev/mapper/vg_n9-lv_home 10G<br>mount /home/<br>df -h</p>
<p>hadoop archive -archiveName test.har -p /data /data/har<br>hadoop fs -ls har:///data/har/test.har</p>
<p>[root@n1 nfs]# time mv 018/ /mnt/hdfs/tmp/ 2&gt;/dev/null<br>[root@n1 home]# time cp -a /mnt/hdfs/tmp/018/ .<br>[root@n1 tmp]# hadoop archive -archiveName 018.har -p /tmp/018/ /tmp/har<br>hadoop fs -ls har:////tmp/har/018.har</p>
<p>[root@n1 nfs]# time cp -a /mnt/hdfs/tmp/har/018.har/ .</p>
<p>Lock on /dfs/dn/in_use.lock acquired by nodename<br>[root@n10 cloudera]# cat /dfs/nn/current/VERSION</p>
<p>#Sun Nov 22 10:19:27 CST 2015<br>namespaceID=39325997<br>clusterID=cluster42<br>cTime=0<br>storageType=NAME_NODE<br>blockpoolID=BP-2074941685-10.6.0.220-1448154708456<br>layoutVersion=-55</p>
<p>[root@n3 ~]# vim /dfs/dn/current/VERSION</p>
<p> #Sun Nov 22 08:14:02 CST 2015<br>storageID=DS-465f3d32-b20c-416a-905a-86f78bbbd7bd<br>clusterID=cluster42<br>cTime=0<br>datanodeUuid=9a02f390-0b95-4cde-bedf-b14949296adc<br>storageType=DATA_NODE<br>layoutVersion=-55</p>
<p>[root@n5 ~]# netstat -tunlp | grep :9000<br>tcp 0 0 10.6.0.215:9000 0.0.0.0:<em> LISTEN 1914/python<br>[root@n5 ~]# netstat -tunlp | grep :9001<br>tcp 0 0 127.0.0.1:9001 0.0.0.0:</em> LISTEN 2117/python<br>[root@n5 ~]# kill -9 1914<br>[root@n5 ~]# kill -9 2117<br>[root@n5 ~]# netstat -tunlp | grep :9001<br>[root@n5 ~]# netstat -tunlp | grep :9000<br>[root@n5 ~]# netstat -tunlp | grep :7180</p>
<p>spark-shell<br>val file = sc.textFile(“hdfs://n10:8020/hadoop/Input/WordCount/“)<br>val counts = file.flatMap(line =&gt; line.split(“ “)).map(word =&gt; (word, 1)).reduceByKey(<em> + </em>)<br>counts.saveAsTextFile(“hdfs://n10:8020/output”)</p>
<p>val file = sc.textFile(“hdfs://n10:8020/hadoop/Input/WordCount/test1.txt”)</p>
<p>val counts = file.flatMap(line =&gt; line.split(“ “)).map(word =&gt; (word, 1)).reduceByKey(<em> + </em>)</p>
<p>counts.saveAsTextFile(“hdfs://n10:8020/output1”)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-6-x-CDH/" data-id="ciwps8ilx000450cy3j5t6v32" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-7-x-GIT" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-7-x-GIT/" class="article-date">
  <time datetime="2016-12-15T02:49:00.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-7-x-GIT/">CentOS 7.x GIT</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>yum install git -y<br>git -version<br>git –version<br>git config –global user.name sanyuanyanjin<br>git config –global user.email sanyuanyanjin@gmail.com<br>mkdir git_exercise<br>cd git_exercise/<br>git init<br>touch hello.txt<br>git status<br>git add hello.txt<br>git add -A //提交目录下全部<br>git status<br>git commit -m “Initial commit.”</p>
<p>下载远程仓库并合并本地文件<br>[root@CentOS7 ~]# git clone <a href="https://github.com/sanyuanyanjin/gitskills.git" target="_blank" rel="external">https://github.com/sanyuanyanjin/gitskills.git</a><br>正克隆到 ‘gitskills’…<br>remote: Counting objects: 3, done.<br>remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0<br>Unpacking objects: 100% (3/3), done.<br>[root@CentOS7 ~]# cd gitskills/<br>[root@CentOS7 gitskills]#touch hello.txt<br>[root@CentOS7 gitskills]# git status<br>[root@CentOS7 gitskills]# git add -A<br>[root@CentOS7 gitskills]# git status</p>
<h1 id="位于分支-master"><a href="#位于分支-master" class="headerlink" title="位于分支 master"></a>位于分支 master</h1><h1 id="要提交的变更："><a href="#要提交的变更：" class="headerlink" title="要提交的变更："></a>要提交的变更：</h1><h1 id="（使用-“git-reset-HEAD-…”-撤出暂存区）"><a href="#（使用-“git-reset-HEAD-…”-撤出暂存区）" class="headerlink" title="（使用 “git reset HEAD …” 撤出暂存区）"></a>（使用 “git reset HEAD <file>…” 撤出暂存区）</file></h1><p>#</p>
<h1 id="新文件：-hello-txt"><a href="#新文件：-hello-txt" class="headerlink" title="新文件：    hello.txt"></a>新文件：    hello.txt</h1><p>#<br>[root@CentOS7 gitskills]# git commit -m “hello1.”<br>[master 3f0f79c] hello1.<br> 1 file changed, 0 insertions(+), 0 deletions(-)<br> create mode 100644 hello.txt<br>[root@CentOS7 gitskills]# git push origin master<br>Username for ‘<a href="https://github.com" target="_blank" rel="external">https://github.com</a>‘: sanyuanyanjin<br>Password for ‘<a href="https://sanyuanyanjin@github.com" target="_blank" rel="external">https://sanyuanyanjin@github.com</a>‘:<br>Counting objects: 4, done.<br>Delta compression using up to 4 threads.<br>Compressing objects: 100% (2/2), done.<br>Writing objects: 100% (3/3), 274 bytes | 0 bytes/s, done.<br>Total 3 (delta 0), reused 0 (delta 0)<br>To <a href="https://github.com/sanyuanyanjin/gitskills.git" target="_blank" rel="external">https://github.com/sanyuanyanjin/gitskills.git</a><br>   afffd47..3f0f79c  master -&gt; master<br>[root@CentOS7 gitskills]# </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-7-x-GIT/" data-id="ciwps8imd000d50cyaa1eu9va" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-7-x-NFS" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-7-x-NFS/" class="article-date">
  <time datetime="2016-12-15T00:30:48.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-7-x-NFS/">CentOS 7.x NFS</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>CentOS 7引入了全新的 systemctl 服务管理，设置和管理服务略有不同。以下是为了提供Mac OS X客户端访问Linux NFS输出的卷实现数据备份的记录，NFS服务器设置见本文，Mac OS X挂载Linux的NFS输出见Mac OS X 挂载Linux卷（NFS）。<br>设置Linux服务端<br>将移动硬盘挂载到 /data 目录<br>mount /dev/sdb1 /data<br>在Paralles Desktop虚拟机运行的是CentOS 7操作系统，使用以下命令安装 NFS 支持<br>yum install nfs-utils nfs-utils-lib<br>设置nfs相关服务在操作系统启动时启动<br>systemctl enable rpcbind<br>systemctl enable nfs-server<br>systemctl enable nfs-lock<br>systemctl enable nfs-idmap<br>启动nfs服务<br>systemctl start rpcbind<br>systemctl start nfs-server<br>systemctl start nfs-lock<br>systemctl start nfs-idmap<br>服务器端设置NFS卷输出，即编辑 /etc/exports 添加：<br>/data    10.211.55.0/24(rw,sync,no_root_squash,no_subtree_check)<br>/data – 共享目录<br>10.211.55.0/24 – 允许访问NFS的客户端IP地址段<br>rw – 允许对共享目录进行读写<br>sync – 实时同步共享目录<br>no_root_squash – 允许root访问<br>no_all_squash - 允许用户授权<br>no_subtree_check - 如果卷的一部分被输出，从客户端发出请求文件的一个常规的调用子目录检查验证卷的相应部分。如果是整个卷输出，禁止这个检查可以加速传输。<br>no_subtree_check - If only part of a volume is exported, a routine called subtree checking verifies that a file that is requested from the client is in the appropriate part of the volume. If the entire volume is exported, disabling this check will speed up transfers. Setting Up an NFS Server<br>NFS客户端挂载<br>Linux挂载NFS的客户端非常简单的命令，先创建挂载目录，然后用 -t nfs 参数挂载就可以了<br>mount -t nfs  10.211.55.9:/data /data<br>如果要设置客户端启动时候就挂载NFS，可以配置 /etc/fstab 添加以下内容<br>10.211.55.9:/data    /data  nfs auto,rw,vers=3,hard,intr,tcp,rsize=32768,wsize=32768      0   0<br>然后在客户端简单使用以下命令就可以挂载<br>mount /data<br>通过防火墙挂载NFS服务<br>在生产环境，可能会因为安全需求在NFS服务器和客户端之间部署防火墙。此时，NFS客户端挂载的时候会有如下输出报错<br>mount.nfs: Connection timed out<br>参考 Running NFS Behind a Firewall 设置防火墙允许访问NFS服务器的服务端口，注意，需要配置NFS服务使用固定端口。<br>MOUNTD_PORT=port</p>
<h1 id="Controls-which-TCP-and-UDP-port-mountd-rpc-mountd-uses"><a href="#Controls-which-TCP-and-UDP-port-mountd-rpc-mountd-uses" class="headerlink" title="Controls which TCP and UDP port mountd (rpc.mountd) uses."></a>Controls which TCP and UDP port mountd (rpc.mountd) uses.</h1><p>STATD_PORT=port</p>
<h1 id="Controls-which-TCP-and-UDP-port-status-rpc-statd-uses"><a href="#Controls-which-TCP-and-UDP-port-status-rpc-statd-uses" class="headerlink" title="Controls which TCP and UDP port status (rpc.statd) uses."></a>Controls which TCP and UDP port status (rpc.statd) uses.</h1><p>LOCKD_TCPPORT=port</p>
<h1 id="Controls-which-TCP-port-nlockmgr-lockd-uses"><a href="#Controls-which-TCP-port-nlockmgr-lockd-uses" class="headerlink" title="Controls which TCP port nlockmgr (lockd) uses."></a>Controls which TCP port nlockmgr (lockd) uses.</h1><p>LOCKD_UDPPORT=port</p>
<h1 id="Controls-which-UDP-port-nlockmgr-lockd-uses"><a href="#Controls-which-UDP-port-nlockmgr-lockd-uses" class="headerlink" title="Controls which UDP port nlockmgr (lockd) uses."></a>Controls which UDP port nlockmgr (lockd) uses.</h1><p>编辑 /etc/sysconfig/nfs 配置文件</p>
<h1 id="TCP-port-rpc-lockd-should-listen-on"><a href="#TCP-port-rpc-lockd-should-listen-on" class="headerlink" title="TCP port rpc.lockd should listen on."></a>TCP port rpc.lockd should listen on.</h1><p>LOCKD_TCPPORT=32803</p>
<h1 id="UDP-port-rpc-lockd-should-listen-on"><a href="#UDP-port-rpc-lockd-should-listen-on" class="headerlink" title="UDP port rpc.lockd should listen on."></a>UDP port rpc.lockd should listen on.</h1><p>LOCKD_UDPPORT=32769<br>MOUNTD_PORT=892<br>STATD_PORT=662<br>可以在Linux NFS服务器上执行以下命令获得NFS端口信息<br>rpcinfo -p<br>需要允许以下端口<br>NFS的TCP和UDP端口2049<br>rpcbind/sunrpc的TCP和UDP端口111<br>设置 MOUNTD_PORT 的TCP和UDP端口<br>设置 STATD_PORT 的TCP和UDP端口<br>设置 LOCKD_TCPPORT 的TCP端口<br>设置 LOCKD_UDPPORT 的UDP端口<br>program vers proto   port  service<br>100000    4   tcp    111  portmapper<br>100000    3   tcp    111  portmapper<br>100000    2   tcp    111  portmapper<br>100000    4   udp    111  portmapper<br>100000    3   udp    111  portmapper<br>100000    2   udp    111  portmapper<br>100024    1   udp  54305  status<br>100024    1   tcp  55604  status<br>100005    1   udp  20048  mountd<br>100005    1   tcp  20048  mountd<br>100005    2   udp  20048  mountd<br>100005    2   tcp  20048  mountd<br>100005    3   udp  20048  mountd<br>100005    3   tcp  20048  mountd<br>100003    3   tcp   2049  nfs<br>100003    4   tcp   2049  nfs<br>100227    3   tcp   2049  nfs_acl<br>100003    3   udp   2049  nfs<br>100003    4   udp   2049  nfs<br>100227    3   udp   2049  nfs_acl<br>100021    1   udp  32769  nlockmgr<br>100021    3   udp  32769  nlockmgr<br>100021    4   udp  32769  nlockmgr<br>100021    1   tcp  32803  nlockmgr<br>100021    3   tcp  32803  nlockmgr<br>100021    4   tcp  32803  nlockmgr<br>100011    1   udp    875  rquotad<br>100011    2   udp    875  rquotad<br>100011    1   tcp    875  rquotad<br>100011    2   tcp    875  rquotad<br>在 Linux NFS 服务器上使用以下命令开启iptables防火墙允许访问以上端口<br>firewall-cmd –permanent –add-port=2049/tcp<br>firewall-cmd –permanent –add-port=2049/udp<br>firewall-cmd –permanent –add-port=111/tcp<br>firewall-cmd –permanent –add-port=111/udp<br>firewall-cmd –permanent –add-port=892/tcp<br>firewall-cmd –permanent –add-port=892/udp<br>firewall-cmd –permanent –add-port=662/tcp<br>firewall-cmd –permanent –add-port=662/udp<br>firewall-cmd –permanent –add-port=32803/tcp<br>firewall-cmd –permanent –add-port=32769/udp<br>在 Linux NFS 服务器上使用以下命令重新加载防火墙规则<br>firewall-cmd –reload</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-7-x-NFS/" data-id="ciwps8imh000g50cy8i3e6u0a" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-7-x-HA-Cluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-7-x-HA-Cluster/" class="article-date">
  <time datetime="2016-12-15T00:27:53.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-7-x-HA-Cluster/">CentOS 7.x HA Cluster</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文以两台机器实现双集热备高可用集群，主机名node1的IP为192.168.122.168，主机名node2的IP为192.168.122.169。<br>一、安装集群软件<br>必须软件pcs，pacemaker，corosync，fence-agents-all，如果需要配置相关服务，也要安装对应的软件<br>二、配置防火墙<br>1、禁止防火墙和selinux</p>
<p>#systemctldisablefirewalld</p>
<p>#systemctlstopfirewalld<br>修改/etc/sysconfig/selinux确保SELINUX=disabled，然后执行setenforce0或者reboot服务器以生效<br>2、设置防火墙规则</p>
<p>#firewall-cmd–permanent–add-service=high-availability</p>
<p>#firewall-cmd–add-service=high-availability<br>三、各节点之间主机名互相解析<br>分别修改2台主机名分别为node1和node2，在centos7中直接修改/etc/hostname加入本机主机名和主机表，然后重启网络服务即可。</p>
<p>#vi/etc/hostname<br>node1</p>
<p>#systemctlrestartnetwork.service</p>
<p>#hostname<br>node1<br>配置2台主机的主机表，在/etc/hosts中加入<br>192.168.122.168node1<br>192.168.122.169node2<br>四、各节点之间时间同步<br>在node1和node2分别进行时间同步，可以使用ntp实现。<br>[root@node1~]#ntpdate172.16.0.1//172.16.0.1为时间服务器<br>五、各节点之间配置ssh的无密码密钥访问。<br>下面的操作需要在各个节点上操作。</p>
<p>#ssh-keygen-trsa-P‘’#这个生成一个密码为空的公钥和一个密钥，把公钥复制到对方节点上即可</p>
<p>#ssh-copy-id-i/root/.ssh/id_rsa.pubroot@node2#对方主机名用登录用户名<br>两台主机都要互相可以通信，所以两台主机都得互相生成密钥和复制公钥，相互的节点上的hosts文件是都要解析对方的主机名，192.168.122.168node1192.168.122.169node2</p>
<p>#sshnode2‘date’;date#测试一下是否已经互信<br>六、通过pacemaker来管理高可用集群<br>1、创建集群用户<br>为了有利于各节点之间通信和配置集群，在每个节点上创建一个hacluster的用户，各个节点上的密码必须是同一个。</p>
<p>#passwdhacluster<br>Changingpasswordforuserhacluster.<br>Newpassword:<br>Retypenewpassword:<br>passwd:allauthenticationtokensupdatedsuccessfully.<br>2、设置pcsd开机自启动</p>
<p>#systemctlstartpcsd.service</p>
<p>#systemctlenablepcsd.service<br>3、集群各节点之间进行认证</p>
<p>#pcsclusterauthnode1node2Username:haclusterPassword:node1:Authorizednode2:Authorized<br>4、创建并启动集群<br>[root@z1~]#pcsclustersetup–start–namemy_clusternode1node2<br>node1:Succeeded<br>node1:StartingCluster…<br>node2:Succeeded<br>node2:StartingCluster…<br>5、设置集群自启动</p>
<p>#pcsclusterenable–all<br>6、查看集群状态信息<br>[root@z1~]#pcsclusterstatus<br>7、设置fence设备<br>这个可以参考<redhatenterpriselinux7highavailabilityadd-onreference><br>corosync默认启用了stonith，而当前集群并没有相应的stonith设备，因此此默认配置目前尚不可用，这可以通过如下命令验证：</redhatenterpriselinux7highavailabilityadd-onreference></p>
<p>#crm_verify-L-V<br>可以通过如下面命令禁用stonith：</p>
<p>#pcspropertysetstonith-enabled=false（默认是true）<br>8、配置存储<br>高可用集群既可以使用本地磁盘来构建纯软件的镜像型集群系统，也可以使用专门的共享磁盘装置来构建大规模的共享磁盘型集群系统，充分满足客户的不同需求。<br>共享磁盘主要有iscsi或DBRD。本文并没有使用共享磁盘。<br>9、配置浮点IP<br>不管集群服务在哪运行,我们要一个固定的地址来提供服务。在这里我选择192.168.122.101作为浮动IP,给它取一个好记的名字ClusterIP并且告诉集群每30秒检查它一次。</p>
<p>#pcsresourcecreateVIPocf:heartbeat:IPaddr2ip=192.168.122.170cidr_netmask=24opmonitorinterval=30s</p>
<p>#pcsupdateVIPopmonitorinterval=15s<br>10、配置apache服务<br>在node1和node2上安装httpd，确认httpd开机被禁用</p>
<p>#systemctlstatushttpd.service；<br>配置httpd监控页面（貌似不配置也可以通过systemd监控），分别在node1和node2上执行</p>
<p>#cat&gt;/etc/httpd/conf.d/status.conf<a href="&#x6d;&#x61;&#x69;&#108;&#116;&#111;&#58;&#x3c;&#69;&#x4f;&#70;&#xa;&#x53;&#x65;&#x74;&#72;&#x61;&#110;&#100;&#x6c;&#101;&#114;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#x2d;&#115;&#116;&#97;&#116;&#117;&#115;&#10;&#79;&#114;&#100;&#x65;&#114;&#100;&#x65;&#x6e;&#121;&#44;&#x61;&#108;&#108;&#111;&#119;&#xa;&#68;&#x65;&#x6e;&#121;&#x66;&#114;&#x6f;&#x6d;&#97;&#x6c;&#108;&#xa;&#65;&#108;&#108;&#111;&#x77;&#x66;&#x72;&#111;&#109;&#108;&#111;&#99;&#x61;&#108;&#104;&#x6f;&#x73;&#116;&#xa;&#69;&#79;&#x46;&#10;&#x9996;&#20808;&#x6211;&#x4eec;&#x4e3a;&#65;&#x70;&#97;&#x63;&#x68;&#101;&#21019;&#24314;&#19968;&#x4e2a;&#20027;&#39029;&#12290;&#x5728;&#99;&#x65;&#110;&#x74;&#x6f;&#x73;&#x4e0a;&#38754;&#x9ed8;&#35748;&#x7684;&#65;&#x70;&#97;&#99;&#104;&#101;&#x64;&#x6f;&#99;&#114;&#111;&#x6f;&#116;&#x662f;&#47;&#x76;&#x61;&#114;&#x2f;&#119;&#x77;&#119;&#47;&#x68;&#x74;&#109;&#x6c;&#44;&#25152;&#20197;&#25105;&#20204;&#22312;&#x8fd9;&#x4e2a;&#x76ee;&#x5f55;&#x4e0b;&#x9762;&#x5efa;&#31435;&#x4e00;&#x4e2a;&#20027;&#x9875;&#12290;&#xa;&#110;&#111;&#x64;&#101;&#x31;&#33410;&#28857;&#20462;&#x6539;&#x5982;&#19979;&#65306;&#10;&#x5b;&#x72;&#111;&#x6f;&#116;&#64;&#110;&#x6f;&#x64;&#101;&#x31;&#x7e;&#93;&#x23;&#99;&#x61;&#116;&#x3c;&#60;&#45;&#69;&#x4e;&#68;">&#x3c;&#69;&#x4f;&#70;&#xa;&#x53;&#x65;&#x74;&#72;&#x61;&#110;&#100;&#x6c;&#101;&#114;&#115;&#101;&#114;&#x76;&#x65;&#x72;&#x2d;&#115;&#116;&#97;&#116;&#117;&#115;&#10;&#79;&#114;&#100;&#x65;&#114;&#100;&#x65;&#x6e;&#121;&#44;&#x61;&#108;&#108;&#111;&#119;&#xa;&#68;&#x65;&#x6e;&#121;&#x66;&#114;&#x6f;&#x6d;&#97;&#x6c;&#108;&#xa;&#65;&#108;&#108;&#111;&#x77;&#x66;&#x72;&#111;&#109;&#108;&#111;&#99;&#x61;&#108;&#104;&#x6f;&#x73;&#116;&#xa;&#69;&#79;&#x46;&#10;&#x9996;&#20808;&#x6211;&#x4eec;&#x4e3a;&#65;&#x70;&#97;&#x63;&#x68;&#101;&#21019;&#24314;&#19968;&#x4e2a;&#20027;&#39029;&#12290;&#x5728;&#99;&#x65;&#110;&#x74;&#x6f;&#x73;&#x4e0a;&#38754;&#x9ed8;&#35748;&#x7684;&#65;&#x70;&#97;&#99;&#104;&#101;&#x64;&#x6f;&#99;&#114;&#111;&#x6f;&#116;&#x662f;&#47;&#x76;&#x61;&#114;&#x2f;&#119;&#x77;&#119;&#47;&#x68;&#x74;&#109;&#x6c;&#44;&#25152;&#20197;&#25105;&#20204;&#22312;&#x8fd9;&#x4e2a;&#x76ee;&#x5f55;&#x4e0b;&#x9762;&#x5efa;&#31435;&#x4e00;&#x4e2a;&#20027;&#x9875;&#12290;&#xa;&#110;&#111;&#x64;&#101;&#x31;&#33410;&#28857;&#20462;&#x6539;&#x5982;&#19979;&#65306;&#10;&#x5b;&#x72;&#111;&#x6f;&#116;&#64;&#110;&#x6f;&#x64;&#101;&#x31;&#x7e;&#93;&#x23;&#99;&#x61;&#116;&#x3c;&#60;&#45;&#69;&#x4e;&#68;</a>/var/www/html/index.html</p>
<p><html></html></p>
<p><body>Hellonode1</body><br><br>END<br>node2节点修改如下：<br>[root@node2~]#cat&lt;&lt;-END&gt;/var/www/html/index.html</p>
<p><html></html></p>
<p><body>Hellonode2</body><br><br>END<br>下面语句是将httpd作为资源添加到集群中：</p>
<p>#pcsresourcecreateWEBapacheconfigfile=”/etc/httpd/conf/httpd.conf”statusurl=”<a href="http://127.0.0.1/server-status" target="_blank" rel="external">http://127.0.0.1/server-status</a>“<br>11、创建group<br>将VIP和WEBresource捆绑到这个group中，使之作为一个整体在集群中切换。（此配置为可选)</p>
<p>#pcsresourcegroupaddMyGroupVIP</p>
<p>#pcsresourcegroupaddMyGroupWEB<br>12、配置服务启动顺序<br>以避免出现资源冲突，语法：(pcsresourcegroupadd的时候也可以根据加的顺序依次启动，此配置为可选)</p>
<p>#pcsconstraintorder[action]then[action]</p>
<p>#pcsconstraintorderstartVIPthenstartWEB<br>13、指定优先的Location（此配置为可选)<br>Pacemaker并不要求你机器的硬件配置是相同的,可能某些机器比另外的机器配置要好。这种状况下我们会希望设置:当某个节点可用时,资源就要跑在上面之类的规则。为了达到这个效果我们创建location约束。同样的,我们给他取一个描述性的名字(prefer-node1),指明我们想在上面跑WEB这个服务,多想在上面跑(我们现在指定分值为50,但是在双节点的集群状态下,任何大于0的值都可以达到想要的效果),以及目标节点的名字:</p>
<p>#pcsconstraintlocationWEBprefersnode1=50</p>
<p>#pcsconstraintlocationWEBprefersnode2=45<br>这里指定分值越大，代表越想在对应的节点上运行。<br>14、资源粘性（此配置为可选)<br>一些环境中会要求尽量避免资源在节点之间迁移。迁移资源通常意味着一段时间内无法提供服务，某些复杂的服务，比如Oracle数据库，这个时间可能会很长。<br>为了达到这个效果，Pacemaker有一个叫做“资源粘性值”的概念，它能够控制一个服务(资源)有多想呆在它正在运行的节点上。<br>Pacemaker为了达到最优分布各个资源的目的，默认设置这个值为0。我们可以为每个资源定义不同的粘性值，但一般来说，更改默认粘性值就够了。资源粘性表示资源是否倾向于留在当前节点，如果为正整数，表示倾向，负数则会离开，-inf表示负无穷，inf表示正无穷。</p>
<p>#pcsresourcedefaultsresource-stickiness=100<br>常用命令汇总：<br>查看集群状态：#pcsstatus<br>查看集群当前配置：#pcsconfig<br>开机后集群自启动：#pcsclusterenable–all<br>启动集群：#pcsclusterstart–all<br>查看集群资源状态：#pcsresourceshow<br>验证集群配置情况：#crm_verify-L-V<br>测试资源配置：#pcsresourcedebug-startresource<br>设置节点为备用状态：#pcsclusterstandbynode1</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-7-x-HA-Cluster/" data-id="ciwps8imf000f50cy1yejkhlv" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-6-x-Puppet" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-6-x-Puppet/" class="article-date">
  <time datetime="2016-12-15T00:26:00.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/CentOS-6-x-Puppet/">CentOS 6.x Puppet</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、Puppet基础原理:<br>Puppet是一款使用GPLV2X协议授权的开源管理配置工具，用ruby语言开发，既可以通过客户端—服务器的方式运行，也可以独立运行。puppet可以为系统管理员提供方便，快捷的系统自动化管理。<br>二、puppet工作流程</p>
<ol>
<li>客户端 puppet-client 向 puppet-master 发起认证请求，或使用带签名的证书。</li>
<li>puppet-master 告诉 puppet-client 是合法的。</li>
<li>puppet-client 调用 facter， Facter 探测出主机的一些变量， 例如主机名、 内存大小、 IP 地址等，puppet-client 将这些信息通过 SSL 连接发送到服务器端。</li>
<li>puppet-master 服务器端检测客户端的主机名，然后找到 manifest 对应的 node 配置，并对该部分内容进行解析。facter 送过来的信息可以作为变量处理，node 牵涉到的代码才解析，其他没牵涉的代码不解析。解析分为几个阶段，首先是语法检查，如果语法错误就报错；如果语法没错，就继续解析，解析的结果生成一个中间的“伪代码”(catelog)，然后把伪代码发给客户端。</li>
<li>puppet-client 端接收到“伪代码”，并且执行。</li>
<li>puppet-client 端在执行时判断有没有 file 文件，如果有，则向 fileserver 发起请求。</li>
<li>puppet-client 端判断有没有配置 report，如果已配置，则把执行结果发送给服务器。</li>
<li>puppet-server 端把 puppet-client 端的执行结果写入日志，并发送给报告系统。<br>三、puppet安装<br>1、直接通过yum安装老系统自带版本。<br>yum install puppet -y<br>2、安装最新版本<br>sudo rpm -ivh <a href="https://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm" target="_blank" rel="external">https://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm</a><br>2.1、安装puppet-server。<br>sudo puppet resource package puppet-server ensure=latest<br>2.2、安装agent<br>sudo puppet resource package puppet ensure=latest<br>四、puppet资源管理<br>Puppet中的资源是puppet工具的核心，它是通过puppet管理配置系统的最小单位。<br>..<br>1、查看资源类型<br>puppet describe -l<br>2、查看资源摘要<br>puppet describe -s <resource_name><br>3、查看资源详细用法<br>puppet describe <resource_name><br>4、资源的基本格式<br>资源名 { ‘标题’:<pre><code>属性1 =&gt; &apos;值&apos;,
属性2 =&gt; &apos;值&apos;,
</code></pre>}<br>`<blockquote>
<p>以安装httpd为例<br>``` cpp<br>package { ‘httpd’:</p>
<pre><code>ensure =&gt; &apos;present&apos;,
provider =&gt; &apos;rpm&apos;,
</code></pre><p>}<br>puppet常用资源:file,filebucket,host,group,package,service,exec,cron,notify 等。<br>..<br>5、资源公有属性:<br>before :指明资源要在某个资源之前运行<br>require：指明某个资源要在某个资源之后运行。<br>notify: 主动通知其他资源，本资源的状态<br>subscibe ：被动通知，当它检测到资源状态发生改变的时候，主动更新所在资源状态。<br>还可以使用<br>-&gt; 表示资源前后关系<br>~&gt; 表示资源之间的通知<br>五、puppet语言<br>1)、puppet变量：<br>1、名称之前必须以$开头，赋值用=，支持追加赋值+=；<br>2、变量名称有两种格式，简短名称，FQN($scope::variable)。</p>
<pre><code>$webserver = &quot;httpd&quot;
package {&quot;httpd&quot;:
       ensure =&gt; &quot;present&quot;,
       name =&gt; $webserver
} 
</code></pre><p>3、作用域:top &gt; node &gt; local 作用域越小，优先级越高<br>2)、数据类型：</p>
<pre><code>1、直接字串
       可以使用引号，也可以不用。
       换行符为\n,windows中\r\n
2、布尔型
       true,false
       其它类型会自动转换为布尔型。
       所有数字都是true
       空字符串为false，其它字符串为true
3、数值
       整数
       浮点数
4、数组，逗号隔开
       $array = [&apos;httpd&apos;,&apos;mysql&apos;,&apos;php&apos;]
       package {$array:ensure =&gt; installed} #依次安装包
5、hash
       { key1 =&gt; value1,key2 =&gt; value2,…}
6、undef，声明未定义的东西不能加上引号的。
</code></pre><p>3)、puppet支持的操作符和对应的表达式：</p>
<h1 id="比较操作符"><a href="#比较操作符" class="headerlink" title="比较操作符:"></a>比较操作符:</h1><pre><code>！=
&lt;,&gt;,&lt;=,&gt;=,
=~ 正则匹配
!~ 正则不匹配
in
</code></pre><p>布尔操作符:</p>
<pre><code>and
or
!
</code></pre><p>算术运算</p>
<pre><code>+
–
 /
 *
 &lt;&lt;   左移
</code></pre><blockquote>
<p>  右移</p>
<pre><code>$osfamily == &apos;CentOS&apos; 
$kernel in [&apos;Linux&apos;,&apos;solaris&apos;,&apos;freebsd&apos;]
</code></pre><p>4)、puppet的条件判断语句：</p>
<pre><code>if ..elsif..else
case
selector语句 #意思是在两个选项中任选其中一个赋值
</code></pre><p>if $operationsystem == ‘CentOS’{</p>
<pre><code>       notice(&quot;welcome to CentOS&quot;)
}
elsif $operationsystem == &apos;Redhat&apos; {
       notice(&quot;Welcome to Redhat&quot;)
}
elsif $operationsystem == &apos;Fedora&apos; {
       notice(&quot;Welcome to Fedora&quot;)
}
else{
       notice(&apos;Welcome to ET&apos;)
}
</code></pre><p>case $operationsystem {</p>
<pre><code>&apos;Solaris&apos;:  { include role::solaris }
&apos;Redhat&apos;,&apos;CentOS&apos; : { include role::redhat }
/^(Debian|Ubuntu)$/ : { include role::debian }
default : { include role::generic }
</code></pre><p>}<br>$webserver = $operatingsystem ? {</p>
<pre><code>/(?i-mx:&apos;ubuntu&apos;|debian)/ =&gt; &apos;apache&apos;,
/(?i-mx:redhat|centos|fedora)/ =&gt; &apos;httpd&apos;,
default =&gt; &apos;httpd&apos;
</code></pre><p>}<br>i：表示忽略大小写</p>
</blockquote>
</blockquote>
</resource_name></resource_name></li>
</ol>
<ul>
<li>： 表示不使用某转移符号<br>m：表示把 “.” 当做换行符使用<br>x :表示互略模式中空白字符和注释。<br>六、puppet类和模块<br>类是具有相同特性和行为的集合。就是一组代码块，在需要时可以通过名称进行调用。只定义类，并不会调用，需要声明才可以。<br>1)、语法：<br>class class_name [inherits] [base_class] {<pre><code>正常的puppet代码
</code></pre>}<br>如果在同个模块定义了多个类， 可以采双冒号（ ：： ） 。<br>例如定义个nginx模块，<br>模块中 定义三个类：<br>class nginx { … }<br>class nginx::config { … }<br>class nginx::vhost { … }<br>2)、类的继承(基类不能有参数)：<br>1、继承资源属性<br>2、覆盖资源属性<pre><code>=&gt;         
</code></pre>3、追加资源属性<pre><code>+&gt;
</code></pre>3)、 模块<br>模块结构<br>module name<pre><code>mainfests
       init.pp  #必须至少声明一个类。类与模块名相同
       *.pp
        # mudule_name::[subdirname]::mainfect_name
files：包含的是一个静态文件。puppet的agentmaster模型。
       puppet:///modles/module_name/[subdir_name/]file_name
templates：模板文件 *.erb 用到ruby语言
       template(&apos;&apos;);
       content =&gt; template(&apos;模板文件&apos;),
lib #插件目录。
tests ：当前模块的使用帮助或者实例文件
spec ：为lib目录的插件提供使用说明，范例的。
</code></pre>七、事例，puppet部署LNMP<br>1、假定已经安装好puppet-server。<br>..<br>2、主机名通信<br>cat &gt;&gt; /etc/hosts &lt;&lt;EOF192.168.198.139 puppet-server192.168.198.160 puppet-client<br>EOF<br>3、提供puppet文件<br>mkdir /etc/puppet/modules/lnmp/{manifests,files,templates,tests} -p<br>vim /etc/puppet/modules/lnmp/manifests/init.pp<br>class lnmp {<pre><code>include lnmp::nginx
include lnmp::mysql
include lnmp::php
</code></pre>}<br>vim /etc/puppet/modules/lnmp/manifests/nginx.pp<br>class lnmp::nginx {<br>  package{‘nginx’:<pre><code>ensure  =&gt; present,
name    =&gt; nginx,
</code></pre>  }<br>  file{‘nginx.conf’:<pre><code>ensure  =&gt; file,
source  =&gt; &apos;puppet:///modules/lnmp/nginx.conf&apos;,
path    =&gt; &apos;/etc/nginx/nginx.conf&apos;,
require =&gt; Package[&apos;nginx&apos;],
</code></pre>  }<br> service{‘nginx’:<pre><code>ensure  =&gt; true,
enable  =&gt; true,
subscribe =&gt; File[&apos;nginx.conf&apos;],
</code></pre>  }<br>}<br>vim /etc/puppet/modules/lnmp/manifests/php.pp<br>class lnmp::php {<br>  package{‘php-fpm’:<pre><code>ensure  =&gt; present,
name    =&gt; php-fpm,
</code></pre>  }<br>  file{‘www.conf’:<pre><code>ensure  =&gt; file,
source  =&gt; &apos;puppet:///modules/lnmp/www.conf&apos;,
path    =&gt; &apos;/etc/php-fpm.d/www.conf&apos;,
require =&gt; Package[&apos;php-fpm&apos;],
</code></pre>  }<br> service{‘php-fpm’:<pre><code>ensure  =&gt; true,
enable  =&gt; true,
subscribe =&gt; File[&apos;www.conf&apos;],
</code></pre>  }<br>}<br>vim /etc/puppet/modules/lnmp/manifests/mysql.pp<br>class lnmp::mysql {<br>  package{‘mysql-server’:<pre><code>ensure  =&gt; present,
name    =&gt; &apos;mysql-server&apos;,
</code></pre>  }<br>  file{‘my.cnf’:<pre><code>ensure  =&gt; file,
source  =&gt; &apos;puppet:///modules/lnmp/my.cnf&apos;,
path    =&gt; &apos;/etc/my.cnf&apos;,
require =&gt; Package[&apos;mysql-server&apos;],
</code></pre>  }<br> service{‘mysqld’:<pre><code>ensure  =&gt; true,
enable  =&gt; true,
subscribe =&gt; File[&apos;my.cnf&apos;],
</code></pre>  }<br>}<br>vim /etc/puppet/manifests/site.pp<br>node ‘puppet-client’ {<br>include lnmp<br>}<br>4、提供服务配置文件<br>cp /root/files/{nginx.conf,www.conf,my.cnf} /etc/puppet/modules/lnmp/files/<br>5、启动puppet服务<br>[root@puppet-server modules]# puppet master –verbose –no-daemonize   #第一次启动以便观察信息Info: Creating a new SSL key for ca<br>Info: Creating a new SSL certificate request for ca<br>Info: Certificate Request fingerprint (SHA256): 7B:A9:AB:84:C0:EB:DC:83:0E:EA:8C:81:1E:25:9A:47:5C:3F:10:31:6F:F7:5C:25:BE:B7:41:3C:B8:6B:35:38…..<br>[root@puppet-client ~]# puppet agent server –server puppet-server –verbose –no-daemonize  #客户端申请证书[root@puppet-server ~]# puppet cert sign puppet-client   #服务器签署证书#稍等一会[root@puppet-client ~]# ss -tnl | egrep “80|3306|9000”LISTEN     0      128                       <em>:9000                     </em>:<em><br>LISTEN     0      50                        </em>:3306                     <em>:</em><br>LISTEN     0      128                       <em>:80                       </em>:*<br>八、总结</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-6-x-Puppet/" data-id="ciwps8im9000950cy9djlx7sk" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-前言-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/前言-1/" class="article-date">
  <time datetime="2016-12-15T00:23:59.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/15/前言-1/">前言</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/前言-1/" data-id="ciwps8ip0002c50cy85mcm31b" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/15/CentOS-6-x-Moodle/">CentOS 6.x Moodle</a>
          </li>
        
          <li>
            <a href="/2016/12/15/CentOS-6-x-SmokePing/">CentOS 6.x SmokePing</a>
          </li>
        
          <li>
            <a href="/2016/12/15/1-刷固件/">1.刷固件</a>
          </li>
        
          <li>
            <a href="/2016/12/15/Linaro-12-11-Hadoop/">Linaro 12.11 Hadoop</a>
          </li>
        
          <li>
            <a href="/2016/12/15/CentOS-6-x-CDH/">CentOS 6.x CDH</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 JinYan<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>