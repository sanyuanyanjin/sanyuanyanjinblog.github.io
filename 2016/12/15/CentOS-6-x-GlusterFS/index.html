<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>CentOS 6.x GlusterFS | SanYuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、前言GlusterFS是一个开源的分布式文件系统,于2011年被红帽收购.它具有高扩展性、高性能、高可用性、可横向扩展的弹性特点,无元数据服务器设计使glusterfs没有单点故障隐患，详细介绍请查看官网：www.gluster.org 。二、环境1、系统：Centos 6.52、部署说明服务端：10.6.0.21710.6.0.21810.6.0.219客户端：10.6.0.215三、部署1">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS 6.x GlusterFS">
<meta property="og:url" content="http://yoursite.com/2016/12/15/CentOS-6-x-GlusterFS/index.html">
<meta property="og:site_name" content="SanYuan">
<meta property="og:description" content="一、前言GlusterFS是一个开源的分布式文件系统,于2011年被红帽收购.它具有高扩展性、高性能、高可用性、可横向扩展的弹性特点,无元数据服务器设计使glusterfs没有单点故障隐患，详细介绍请查看官网：www.gluster.org 。二、环境1、系统：Centos 6.52、部署说明服务端：10.6.0.21710.6.0.21810.6.0.219客户端：10.6.0.215三、部署1">
<meta property="og:updated_time" content="2016-12-15T03:14:31.815Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CentOS 6.x GlusterFS">
<meta name="twitter:description" content="一、前言GlusterFS是一个开源的分布式文件系统,于2011年被红帽收购.它具有高扩展性、高性能、高可用性、可横向扩展的弹性特点,无元数据服务器设计使glusterfs没有单点故障隐患，详细介绍请查看官网：www.gluster.org 。二、环境1、系统：Centos 6.52、部署说明服务端：10.6.0.21710.6.0.21810.6.0.219客户端：10.6.0.215三、部署1">
  
    <link rel="alternate" href="/atom.xml" title="SanYuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SanYuan</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-CentOS-6-x-GlusterFS" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/15/CentOS-6-x-GlusterFS/" class="article-date">
  <time datetime="2016-12-15T03:13:50.000Z" itemprop="datePublished">2016-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CentOS 6.x GlusterFS
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一、前言<br>GlusterFS是一个开源的分布式文件系统,于2011年被红帽收购.它具有高扩展性、高性能、高可用性、可横向扩展的弹性特点,无元数据服务器设计使glusterfs没有单点故障隐患，详细介绍请查看官网：www.gluster.org 。<br>二、环境<br>1、系统：<br>Centos 6.5<br>2、部署说明<br>服务端：<br>10.6.0.217<br>10.6.0.218<br>10.6.0.219<br>客户端：<br>10.6.0.215<br>三、部署<br>1、服务端安装：<br>rpm -ivh <a href="http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="external">http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm</a><br>wget -P /etc/yum.repos.d <a href="https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/CentOS/glusterfs-epel.repo" target="_blank" rel="external">https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/CentOS/glusterfs-epel.repo</a><br>[root@n5 ~]# cd /etc/yum.repos.d/<br>[root@n5 yum.repos.d]# cat glusterfs-epel.repo</p>
<h1 id="Place-this-file-in-your-etc-yum-repos-d-directory"><a href="#Place-this-file-in-your-etc-yum-repos-d-directory" class="headerlink" title="Place this file in your /etc/yum.repos.d/ directory"></a>Place this file in your /etc/yum.repos.d/ directory</h1><p>[glusterfs-epel]<br>name=GlusterFS is a clustered file-system capable of scaling to several petabytes.<br>baseurl=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/$basearch/" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/$basearch/</a><br>enabled=1<br>skip_if_unavailable=1<br>gpgcheck=1</p>
<h1 id="gpgkey-http-download-gluster-org-pub-gluster-glusterfs-3-7-3-7-12-EPEL-repo-pub-key"><a href="#gpgkey-http-download-gluster-org-pub-gluster-glusterfs-3-7-3-7-12-EPEL-repo-pub-key" class="headerlink" title="gpgkey=http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key"></a>gpgkey=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key</a></h1><p>gpgkey=<a href="https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key" target="_blank" rel="external">https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key</a></p>
<p>[glusterfs-noarch-epel]<br>name=GlusterFS is a clustered file-system capable of scaling to several petabytes.<br>baseurl=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/noarch" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/noarch</a><br>enabled=1<br>skip_if_unavailable=1<br>gpgcheck=1<br>gpgkey=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key</a></p>
<p>[glusterfs-source-epel]<br>name=GlusterFS is a clustered file-system capable of scaling to several petabytes. - Source<br>baseurl=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/SRPMS" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/epel-$releasever/SRPMS</a><br>enabled=0<br>skip_if_unavailable=1<br>gpgcheck=1</p>
<h1 id="gpgkey-http-download-gluster-org-pub-gluster-glusterfs-3-7-3-7-12-EPEL-repo-pub-key-1"><a href="#gpgkey-http-download-gluster-org-pub-gluster-glusterfs-3-7-3-7-12-EPEL-repo-pub-key-1" class="headerlink" title="gpgkey=http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key"></a>gpgkey=<a href="http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key" target="_blank" rel="external">http://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key</a></h1><p>gpgkey=<a href="https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key" target="_blank" rel="external">https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/EPEL.repo/pub.key</a><br>[root@n5 yum.repos.d]#<br>wget -P /etc/yum.repos.d <a href="https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/pub.key" target="_blank" rel="external">https://download.gluster.org/pub/gluster/glusterfs/3.7/3.7.12/pub.key</a><br>[root@n6 ~]# cd -<br>/etc/yum.repos.d<br>[root@n6 yum.repos.d]# scp -r glusterfs-epel.repo pub.key root@n5:/etc/yum.repos.d<br>The authenticity of host ‘n5 (10.6.0.215)’ can’t be established.<br>RSA key fingerprint is 23:92:f4:8f:62:12:e2:31:d2:31:5b:d7:28:f3:58:1f.<br>Are you sure you want to continue connecting (yes/no)? yes<br>Warning: Permanently added ‘n5,10.6.0.215’ (RSA) to the list of known hosts.<br>root@n5’s password:<br>glusterfs-epel.repo                                                                                                                            100% 1257     1.2KB/s   00:00<br>pub.key                                                                                                                                        100% 1732     1.7KB/s   00:00<br>[root@n6 yum.repos.d]#<br>yum clean all<br>rpm –import pub.key<br>yum makecache<br>yum -y install glusterfs glusterfs-server<br>chkconfig glusterd on<br>service glusterd start<br>2、服务端配置：<br>将3个存储节点组成一集群，本文在第一个节点执行，只需要在任意节点执行就OK。<br>[root@n6 ~]# gluster peer probe 10.6.0.216<br>peer probe: success. Probe on localhost not needed<br>[root@n6 ~]# gluster peer probe 10.6.0.217<br>peer probe: success.<br>[root@n6 ~]# gluster peer probe 10.6.0.218<br>peer probe: success.<br>[root@n6 ~]# gluster peer probe 10.6.0.219<br>peer probe: success.<br>查看集群的节点信息：<br>[root@n6 ~]# gluster peer status<br>Number of Peers: 3</p>
<p>Hostname: 10.6.0.217<br>Uuid: f2614374-cc36-4f01-970d-8bae30928451<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.218<br>Uuid: 3baee195-593a-4d97-9b61-96eb2a7e1778<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.219<br>Uuid: b342072a-ca38-476c-82b8-21ed28eb5376<br>State: Peer in Cluster (Connected)<br>以/data/gluster为共享目录，创建名为img的卷,副本数为3：<br>mkdir -p /data/gluster<br>[root@n6 ~]# gluster volume create img replica 3 10.6.0.217:/data/gluster 10.6.0.218:/data/gluster 10.6.0.219:/data/gluster force<br>volume create: img: success: please start the volume to access data<br>启动卷：<br>[root@n6 ~]# gluster volume start img<br>volume start: img: success<br>[root@n6 ~]#<br>查看卷状态:<br>[root@n6 ~]# gluster volume info</p>
<p>Volume Name: img<br>Type: Replicate<br>Volume ID: c481f5a9-5dcb-4cb3-9870-0ec57dbc22fb<br>Status: Started<br>Number of Bricks: 1 x 3 = 3<br>Transport-type: tcp<br>Bricks:<br>Brick1: 10.6.0.217:/data/gluster<br>Brick2: 10.6.0.218:/data/gluster<br>Brick3: 10.6.0.219:/data/gluster<br>Options Reconfigured:<br>performance.readdir-ahead: on<br>[root@n6 ~]#<br>3、客户端安装配置：<br>安装：<br>yum -y install glusterfs glusterfs-fuse<br>[root@n5 ~]# mkdir -p /data/img<br>挂载任意一个节点即可<br>[root@n5 ~]# mount -t glusterfs 10.6.0.217:/img /data/img<br>[root@n5 ~]# df -h<br>Filesystem                  Size  Used Avail Use% Mounted on<br>/dev/mapper/vg_n5-LogVol00  3.6T  1.1T  2.4T  31% /<br>tmpfs                       1.9G   68K  1.9G   1% /dev/shm<br>/dev/sda1                   194M   35M  150M  19% /boot<br>cm_processes                1.9G   72M  1.9G   4% /opt/cm-5.1.3/run/cloudera-scm-agent/process<br>10.6.0.217:/img             3.6T  1.4T  2.1T  41% /data/img<br>[root@n5 ~]#<br>mount -t nfs -o mountproto=tcp,vers=3 10.6.0.217:/img /home/nfs （使用NFS挂载，注意远端的rpcbind服务必须开启）<br>echo “10.6.0.217:/img /data/img glusterfs defaults,_netdev 0 0” &gt;&gt; /etc/fstab (开机自动挂载)</p>
<p>安装配置Samba<br>yum install samba samba-client samba-swat -y<br>vim /etc/samba/smb.conf<br>[img]<br>        comment = The img<br>        path = /data/img<br>        browseable = yes<br>        writable = yes<br>useradd smbimg<br>smbpasswd -a smbimg<br>/etc/init.d/smb start<br>/etc/init.d/nmb start<br>service smb status<br>chkconfig smb on</p>
<p>[root@n5 ~]# ll -d /data/img/<br>drwxr-xr-x 4 root root 4096 8月   2 13:56 /data/img/<br>[root@n5 ~]# chown -R smbimg:smbimg /data/img/<br>[root@n5 ~]# ll -d /data/img/<br>drwxr-xr-x 4 smbimg smbimg 4096 8月   2 13:56 /data/img/<br>[root@n5 ~]#<br>[root@n5 ~]# ll /data/img/<br>总用量 0<br>-rwxr–r– 1 smbimg smbimg 0 8月   2 14:08 测试gfs.txt</p>
<p>安装配置FTP<br>yum -y install vsftpd<br>vim /etc/vsftpd/vsftpd.conf<br>chkconfig –level 345 vsftpd on<br>useradd -g ftp -d /data/img/ftpimg -M ftpimg<br>passwd ftpimg<br>chown -R ftpimg /data/img/ftpimg<br>ll -d /data/img/ftpimg<br>drwxr-xr-x 2 ftpimg root 4096 8月   2 14:12 /data/img/ftpimg<br>service vsftpd restart</p>
<p>四、测试<br>1、检查文件正确性<br>dd if=/dev/urandom of=/data/navy bs=1M count=100 # 在挂载客户端生成测试文件<br>cp /data/navy /mnt/  # 文件拷贝到存储上<br>md5sum /data/navy /mnt/navy # 在查看客户端检查文件哈希<br>md5sum /data/gluster/navy # 存储集群的某2个节点上会有此文件，检查其哈希<br>2、宕机测试。使用glusterfs-fuse挂载，即使目标服务器故障，也完全不影响使用。用NFS则要注意挂载选项，否则服务端故障容易导致文件系统halt住而影响服务！</p>
<h1 id="将其中一个节点停止存储服务service-glusterd-stop"><a href="#将其中一个节点停止存储服务service-glusterd-stop" class="headerlink" title="将其中一个节点停止存储服务service glusterd stop"></a>将其中一个节点停止存储服务service glusterd stop</h1><p>service glusterfsd stop# 在挂载客户端删除测试文件<br>rm -fv /mnt/navy# 此时在服务端查看，服务被停止的节点上navy并未被删除。此时启动服务：service glusterd start# 数秒后，navy就被自动删除了。新增文件效果相同！<br>五、运维常用命令：<br>删除卷<br>gluster volume stop img<br>gluster volume delete img<br>将机器移出集群<br>gluster peer detach 10.6.0.217<br>只允许10.6.<em>.</em>的网络访问glusterfs<br>gluster volume set img auth.allow 10.6.<em>.</em></p>
<p>加入新的机器并添加到卷里(由于副本数设置为3,至少要添加3（6、9、12..）台机器)<br>gluster peer probe 10.6.0.212<br>gluster peer probe 10.6.0.213<br>gluster peer probe 10.6.0.216</p>
<p>[root@n3 ~]# mkdir -p /data/gluster<br>gluster volume add-brick img 10.6.0.212:/data/gluster 10.6.0.213:/data/gluster 10.6.0.216:/data/gluster force</p>
<p>[root@n6 ~]# gluster volume add-brick img 10.6.0.212:/data/gluster 10.6.0.213:/data/gluster 10.6.0.216:/data/gluster force<br>volume add-brick: success<br>[root@n6 ~]# gluster volume info</p>
<p>Volume Name: img<br>Type: Distributed-Replicate<br>Volume ID: c481f5a9-5dcb-4cb3-9870-0ec57dbc22fb<br>Status: Started<br>Number of Bricks: 2 x 3 = 6<br>Transport-type: tcp<br>Bricks:<br>Brick1: 10.6.0.217:/data/gluster<br>Brick2: 10.6.0.218:/data/gluster<br>Brick3: 10.6.0.219:/data/gluster<br>Brick4: 10.6.0.212:/data/gluster<br>Brick5: 10.6.0.213:/data/gluster<br>Brick6: 10.6.0.216:/data/gluster<br>Options Reconfigured:<br>performance.readdir-ahead: on<br>[root@n6 ~]#</p>
<p><a href="https://gluster.readthedocs.io/en/latest/Administrator%20Guide/Managing%20Volumes/#rebalancing-volumes" target="_blank" rel="external">https://gluster.readthedocs.io/en/latest/Administrator%20Guide/Managing%20Volumes/#rebalancing-volumes</a><br>均衡卷<br>[root@n6 ~]# gluster volume rebalance img start<br>volume rebalance: img: success: Rebalance on img has been started successfully. Use rebalance status command to check status of the rebalance process.<br>ID: b9d8629a-673d-4db2-8361-bb8e9b65b16b</p>
<p>[root@n6 ~]# gluster volume rebalance img status<br>                                    Node Rebalanced-files          size       scanned      failures       skipped               status  run time in h:m:s</p>
<pre><code> ---------      -----------   -----------   -----------   -----------   -----------         ------------     --------------
 localhost                0        0Bytes             0             0             0          in progress        0:0:17
10.6.0.217                0        0Bytes          1033             0           341          in progress        0:0:16
10.6.0.218                0        0Bytes             0             0             0          in progress        0:0:17
10.6.0.219                0        0Bytes             0             0             0          in progress        0:0:16
10.6.0.212                0        0Bytes             1             0             0          in progress        0:0:17
10.6.0.213                0        0Bytes             0             0             0          in progress        0:0:17
</code></pre><p>volume rebalance: img: success<br>[root@n6 ~]#</p>
<p>[root@n6 ~]# gluster volume status<br>Status of volume: img</p>
<h2 id="Gluster-process-TCP-Port-RDMA-Port-Online-Pid"><a href="#Gluster-process-TCP-Port-RDMA-Port-Online-Pid" class="headerlink" title="Gluster process                             TCP Port  RDMA Port  Online  Pid"></a>Gluster process                             TCP Port  RDMA Port  Online  Pid</h2><p>Brick 10.6.0.217:/data/gluster              49152     0          Y       31557<br>Brick 10.6.0.218:/data/gluster              49152     0          Y       2469<br>Brick 10.6.0.219:/data/gluster              49152     0          Y       12325<br>Brick 10.6.0.212:/data/gluster              49152     0          Y       31261<br>Brick 10.6.0.213:/data/gluster              49152     0          Y       24831<br>Brick 10.6.0.216:/data/gluster              49152     0          Y       28081<br>NFS Server on localhost                     2049      0          Y       28102<br>Self-heal Daemon on localhost               N/A       N/A        Y       28112<br>NFS Server on 10.6.0.217                    2049      0          Y       8257<br>Self-heal Daemon on 10.6.0.217              N/A       N/A        Y       8267<br>NFS Server on 10.6.0.219                    2049      0          Y       26335<br>Self-heal Daemon on 10.6.0.219              N/A       N/A        Y       26344<br>NFS Server on 10.6.0.212                    N/A       N/A        N       N/A<br>Self-heal Daemon on 10.6.0.212              N/A       N/A        Y       31290<br>NFS Server on 10.6.0.213                    2049      0          Y       24852<br>Self-heal Daemon on 10.6.0.213              N/A       N/A        Y       24861<br>NFS Server on 10.6.0.218                    2049      0          Y       9773<br>Self-heal Daemon on 10.6.0.218              N/A       N/A        Y       9782</p>
<h2 id="Task-Status-of-Volume-img"><a href="#Task-Status-of-Volume-img" class="headerlink" title="Task Status of Volume img"></a>Task Status of Volume img</h2><p>Task                 : Rebalance<br>ID                   : b9d8629a-673d-4db2-8361-bb8e9b65b16b<br>Status               : completed           </p>
<p>[root@n6 ~]#</p>
<p>[root@n6 ~]# gluster<br>gluster&gt; peer status<br>Number of Peers: 5</p>
<p>Hostname: 10.6.0.217<br>Uuid: f2614374-cc36-4f01-970d-8bae30928451<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.218<br>Uuid: 3baee195-593a-4d97-9b61-96eb2a7e1778<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.219<br>Uuid: b342072a-ca38-476c-82b8-21ed28eb5376<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.212<br>Uuid: 4f734c6e-aefc-4bd7-98e3-1d27e437eaff<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.213<br>Uuid: bae64a18-2613-4e68-88fa-2016d2ecf86b<br>State: Peer in Cluster (Connected)<br>gluster&gt;</p>
<p>[root@n7 ~]# gluster<br>gluster&gt; peer status<br>Number of Peers: 5</p>
<p>Hostname: n6<br>Uuid: 9512aa35-a8ee-4d50-a715-fbc857e3d8f8<br>State: Peer in Cluster (Connected)<br>Other names:<br>10.6.0.216</p>
<p>Hostname: 10.6.0.218<br>Uuid: 3baee195-593a-4d97-9b61-96eb2a7e1778<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.219<br>Uuid: b342072a-ca38-476c-82b8-21ed28eb5376<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.212<br>Uuid: 4f734c6e-aefc-4bd7-98e3-1d27e437eaff<br>State: Peer in Cluster (Connected)</p>
<p>Hostname: 10.6.0.213<br>Uuid: bae64a18-2613-4e68-88fa-2016d2ecf86b<br>State: Peer in Cluster (Connected)<br>gluster&gt;</p>
<p>收缩卷</p>
<h1 id="收缩卷前gluster需要先移动数据到其他位置"><a href="#收缩卷前gluster需要先移动数据到其他位置" class="headerlink" title="收缩卷前gluster需要先移动数据到其他位置"></a>收缩卷前gluster需要先移动数据到其他位置</h1><p>gluster volume remove-brick img 10.6.0.217:/data/gluster/img 10.6.0.218:/data/gluster/img start</p>
<h1 id="查看迁移状态"><a href="#查看迁移状态" class="headerlink" title="查看迁移状态"></a>查看迁移状态</h1><p>gluster volume remove-brick img 10.6.0.217:/data/gluster/img 10.6.0.218:/data/gluster/img status</p>
<h1 id="迁移完成后提交"><a href="#迁移完成后提交" class="headerlink" title="迁移完成后提交"></a>迁移完成后提交</h1><p>gluster volume remove-brick img 10.6.0.217:/data/gluster/img 10.6.0.218:/data/gluster/img commit</p>
<p>节点故障处理<br>如果一台节点服务器down机，这个时候，我们要恢复故障，替换volume中坏掉的brick为新的brick，参考如下操作：</p>
<p>#prob server<br>gluster peer probe [new-server]</p>
<p>#replace old to new brick<br>gluster volume replace-brick vol-name [old-server]:/[old-brick] [new-server]:/[new-brick] start</p>
<p>#检查同步的状态<br>gluster volume replace-brick vol-name [old-server]:/[old-brick] [new-server]:/[new-brick] status</p>
<p>#等待同步完成之后 提交<br>gluster volume replace-brick vol-name [old-server]:/[old-brick] [new-server]:/[new-brick] commit force<br>只需在一台节点上操作，所有的服务器上该卷的brick都换成新的brick了。</p>
<p>迁移卷</p>
<h1 id="将10-6-0-217的数据迁移到-先将10-6-0-212加入集群"><a href="#将10-6-0-217的数据迁移到-先将10-6-0-212加入集群" class="headerlink" title="将10.6.0.217的数据迁移到,先将10.6.0.212加入集群"></a>将10.6.0.217的数据迁移到,先将10.6.0.212加入集群</h1><p>gluster peer probe 10.6.0.212<br>gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.212:/data/gluster/img start</p>
<h1 id="查看迁移状态gluster-volume-replace-brick-img-10-6-0-217-data-gluster-img-10-6-0-212-data-gluster-img-status"><a href="#查看迁移状态gluster-volume-replace-brick-img-10-6-0-217-data-gluster-img-10-6-0-212-data-gluster-img-status" class="headerlink" title="查看迁移状态gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.212:/data/gluster/img status"></a>查看迁移状态gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.212:/data/gluster/img status</h1><h1 id="数据迁移完毕后提交gluster-volume-replace-brick-img-10-6-0-217-data-gluster-img-10-6-0-212-data-gluster-img-commit"><a href="#数据迁移完毕后提交gluster-volume-replace-brick-img-10-6-0-217-data-gluster-img-10-6-0-212-data-gluster-img-commit" class="headerlink" title="数据迁移完毕后提交gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.212:/data/gluster/img commit"></a>数据迁移完毕后提交gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.212:/data/gluster/img commit</h1><h1 id="如果机器10-6-0-217出现故障已经不能运行-执行强制提交然后要求gluster马上执行一次同步"><a href="#如果机器10-6-0-217出现故障已经不能运行-执行强制提交然后要求gluster马上执行一次同步" class="headerlink" title="如果机器10.6.0.217出现故障已经不能运行,执行强制提交然后要求gluster马上执行一次同步"></a>如果机器10.6.0.217出现故障已经不能运行,执行强制提交然后要求gluster马上执行一次同步</h1><p>gluster volume replace-brick img 10.6.0.217:/data/gluster/img 10.6.0.218:/data/gluster/img commit -force<br>gluster volume heal imgs full</p>
<p>安装：</p>
<p>yum install scsi-target-utils -y</p>
<p>启动服务</p>
<p>/etc/init.d/tgtd start</p>
<p>设为开机自启动：</p>
<p>chkconfig tgtd on</p>
<p>确认一下有没有端口起来<br>netstat -anlpt | grep 3260</p>
<p>vim /etc/tgt/targets.conf</p>
<target iqn.2016-08.n3:test=""><br>  backing-store /mnt/test<br></target>

<p>[root@n2 ~]# ll -h /data/img/img1<br>-rw-r–r– 1 root root 200M 8月  23 14:45 /data/img/img1</p>
<p>tgtadm –lld iscsi –op new –mode logicalunit –tid 1 –lun 2 -b /data/img/img1</p>
<p>[root@n5 ~]# dd if=/dev/zero of=/data/img/n5img1 bs=10M count=5<br>记录了5+0 的读入<br>记录了5+0 的写出<br>52428800字节(52 MB)已复制，1.87226 秒，28.0 MB/秒<br>[root@n5 ~]# tgtadm –lld iscsi –op new –mode logicalunit –tid 1 –lun 3 -b /data/img/n5img1<br>[root@n5 ~]#</p>
<p>10.6.100.39 n5# dd if=/dev/zero of=/data/img/img1  bs=1024M count=1024<br>vim /etc/tgt/targets.conf</p>
<target iqn.2016-08.n5:img1=""><br>  backing-store /data/img/img1<br></target>

<p>/etc/init.d/tgtd restart</p>
<p>10.6.100.39 n5# dd if=/dev/zero of=/data/img/img2  bs=1024M count=100<br>vim /etc/tgt/targets.conf</p>
<target iqn.2016-09.n5:img2=""><br>  backing-store /data/img/img2<br></target>

<p>/etc/init.d/tgtd restart</p>
<p>查看信息<br>tgtadm –lld iscsi –op show –mode target</p>
<p>tgtadm –lld iscsi –op new –mode logicalunit –tid 1 –lun 1 -b /data/img/img2</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/15/CentOS-6-x-GlusterFS/" data-id="ciwvctjxx000cu1cy8525q8ww" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/12/15/CentOS-6-x-SendMail/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          CentOS 6.x SendMail
        
      </div>
    </a>
  
  
    <a href="/2016/12/15/CentOS-6-x-Expec/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">CentOS 6.x Expec</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/19/alfresco/">alfresco</a>
          </li>
        
          <li>
            <a href="/2016/12/19/书单/">书单</a>
          </li>
        
          <li>
            <a href="/2016/12/15/NGINX日志切割/">NGINX日志切割</a>
          </li>
        
          <li>
            <a href="/2016/12/15/CentOS-6-x-安装SVN/">CentOS 6.x 安装SVN</a>
          </li>
        
          <li>
            <a href="/2016/12/15/CentOS-7-x-git/">CentOS 7.x git</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 JinYan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>