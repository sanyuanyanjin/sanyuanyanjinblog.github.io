<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>SanYuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="SanYuan">
<meta property="og:url" content="http://yoursite.com/page/7/index.html">
<meta property="og:site_name" content="SanYuan">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SanYuan">
  
    <link rel="alternate" href="/atom.xml" title="SanYuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SanYuan</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-如何用十条命令在一分钟内检查Linux服务器性能" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/" class="article-date">
  <time datetime="2016-12-12T09:08:07.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/">如何用十条命令在一分钟内检查Linux服务器性能</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过执行以下命令，可以在1分钟内对系统资源使用情况有个大致的了解。</p>
<p>uptime</p>
<p>dmesg | tail</p>
<p>vmstat 1</p>
<p>mpstat -P ALL 1</p>
<p>pidstat 1</p>
<p>iostat -xz 1</p>
<p>free -m</p>
<p>sar -n DEV 1</p>
<p>sar -n TCP,ETCP 1</p>
<p>top</p>
<p>其中一些命令需要安装sysstat包，有一些由procps包提供。这些命令的输出，有助于快速定位性能瓶颈，检查出所有资源（CPU、内存、磁盘IO等）的利用率（utilization）、饱和度（saturation）和错误（error）度量，也就是所谓的USE方法。</p>
<p>下面我们来逐一介绍下这些命令，有关这些命令更多的参数和说明，请参照命令的手册。</p>
<p>uptime<br>$ uptime</p>
<p>23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02</p>
<p>这个命令可以快速查看机器的负载情况。在Linux系统中，这些数据表示等待CPU资源的进程和阻塞在不可中断IO进程（进程状态为D）的数量。这些数据可以让我们对系统资源使用有一个宏观的了解。</p>
<p>命令的输出分别表示1分钟、5分钟、15分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是趋于缓解。如果1分钟平均负载很高，而15分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查CPU资源都消耗在了哪里。反之，如果15分钟平均负载很高，1分钟平均负载较低，则有可能是CPU资源紧张时刻已经过去。</p>
<p>上面例子中的输出，可以看见最近1分钟的平均负载非常高，且远高于最近15分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的vmstat、mpstat等命令进一步排查。</p>
<p>dmesg丨tail<br>$ dmesg | tail</p>
<p>[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0</p>
<p>[…]</p>
<p>[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child</p>
<p>[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB</p>
<p>[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping</p>
<p>request.  Check SNMP counters.</p>
<p>该命令会输出系统日志的最后10行。示例中的输出，可以看见一次内核的oom kill和一次TCP丢包。这些日志可以帮助排查性能问题。千万不要忘了这一步。</p>
<p>vmstat 1<br>$ vmstat 1</p>
<p>procs ———memory———- —swap– —–io—- -system– ——cpu—–</p>
<p> r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</p>
<p>34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0</p>
<p>32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0</p>
<p>32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0</p>
<p>32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0</p>
<p>32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0</p>
<p>^C</p>
<p>vmstat(8) 命令，每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数1，表示每秒输出一次统计信息，表头提示了每一列的含义，这几介绍一些和性能调优相关的列：</p>
<p>r：等待在CPU资源的进程数。这个数据比平均负载更加能够体现CPU负载情况，数据中不包含等待IO的进程。如果这个数值大于机器CPU核数，那么机器的CPU资源已经饱和。</p>
<p>free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的free命令，可以更详细的了解系统内存的使用情况。</p>
<p>si，so：交换区写入和读取的数量。如果这个数据不为0，说明系统已经在使用交换区（swap），机器物理内存已经不足。</p>
<p>us, sy, id, wa, st：这些都代表了CPU时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。</p>
<p>上述这些CPU时间，可以让我们很快了解CPU是否出于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU出于忙于执行指令。如果IO等待时间很长，那么系统的瓶颈可能在磁盘IO。</p>
<p>示例命令的输出可以看见，大量CPU时间消耗在用户态，也就是用户应用程序消耗了CPU时间。这不一定是性能问题，需要结合r队列，一起分析。</p>
<p>mpstat-P ALL 1<br>$ mpstat -P ALL 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86<em>64</em> (32 CPU)</p>
<p>07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle</p>
<p>07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78</p>
<p>07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99</p>
<p>07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00</p>
<p>07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00</p>
<p>07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03</p>
<p>[…]</p>
<p>该命令可以显示每个CPU的占用情况，如果有一个CPU占用率特别高，那么有可能是一个单线程应用程序引起的。</p>
<p>pidstat 1<br>$ pidstat 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86<em>64</em>    (32 CPU)</p>
<p>07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</p>
<p>07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0</p>
<p>07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave</p>
<p>07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java</p>
<p>07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java</p>
<p>07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java</p>
<p>07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat</p>
<p>07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</p>
<p>07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave</p>
<p>07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java</p>
<p>07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass</p>
<p>07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat</p>
<p>^C</p>
<p>pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。</p>
<p>iostat-xz 1<br>$ iostat -xz 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86<em>64</em> (32 CPU)</p>
<p>avg-cpu:  %user   %nice %system %iowait  %steal   %idle</p>
<pre><code>73.96    0.00    3.73    0.03    0.06   22.21
</code></pre><p>Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</p>
<p>xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09</p>
<p>xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25</p>
<p>xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26</p>
<p>dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04</p>
<p>dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00</p>
<p>dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03</p>
<p>[…]</p>
<p>^C</p>
<p>iostat命令主要用于查看机器磁盘IO情况。该命令输出的列，主要含义是：</p>
<p>r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。</p>
<p>await：IO操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括IO等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。</p>
<p>avgqu-sz：向设备发出的请求平均数量。如果这个数值大于1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。</p>
<p>%util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过60，可能会影响IO性能（可以参照IO操作平均等待时间）。如果到达100%，说明硬件设备已经饱和。</p>
<p>如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使IO性能不理想，也不一定意味这应用程序性能会不好，可以利用诸如预读取、写缓存等策略提升应用性能。</p>
<p>free -m<br>$ free -m</p>
<pre><code>total       used       free     shared    buffers     cached
</code></pre><p>Mem:        245998      24545     221453         83         59        541</p>
<p>-/+ buffers/cache:      23944     222053</p>
<p>Swap:            0          0          0</p>
<p>free命令可以查看系统内存的使用情况，-m参数表示按照兆字节展示。最后两列分别表示用于IO缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行-/+ buffers/cache，看上去缓存占用了大量内存空间。</p>
<p>这是Linux系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。</p>
<p>如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加IO开销（可以在iostat命令中提现），降低系统性能。</p>
<p>sar -n DEV 1<br>$ sar -n DEV 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86<em>64</em>    (32 CPU)</p>
<p>12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</p>
<p>12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</p>
<p>12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00</p>
<p>12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00</p>
<p>12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</p>
<p>^C</p>
<p>sar命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0网卡设备，吞吐率大概在22 Mbytes/s，既176 Mbits/sec，没有达到1Gbit/sec的硬件上限。</p>
<p>sar -n TCP,ETCP 1<br>$ sar -n TCP,ETCP 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86<em>64</em>    (32 CPU)</p>
<p>12:17:19 AM  active/s passive/s    iseg/s    oseg/s</p>
<p>12:17:20 AM      1.00      0.00  10233.00  18846.00</p>
<p>12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</p>
<p>12:17:20 AM      0.00      0.00      0.00      0.00      0.00</p>
<p>12:17:20 AM  active/s passive/s    iseg/s    oseg/s</p>
<p>12:17:21 AM      1.00      0.00   8359.00   6039.00</p>
<p>12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</p>
<p>12:17:21 AM      0.00      0.00      0.00      0.00      0.00</p>
<p>^C</p>
<p>sar命令在这里用于查看TCP连接状态，其中包括：</p>
<p>active/s：每秒本地发起的TCP连接数，既通过connect调用创建的TCP连接；</p>
<p>passive/s：每秒远程发起的TCP连接数，即通过accept调用创建的TCP连接；</p>
<p>retrans/s：每秒TCP重传数量；</p>
<p>TCP连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。</p>
<p>top<br>$ top</p>
<p>top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92</p>
<p>Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie</p>
<p>%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st</p>
<p>KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers</p>
<p>KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem</p>
<p>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</p>
<p> 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java</p>
<p>  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave</p>
<p> 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top</p>
<p>  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java</p>
<p>  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init</p>
<pre><code>2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd

3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0

5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H

6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0

8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched
</code></pre><p>top命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统CPU使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU占用率最高的进程等。</p>
<p>但是，top命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停top命令刷新，来记录和比对数据。</p>
<p>总结</p>
<p>排查Linux服务器性能问题还有很多工具，上面介绍的一些命令，可以帮助我们快速的定位问题。例如前面的示例输出，多个证据证明有JAVA进程占用了大量CPU资源，之后的性能调优就可以针对应用程序进行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/" data-id="ciwohfw2x00240fcyx9v28qdr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据工程师常用的-Shell-命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/数据工程师常用的-Shell-命令/" class="article-date">
  <time datetime="2016-12-12T09:04:24.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/数据工程师常用的-Shell-命令/">数据工程师常用的 Shell 命令</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Linux以其强大的命令行称霸江湖，Shell命令是数据极客的必修兵器。探索性数据分析，在需求和数据都不太明确的环境下，使用各种命令进行一次探索与挖掘。从基础的文件查看到简单的统计，再到一些常用的探索性分析命令，其目的都只是为了更好的做数据分析与挖掘而已。<br>01 Shell命令行</p>
<p>对于经常和数据打交道的人来说，数据工程师应该也是常常和Linux打交道。Linux以其强大的命令行称霸江湖，因此，Shell命令也是数据极客的必修兵器。</p>
<p>利用Linux命令行的几个命令，就可以完成一些简单的统计分析工作，比如利用wc命令统计文件行，单词数，字符数，利用sort排序和去重，再结合uniq可以进行词频统计。比如：<br>$ cat file.txt<br>yunjie<br>yunjie-talk<br>yunjie-yun<br>yunjie<br>yunjie-shuo<br>$ sort file.txt | uniq -c | sort -nr | head -5<br>   2 yunjie<br>   1 yunjie-shuo<br>   1 yunjie-talk<br>   1 yunjie-yun</p>
<p>先用cat命令，了解一下文件的大概格式与内容，发现每行为一个单词。现在需要统计这些单词出现的频率，以及显示出现次数最多的5个单词。</p>
<p>先对文件进行排序，这样相同的单词在紧挨着的行，再后uniq -c 命令，统计不同的单词及各个单词出现的次数。这样得到的结果就是次数后面紧接着单词，然后使用sort -nr对次数进行排序，并逆序显示，最后head命令显示结果的前5行。</p>
<p>非常简单的一种方式，读取文件，排序，统计，再对统计结果进行逆序，最后只显示前几个结果。</p>
<p>类似于sql语句：</p>
<p>select word,count(1) cnt<br>from file<br>group by word<br>order by cnt desc<br>limit 5;</p>
<p>如果对sql语句熟悉的话，上面的形式应该更容易理解。虽然实现的思想和方式非常简单，但在实际的探索性数据分析中使用却非常频繁。</p>
<p>02 探索性分析</p>
<p>比如在日志分析中，有时并没有非常明确的目标，或者即使有明确的目标，通常各种数据也并没有明确的定义。比如，别人丢给你一个压缩文件，说想分析一下里面有哪些是异常的访问请求。任务描述就是这样，没有更明确的了。</p>
<p>拿到日志文件和这样的分析任务，就需要进行各种可能的探索性分析。先看一下文件的格式，是否压缩过，使用gzip压缩还是tar压缩。解压后，需要先大概了解一下，文件是什么样的格式。对于网络请求的日志文件，是一行一个请求和响应，还是多行一个请求和响应。查看文件有多少行，查看文件占用空间大小。如果解压后包含多个目录或者文件，同样的一个命令，更能发挥强大效果。此时，通常需要如下命令：</p>
<p>gzip/tar：压缩/解压<br>cat/zcat：文件查看<br>less/more：文件查看，支持gz压缩格式直接查看<br>head/tail：查看文件前/后10行<br>wc：统计行数、单词数、字符数<br>du -h -c -s：查看空间占用</p>
<p>上面有一个比较有趣的命令组，less和more，这两个都可以分页查看文件。最开始有的more命令，好像是当时more不支持向后翻页。于是一帮人就在此基础上进行了改进，直接叫less，和more同样的功能只是更强大些。因此，也发展出了“less is more”的哲学，“少即是多”，而且少比多更好。这种思想，在产品设计与代码优化中都有体现。</p>
<p>了解文件的大概信息后，可能需要提取一行中某个字段的内容，或者需要搜索某些行出来，或者需要对某些字符或者行进行一定的修改操作，或者需要在众多的目录和文件中找出某此天的日志（甚至找到后需要对这些天的日志进行统一处理），此时下面这些命令可以帮你：</p>
<p>awk：命令行下的数据库操作工具<br>join/cut/paste：关联文件/切分字段/合并文件<br>fgrep/grep/egrep：全局正则表达式查找<br>find：查找文件，并且对查找结果批量化执行任务<br>sed：流编辑器，批量修改、替换文件<br>split：对大文件进行切分处理，按多少行一个文件，或者多少字节一个文件<br>rename：批量重命名(Ubuntu上带的perl脚本，其它系统需要安装)，使用-n命令进行测试</p>
<p>如：</p>
<h1 id="解压缩日志"><a href="#解压缩日志" class="headerlink" title="解压缩日志"></a>解压缩日志</h1><p>$ gzip -d a.gz<br>$ tar zcvf/jcvf one.tar.bz2 one</p>
<h1 id="直接查看压缩日志"><a href="#直接查看压缩日志" class="headerlink" title="直接查看压缩日志"></a>直接查看压缩日志</h1><p>$ less a.gz  </p>
<h1 id="无需先解压"><a href="#无需先解压" class="headerlink" title="无需先解压"></a>无需先解压</h1><p>另外，以z开头的几个命令可以简单处理gzip压缩文件, 如zcat：直接打印压缩文件，还有zgrep/zfgrep/zegrep，在压缩文件中直接查找。</p>
<h1 id="查询字符串，并显示匹配行的前3行和后3行内容"><a href="#查询字符串，并显示匹配行的前3行和后3行内容" class="headerlink" title="查询字符串，并显示匹配行的前3行和后3行内容"></a>查询字符串，并显示匹配行的前3行和后3行内容</h1><p>fgrep ‘yunjie-talk’ -A 3 -B 3 log.txt</p>
<h1 id="在当前目前-及子目录-下，所有的log文件中搜索字符串hacked-by"><a href="#在当前目前-及子目录-下，所有的log文件中搜索字符串hacked-by" class="headerlink" title="在当前目前(及子目录)下，所有的log文件中搜索字符串hacked by:"></a>在当前目前(及子目录)下，所有的log文件中搜索字符串hacked by:</h1><p>$ find . -name “*.log” | xargs fgrep “hacked by”</p>
<p>fgrep, grep, egrep的一些区别：</p>
<p>fgrep按字符串的本来意思完全匹配，里面的正则元字符当成普通字符解析， 如： fgrep “1.2.3.4″ 则只匹配ip地址： 1.2.3.4, 其中的.不会匹配任意字符。fgrep当然会比grep快多了。写起来又简单，不用转义。<br>grep只使用普通的一些正则，egrep或者grep -E使用扩展的正则，如</p>
<p>egrep “one|two”, 匹配one或者two<br>grep -E -v “.jpg|.png|.gif|.css|.js” log.txt |wc -l</p>
<p>查找所有来自日本的ip的请求，先把所有来源ip取出来，去重，找出日本的ip，放入文件japan.ip，再使用命令：</p>
<p>$ cat log.gz | gzip -d | fgrep -f japan.ip &gt; japan.log</p>
<p>对hive中导出的文件，替换01</p>
<p>cat 0000* | sed ‘s/x1/ /g’ &gt; log.txt<br>03 其它常用命令</p>
<p>如果文件编码是从windows上传过来的gb2312编码，需要处理成utf8的编码，或者某个日志被黑客后来修改过了，需要和原来的备份数据进行对比，这些工作都是需要数据工程师自己能熟悉的掌握。</p>
<p>假如日志文件是最近一年的请求日志，那么可能是按天或者按小时进行单独存放，此时如果只需要提取某些天（比如周末）的数据，很可能需要处理时间。</p>
<p>因此，下面的一些命令或者工具就很有用了：</p>
<p>date：命令行时间操作函数<br>sort/uniq：排序、去重、统计<br>comm：对两个排序文件进行按行比较（共同行、只出现在左边文件、只出现在右边文件）<br>diff：逐字符比较文件的异同，配合cdiff，类似于github的显示效果<br>curl/w3m/httpie：命令行下进行网络请求<br>iconv：文件编码转换，如：iconv -f GB2312 -t UTF8 1.csv &gt; 2.csv<br>seq：产生连续的序列，配合for循环使用</p>
<p>输出今天/昨天的日期字符串</p>
<p>$ date -d today +%Y%m%d<br>20160320<br>$ date -d yesterday +%Y%m%d<br>20160319</p>
<p>对unix秒的处理</p>
<h1 id="当前的时间"><a href="#当前的时间" class="headerlink" title="当前的时间"></a>当前的时间</h1><p>$ date +%s<br>1458484275<br>$date -d @1458484275<br>Sun Mar 20 22:31:15 CST 2016</p>
<p>两个文件a.txt, b.txt求只出现在a.txt中的数据：</p>
<h1 id="排序两个文件"><a href="#排序两个文件" class="headerlink" title="排序两个文件"></a>排序两个文件</h1><p>$ sort a.txt &gt; a.txt.sort<br>$ sort b.txt &gt; b.txt.sort</p>
<h1 id="求只出现在c-sh中的内容"><a href="#求只出现在c-sh中的内容" class="headerlink" title="求只出现在c.sh中的内容"></a>求只出现在c.sh中的内容</h1><p>$ comm -2 -3 a.txt.sort b.txt.sort</p>
<p>04 批量操作</p>
<p>对上面的文件进行了一番探索分析后，可能已经有一定的线索或者眉目了，需要更进一步的处理大量的文件或者字段了。此时的步骤也许是一个消耗时间的过程，也许是一个需要看缘分的过程。总之，可能需要综合上面的一些命令，并且对大量的日志进行处理。</p>
<p>这也是体现Shell更强大的一面——批量化的功能了。命令比图形界面的最大优势就是，只需熟悉了，就很容易实现批量化操作，将这些批量化的命令组合成一个文件，于是便产生了脚本。</p>
<p>批量化命令或者脚本，熟悉几个常用的流程控制，就能发挥出强大的性能：</p>
<p>if条件判断：</p>
<p>if [ -d ${base_d} ];<br>    then mkdir -p ${base_d};<br>fi</p>
<p>while循环：</p>
<p>while<br>do<br>    do_something;<br>done</p>
<p>for循环（用得很多）：</p>
<p>for x in *.log.gz;<br>do<br>    gzip -d ${x};<br>done</p>
<p>这几个条件判断与循环，也可以直接在命令行下使用，区别是多加几个分号隔开即可。</p>
<p>另外，执行长时间的任务，最好直接用nohup来操作。</p>
<p>生成过去8天的日期序列：</p>
<p>$for num in <code>seq 8 -1 1</code>;do dd=<code>date --date=&quot;${num} day ago&quot; +%Y%m%d</code>;echo ${dd};done<br>20160312<br>20160313<br>20160314<br>20160315<br>20160316<br>20160317<br>20160318<br>20160319</p>
<p>有目录和文件如下：</p>
<p>20160320 目录<br>    10.1.0.1_20160320<em>.log.gz   目录<br>        201603200000.log.gz          文件<br>        201603200010.log.gz          文件<br>    10.1.0.2_20160320</em>.log.gz   目录<br>        201603200000.log.gz         文件<br>        201603200010.log.gz         文件</p>
<p>需求：去掉目录中的*.log.gz，这样很容易让人误解为文件。 rename -n为测试，rename使用和sed相同的语法。</p>
<p>$ for d in 201603??;do echo ${d}; cd ${d}; rename -n ‘s/<em>.log.gz//‘ </em>.log.gz ; cd ..;done</p>
<p>测试完成后，使用rename不加-n为真正执行重命名操作。</p>
<p>05 结尾</p>
<p>这儿只是简单列举了一些数据分析或者数据处理相关的命令，只能算是Linux的Shell那博大精深的命令中的冰山一角。</p>
<p>但如果能把这些相关的命令融会贯通，并且能实际使用的话，也算是在数据极客之路上多走了一步。</p>
<p>从基础的文件查看到简单的统计，再到一些常用的探索性分析命令，其目的都只是为了更好的做数据分析与挖掘而已。能综合这些命令，并组合起来使用，将命令存放到文件，即产生了Shell脚本。Shell脚本本身也是一门强大的学问了，其中各个命令还有每个命令支持的参数，值得慢慢研究。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/数据工程师常用的-Shell-命令/" data-id="ciwohfw36002e0fcyvik25f28" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-awk" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/awk/" class="article-date">
  <time datetime="2016-12-12T08:21:51.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/awk/">awk</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div></pre></td><td class="code"><pre><div class="line">awk 数据流处理工具</div><div class="line"></div><div class="line">awk脚本结构</div><div class="line">awk &apos; BEGIN&#123; statements &#125; statements2 END&#123; statements &#125; &apos;</div><div class="line"></div><div class="line">工作方式</div><div class="line">1.执行begin中语句块；</div><div class="line">2.从文件或stdin中读入一行，然后执行statements2，重复这个过程，直到文件全部被读取完毕；</div><div class="line">3.执行end语句块；</div><div class="line"></div><div class="line">print 打印当前行</div><div class="line"></div><div class="line">使用不带参数的print时，会打印当前行;</div><div class="line"></div><div class="line">  echo -e &quot;line1\nline2&quot; | awk &apos;BEGIN&#123;print &quot;start&quot;&#125; &#123;print &#125; END&#123; print &quot;End&quot; &#125;&apos;</div><div class="line"></div><div class="line">print 以逗号分割时，参数以空格定界;</div><div class="line"></div><div class="line">echo | awk &apos; &#123;var1 = &quot;v1&quot; ; var2 = &quot;V2&quot;; var3=&quot;v3&quot;; \</div><div class="line">print var1, var2 , var3; &#125;&apos;</div><div class="line">$&gt;v1 V2 v3</div><div class="line"></div><div class="line">使用-拼接符的方式（&quot;&quot;作为拼接符）;</div><div class="line"></div><div class="line">echo | awk &apos; &#123;var1 = &quot;v1&quot; ; var2 = &quot;V2&quot;; var3=&quot;v3&quot;; \</div><div class="line">print var1&quot;-&quot;var2&quot;-&quot;var3; &#125;&apos;</div><div class="line">$&gt;v1-V2-v3</div><div class="line"></div><div class="line">特殊变量： NR NF $0 $1 $2</div><div class="line"></div><div class="line">NR:表示记录数量，在执行过程中对应当前行号；</div><div class="line">NF:表示字段数量，在执行过程总对应当前行的字段数；</div><div class="line">$0:这个变量包含执行过程中当前行的文本内容；</div><div class="line">$1:第一个字段的文本内容；</div><div class="line">$2:第二个字段的文本内容；</div><div class="line"></div><div class="line">echo -e &quot;line1 f2 f3\n line2 \n line 3&quot; | awk &apos;&#123;print NR&quot;:&quot;$0&quot;-&quot;$1&quot;-&quot;$2&#125;&apos;</div><div class="line"></div><div class="line">打印每一行的第二和第三个字段：</div><div class="line">  awk &apos;&#123;print $2, $3&#125;&apos; file</div><div class="line"></div><div class="line">统计文件的行数：</div><div class="line">  awk &apos; END &#123;print NR&#125;&apos; file</div><div class="line"></div><div class="line">累加每一行的第一个字段：</div><div class="line">  echo -e &quot;1\n 2\n 3\n 4\n&quot; | awk &apos;BEGIN&#123;num = 0 ;</div><div class="line">  print &quot;begin&quot;;&#125; &#123;sum += $1;&#125; END &#123;print &quot;==&quot;; print sum &#125;&apos;</div><div class="line"></div><div class="line">传递外部变量</div><div class="line"></div><div class="line">var=1000</div><div class="line">echo | awk &apos;&#123;print vara&#125;&apos; vara=$var #  输入来自stdin</div><div class="line">awk &apos;&#123;print vara&#125;&apos; vara=$var file # 输入来自文件</div><div class="line"></div><div class="line">用样式对awk处理的行进行过滤</div><div class="line"></div><div class="line">awk &apos;NR &lt; 5&apos; #行号小于5</div><div class="line">awk &apos;NR==1,NR==4 &#123;print&#125;&apos; file #行号等于1和4的打印出来</div><div class="line">awk &apos;/linux/&apos; #包含linux文本的行（可以用正则表达式来指定，超级强大）</div><div class="line">awk &apos;!/linux/&apos; #不包含linux文本的行</div><div class="line"></div><div class="line">设置定界符</div><div class="line"></div><div class="line">使用-F来设置定界符（默认为空格）</div><div class="line">awk -F: &apos;&#123;print $NF&#125;&apos; /etc/passwd</div><div class="line"></div><div class="line">读取命令输出</div><div class="line"></div><div class="line">使用getline，将外部shell命令的输出读入到变量cmdout中；</div><div class="line"></div><div class="line">echo | awk &apos;&#123;&quot;grep root /etc/passwd&quot; | getline cmdout; print cmdout &#125;&apos;</div><div class="line"></div><div class="line">在awk中使用循环</div><div class="line"></div><div class="line">for(i=0;i&lt;10;i++)&#123;print $i;&#125;</div><div class="line">for(i in array)&#123;print array[i];&#125;</div><div class="line"></div><div class="line">eg:</div><div class="line">以逆序的形式打印行：(tac命令的实现）</div><div class="line"></div><div class="line">seq 9| \</div><div class="line">awk &apos;&#123;lifo[NR] = $0; lno=NR&#125; \</div><div class="line">END&#123; for(;lno&gt;-1;lno--)&#123;print lifo[lno];&#125;</div><div class="line">&#125; &apos;</div><div class="line"></div><div class="line">awk实现head、tail命令</div><div class="line"></div><div class="line">head:</div><div class="line">  awk &apos;NR&lt;=10&#123;print&#125;&apos; filename</div><div class="line"></div><div class="line">tail:</div><div class="line">  awk &apos;&#123;buffer[NR%10] = $0;&#125; END&#123;for(i=0;i&lt;11;i++)&#123; \</div><div class="line">  print buffer[i %10]&#125; &#125; &apos; filename</div><div class="line"></div><div class="line">打印指定列</div><div class="line"></div><div class="line">awk方式实现：</div><div class="line">  ls -lrt | awk &apos;&#123;print $6&#125;&apos;</div><div class="line"></div><div class="line">cut方式实现</div><div class="line">  ls -lrt | cut -f6</div><div class="line"></div><div class="line">打印指定文本区域</div><div class="line"></div><div class="line">确定行号</div><div class="line">  seq 100| awk &apos;NR==4,NR==6&#123;print&#125;&apos;</div><div class="line"></div><div class="line">确定文本</div><div class="line">打印处于start_pattern 和end_pattern之间的文本；</div><div class="line">  awk &apos;/start_pattern/, /end_pattern/&apos; filename</div><div class="line"></div><div class="line">eg:</div><div class="line">seq 100 | awk &apos;/13/,/15/&apos;</div><div class="line">cat /etc/passwd| awk &apos;/mai.*mail/,/news.*news/&apos;</div><div class="line"></div><div class="line">awk常用内建函数</div><div class="line"></div><div class="line">index(string,search_string):返回search_string在string中出现的位置</div><div class="line">sub(regex,replacement_str,string):将正则匹配到的第一处内容替换为replacement_str;</div><div class="line">match(regex,string):检查正则表达式是否能够匹配字符串；</div><div class="line">length(string)：返回字符串长度</div><div class="line"></div><div class="line">echo | awk &apos;&#123;&quot;grep root /etc/passwd&quot; | getline cmdout; print length(cmdout) &#125;&apos;</div><div class="line"></div><div class="line">printf 类似c语言中的printf，对输出进行格式化</div><div class="line">eg：</div><div class="line"></div><div class="line">seq 10 | awk &apos;&#123;printf &quot;-&gt;%4s\n&quot;, $1&#125;&apos;</div><div class="line"></div><div class="line">迭代文件中的行、单词和字符</div><div class="line"></div><div class="line">1. 迭代文件中的每一行</div><div class="line"></div><div class="line">while 循环法</div><div class="line"></div><div class="line">while read line;</div><div class="line">do</div><div class="line">echo $line;</div><div class="line">done &lt; file.txt</div><div class="line"></div><div class="line">改成子shell:</div><div class="line">cat file.txt | (while read line;do echo $line;done)</div><div class="line"></div><div class="line">awk法：</div><div class="line">cat file.txt| awk &apos;&#123;print&#125;&apos;</div><div class="line"></div><div class="line">2.迭代一行中的每一个单词</div><div class="line"></div><div class="line">for word in $line;</div><div class="line">do</div><div class="line">echo $word;</div><div class="line">done</div><div class="line"></div><div class="line">3. 迭代每一个字符</div><div class="line"></div><div class="line">$&#123;string:start_pos:num_of_chars&#125;：从字符串中提取一个字符；(bash文本切片）</div><div class="line">$&#123;#word&#125;:返回变量word的长度</div><div class="line"></div><div class="line">for((i=0;i&lt;$&#123;#word&#125;;i++))</div><div class="line">do</div><div class="line">echo $&#123;word:i:1);</div><div class="line">done</div><div class="line"></div><div class="line">从格式化输出里提取一列(我最常使用的awk技巧)</div><div class="line"></div><div class="line">我几乎天天都会使用它。真的。经常会有一些输出，我只需要其中的第二列，或第三列，下面这个命令就能做到这些：</div><div class="line">#Sample output of git status -s command:</div><div class="line"></div><div class="line">$ git status -s</div><div class="line"></div><div class="line">M .bashrc</div><div class="line">?? .vim/bundle/extempore/</div><div class="line"></div><div class="line"># Remove status code from git status and just get the file names</div><div class="line">$ git status -s | awk &apos;&#123;print $2&#125;&apos;</div><div class="line"></div><div class="line">.bashrc</div><div class="line">.vim/bundle/extempore/</div><div class="line">为什么不写个函数，让我们随时都可以用呢？</div><div class="line">function col &#123;</div><div class="line">awk -v col=$1 &apos;&#123;print $col&#125;&apos;</div><div class="line">&#125;</div><div class="line">这使得提取列非常容易，比如，你不想要第一列？简单：</div><div class="line">$ git status -s | col 2</div><div class="line"></div><div class="line">.bashrc</div><div class="line">.vim/bundle/extempore/</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/awk/" data-id="ciwohfw1a000v0fcylcyzq2vv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-sed" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/sed/" class="article-date">
  <time datetime="2016-12-12T08:09:38.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/sed/">sed</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>sed 文本替换利器</p>
<p>用命令行往文件的顶部添加文字</p>
<p>每次我都会重新寻找这个命令的写法。下面就是如何使用sed往一个文件顶部添加一行的方法：<br>sed -i ‘1s/^/line to insert\n/‘ path/to/file/you/want/to/change.txt</p>
<p>首处替换<br>  seg ‘s/text/replace_text/‘ file   //替换每一行的第一处匹配的text</p>
<p>全局替换<br>   seg ‘s/text/replace_text/g’ file</p>
<p>默认替换后，输出替换后的内容，如果需要直接替换原文件,使用-i：<br>  seg -i ‘s/text/repalce_text/g’ file</p>
<p>移除空白行：<br>  sed ‘/^$/d’ file</p>
<p>变量转换<br>已匹配的字符串通过标记&amp;来引用.<br>echo this is en example | seg ‘s/\w+/[&amp;]/g’<br>$&gt;[this]  [is] [en] [example]</p>
<p>子串匹配标记<br>第一个匹配的括号内容使用标记 \1 来引用<br>  sed ‘s/hello([0-9])/\1/‘</p>
<p>双引号求值<br>sed通常用单引号来引用；也可使用双引号，使用双引号后，双引号会对表达式求值：<br>  sed ‘s/$var/HLLOE/‘</p>
<p>当使用双引号时，我们可以在sed样式和替换字符串中指定变量；<br>eg:<br>p=patten<br>r=replaced<br>echo “line con a patten” | sed “s/$p/$r/g”<br>$&gt;line con a replaced</p>
<p>其它示例<br>字符串插入字符：将文本中每行内容（PEKSHA） 转换为 PEK/SHA<br>  sed ‘s/^.{3}/&amp;\//g’ file</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/sed/" data-id="ciwohfw1u00160fcyofw5jm3k" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-umount" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/umount/" class="article-date">
  <time datetime="2016-12-12T08:09:03.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/umount/">umount</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原来umount 还有一个-l选项，作用是当需卸载文件系统的引用不繁忙时直接卸载：<br>umount -l directoryname</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/umount/" data-id="ciwohfw1z001c0fcyrtl9keon" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-uniq" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/uniq/" class="article-date">
  <time datetime="2016-12-12T08:07:25.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/uniq/">uniq</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>uniq 消除重复行</p>
<p>消除重复行<br>  sort unsort.txt | uniq</p>
<p>统计各行在文件中出现的次数<br>  sort unsort.txt | uniq -c</p>
<p>找出重复行<br>  sort unsort.txt | uniq -d</p>
<p>可指定每行中需要比较的重复内容：-s 开始位置 -w 比较字符数</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/uniq/" data-id="ciwohfw23001e0fcyfqww9s24" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-海量运维" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/海量运维/" class="article-date">
  <time datetime="2016-12-12T07:40:50.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/海量运维/">海量运维</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="海量运维\海量运维.jpg" alt="海量运维"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/海量运维/" data-id="ciwohfw38002i0fcyfvsyl052" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-结婚日狂想" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/结婚日狂想/" class="article-date">
  <time datetime="2016-12-12T07:26:38.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/结婚日狂想/">结婚日狂想</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>2013年1月4日<br>今天日子有些特殊，因为今天可以翻译成“爱你一生一世”。<br>除此之外，还有一则消息，哦，错了，不是消息是新闻，是让全世界瞩目的新闻。<br>是全球最大商业帝国，三元帝国集团的首席执行官兼董事长元和他最心爱的女人结婚的日子。<br>等等，最大商业帝国？还全球？三元帝国，从来没听说过啊！<br>哦，诸位莫急，待我来细细拆解。<br>三元帝国，乃是元创立，最惊人的就是这个集团能够在短短的三年之中，拥有了全球30%的财富，注意了这个30%不是民间资本。<br>这么举个例子吧，如果全世界所有的，不管是个人、单位、集团还是国家的财富加起来是100的话，那么三元帝国的财富就是30。明白了吧，除了几个大国外，其他的许多小国家都得仰仗在三元帝国的运作下生存。<br>那么这个集团是运营什么的呢？<br>这么说吧，上到宇宙飞船、航空母舰的研发，下到老百姓吃什么、穿什么，都是集团运营的项目。<br>集团的根是衣、食、住、行四大行业发展起来的。<br>那岂不是垄断啦，不得了啦！国家怎么不控制的。<br>原因有二：<br>一是元这个人可以和两千多年前的法圣商鞅一般，大公无私，绝不会做些坑蒙拐骗的事情，那都是低层次人弄的。<br>二是，说白点就是国家想管怎么管呢，你这个国家限制我，没关系啊，全世界那么多国家呢，还愁我活不下去啊！再说，现在国家相限制，也不敢了，因为这个集团有太多的投资，在国家建设上了，说白了，国家缺不得这个集团啊！<br>呵呵，扯远了。再次回到结婚的现场，哦不对，不是现场因为这次结婚典礼，在全世界188个国家，都同时举行。<br>路线是中国的泰兴、上海、南京、北京、成都、拉萨……<br>抵达中亚，北上俄罗斯，到欧洲，南赴非洲<br>跨大西洋，至加拿大，后抵美利坚，再去拉美<br>回转太平洋，飞澳洲，渡印度洋，到南亚、东南亚<br>归中国泰兴<br>泰兴是三元帝国的总部，2013年已经是全球最大城市、最富城市、最人文城市、最美城市、最舒适城市，能够成为泰兴市民的，不是国家政要，就是国际名流，当然还有土生土长的泰兴人，他们是最幸福的，出生以来的抚养、教育、一直到成人，不要父母掏一分钱，享受着全世界最高档的教育，不管是谁，都有一种教育方式，让他成才，这是元上初三的时候化学老师告诉他的。<br>2013年1月4日上午9时<br>来自于全世界各国首脑和名流们都齐聚泰兴，中国34个省长及主席、常委们，都早早来到了泰兴，各大媒体，早就瞄准了这次机会。<br>准确的说，这是有人类以来，最大的聚会，前无古人，后有没有来者，咱们就不讨论了。<br>地点位于三元帝国的总部大楼，除了高达666米外，往地下也是333米，所以高度为999米，面积为81平方公里。<br>所以虽然人数达到了30万以上，可以并不显得拥挤。<br>“安全呢，要知道奥运会，安检可是很严格的啊，那时候可没有这么多重要人士，现在可是异常危险的时刻啊！”一个人问道。<br>旁边的人就像看到一个白痴一样的看着他，极为兴奋的说道：“放心吧！兄台，到其他地方我不敢保证，可是如果你到了三元帝国的总部，还存在这个想法的话，就是杞人忧天了。”<br>“为啥？”显然问的人没有得到满意的答案。<br>“为啥？除了这栋大楼，是全世界最先进的技术，花费一年时间，不分昼夜的建设，动用了整整10万人，投资了共1000万亿外，你以为三元帝国能在短短三年内，成为全球最大的集团是侥幸的吗？因为三元帝国有支秘密的保安部队，其实称他们是保安，实在是委屈他们了啊！就是美国的CIA，英国的军情六处，我国的安全局所有人都来，都不是他们的对手。”<br>三元帝国果然不同凡响啊！问的人感慨道。<br>元出场了，竟然不是穿的职业装，而是汉服，不过是改良过的服装，可是一眼还是能够看出来，这就是汉服。<br>元的声音通过音响系统清晰的传送到了每个宾客的耳中：“多谢大家的光临，我结婚的大喜日子，趁今天大家都在的情况下，我就宣布一件事，一周之后，所有集团的员工，必须穿着我身上的服装，这是我华夏民族的汉服，因为三元帝国首先属于华夏，其次属于我，所以全世界，只要在我集团工作的员工，都必须穿着汉服，公司服装已经准备齐全，一周后大家准时穿上，如果不愿意穿着的人，那只能很抱歉，我们的合作结束了。”<br>话音刚落，全场都沸腾起来，这个决定也太过了吧，就连中国人自己都感觉到，这个要求苛刻了。当然中国人，自今之后，全国都得穿着汉服，这是毫无疑问的。<br>可是，集团工作的一共三亿六千万人，中国人有两亿，可是剩下还有一亿六千万呢？<br>那有能怎么办呢，毕竟在集团工作各种条件实在太优厚了，有几个人为了所谓的服饰，而放弃如此优越的生活呢。<br>元的声音再次响起，全场立刻寂然无声：“好，既然公事已然说完，下面就进入正事吧！”<br>这一幕将永载史册，全世界共180个国家的主席、总统、国王、总理……为元进行了证婚，只见元和他的妻子，走过了两旁侍立180个国家的首脑中间的红地毯，结束了仪式。<br>今天所有的结婚，没有结婚的总之几乎所有的女人，见到这一幕时，都羡慕无比，没有人嫉妒，因为她们都知道，元的妻子的伟大，这种伟大，让绝大多数女人都汗颜。就是剩下那堆人，也不过与元的妻子持平而已。<br>仪式结束了，大家都回到了自己的座位上。<br>下面的一幕又掀起了另一个高潮，全世界最巨大的商业帝国三元帝国集团的首席执行官兼任董事长的元，朝一个方位跪了下去，这个跪的方向立刻引起了全场乃至全世界的关注，只见两个面容慈祥的老人，端坐于高台座位上。<br>当两个老人得知，下面坐的有国家主席和总理时，身体颤巍巍的站了起来，老爷子说道：“儿啊，今天有这样的成就，都是你自己的努力，我们父母二人对不起你啊！”<br>元含泪痛哭道：“爸、妈，儿子怎么敢这么想，没有你们的生养之恩，我哪来这等成就，所以我这辈子最大的恩人就是你们，你们的幸福，才是我一切的源泉。”<br>第二天各大媒体的大标题几乎都是“婚礼之大无出其右，孝道之尽难赶其元。”</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/结婚日狂想/" data-id="ciwohfw3d002o0fcy2ni5lqpm" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-离职之美" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/离职之美/" class="article-date">
  <time datetime="2016-12-12T07:26:08.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/离职之美/">离职之美</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>经过了数天的内心挣扎，于今日请辞了。</p>
<p>请辞了，表明了经济之源断绝了，难以生存了。</p>
<p>还记得一位大师说过：“半杯水，在乐观人眼中，会欣喜，因为还有半杯呢！而在悲观人眼里，会沮丧，因为只剩下半杯了。”其实，半杯水没有变，变的是人的心。</p>
<p>我不敢说，自己是那乐观的人，但肯定不属于悲观者。</p>
<p>要知道，人能够来到这个世间，是多么的不容易，何至于数千万分之一的概率。既然这么的不容易，那干嘛不轰轰烈烈做一番自己的事业呢，何必人云亦云，鹦鹉学舌呢？</p>
<p>看到听到很多事故的发生，感慨道人的生命原来如此的脆弱，生死只是眨眼之间，如果在离别的那一刻，对自己的一生生出遗憾，那么是多么可悲的事啊！</p>
<p>故离职对我来说，是破而后立之美，是蛹化蝶之美，是实现自己梦想之美。</p>
<p>古往今来，凡变革者，都是打破旧的东西，建立新的东西，过程好像如此的简单，可是打破旧的时候，多少腥风血雨，多少江湖仇杀，多少强敌环伺，一个不小心，便陷入万劫不复之境地。</p>
<p>就说离我们近的，清末“戊戌变法”吧，又称作“百日维新”，戊戌六君子的慷慨就义，谭嗣同的那句“我自横刀向天笑，去留肝胆两昆仑”还萦绕在我的耳边，多么的惨烈啊！可是逝去的人，并没有后悔，没有遗憾，因为他们践行了自己的梦想，成仁取义，必将名垂千古。</p>
<p>还有两千多年前的“商鞅变法”，商鞅一人入秦，使地处边陲、贫弱的秦国在二十年里成为战时强国，为后来秦始皇统一全国，奠定了坚实的基础。</p>
<p>虽然商鞅因为触犯了元老世族的利益，而被“车裂”，可是秦法却留了下来，继续指引着大秦帝国的前进方向。可以说明，商鞅就义之时，了无遗憾，还是因为他实现了自己的梦想，实现了他来到这个世间的使命。</p>
<p>上述二人，都是牺牲了自己的性命，来换取了自己的梦想，可以算是极致了吧！</p>
<p>而我呢，不过是一时断绝自己的经济来源，与他们相比，实在是微不足道。</p>
<p>古语有云：“欲取之，必先予之。”就是说，不管做任何事，都要付出代价，这份代价可以寓指各种事物，譬如：时间、自由、舒适甚至于生命。</p>
<p>2011-6-28</p>
<p>仁佳作于宁</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/离职之美/" data-id="ciwohfw3c002m0fcy92v5evkb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-父亲之我识" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/父亲之我识/" class="article-date">
  <time datetime="2016-12-12T07:25:38.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/父亲之我识/">父亲之我识</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1986年的夏天</p>
<p>我出生了，现在想来那一年，甚是模糊。</p>
<p>听我母亲说，就是那年采用了夏令时。所谓夏令时，就是将现有时间向后推迟一小时，但后来由于用来十分麻烦，遂又弃而不用了。</p>
<p>听我母亲说，我的父亲小时候异常贫苦。</p>
<p>在我父亲三岁的时候，我的爷爷就去世了，后来我的奶奶改嫁，父亲也跟着去了。就有了父亲的同母异父的弟弟，也就是我的叔叔。</p>
<p>父亲很小的时候，就干着沉重的家务活，生活异常的艰辛，我听母亲缓缓道来，心中悲苦异常，联想到了我现在的生活，虽然苦，可是和我父亲的童年一比，简直有天壤之别啊！暗自恨道：自己还这么的不知足，实在是不孝啊！</p>
<p>父亲12岁的时候，就远赴他乡了，听说到了香港，但是被遣返了回来。到了福建省，就呆了整整十年。</p>
<p>就是现在还看到了父亲那些年所写的日记，大多是爱党爱国主题的，我不禁感叹道父辈们那时候如此的淳朴。</p>
<p>经过我姨奶奶的介绍，我父亲和母亲相识了，结婚的第二年生了个女儿，可是不幸夭折了，父母亲自然是悲痛异常啊。</p>
<p>又三年，也就是86年，我出生了。现在听我母亲谈起当年的女儿，我也是异常悲痛，我多么希望有个姐姐啊！</p>
<p>我上学了，终于有了对父亲那清晰的记忆。</p>
<p>记得父亲给我天天讲故事，还时常买连环画给我，我想对历史的爱好，那个时候就已经萌芽了吧！</p>
<p>父亲经常带我去看电影，去公园、去好多好玩的地方。</p>
<p>记忆最深刻的就是，因为那时候家里并不富裕，一周也只能吃到两次肉吧！可是父亲都让给了我，还买糖浆的营养品给我。</p>
<p>现在回想起来，父亲实在是很伟大啊，在我心目中就如同山岳般为家人遮风挡雨。</p>
<p>我上中学时，母亲因工受伤，卧在床上，是父亲倾心照顾、让母亲很快的康复了，我想这就是所谓的爱情的真谛吧，在平平淡淡的生活中，得到了升华。</p>
<p>到了我上大学的时候，家里翻盖新房，父亲那挥汗如雨的身影一直在我脑海之中挥之不去。</p>
<p>可是等新房盖好后，父亲一心想把欠的债务所还清，毅然踏上了去广东的火车，刚开始还不怎么觉察，可是过了段时间，刚好到了我的暑假。</p>
<p>发生了一件，我至今想起都面如土色的一件事。</p>
<p>听亲戚朋友、周围邻居说父亲被传销骗了去，当时的母亲顿时就吓得卧床不起，我也是猛然失色。</p>
<p>接下来的一段时间，就是不断和父亲联络，而家里和亲戚们不断奔走，大约一周后，回来的音信还是没有，我带着无精打采的母亲去找一个常年在外奔走的舅舅，希望他能够亲赴广东，接我的父亲回来。</p>
<p>看着母亲那番模样，我向我的舅舅跪了下来，心里的那股压抑的情感随着这一跪都喷发了出来，舅舅也被我的举动吓了一跳，遂答应了下来。</p>
<p>如此又过了大约两三天，舅舅已经到了广州火车站，利用了他在那里的各种关系，终于将我最敬爱的父亲从传销的魔窟中解救了出来，当天下午，至今那一幕都深深的印在了我的脑海深处。</p>
<p>父亲头顶行李，面带笑容，走入家门，当时的我是喜极而泣，母亲是精神振奋，家里摆了好几桌，就是为了庆贺父亲的归来。</p>
<p>那如同梦魇的11天，就这样过去了。</p>
<p>之后的日子，家里人都一致不让父亲外出了。</p>
<p>心有余悸啊！</p>
<p>可是也许是房子风水问题吧，我大三那年的过年，本来是出去拜年的，晚上回家时候，我父亲载着母亲，发生了车祸，父亲满脸都是血啊！</p>
<p>我看着大惊失色，立刻联系了村里的医生，经过诊断，还好就是外伤，父亲就这样躺了半个月，又出去做生活了（家乡话工作）。</p>
<p>父亲的经历太过惨痛了，我只恨自己没用，还让父母如此大的年纪还在外面奔波忙碌，惭愧不已啊！</p>
<p>可是好像老天似乎和我家作对般，就在两周前，父亲从脚手架上掉落下来，直接住到了医院。</p>
<p>我听到了这个消息，如同晴天霹雳般，当晚的我，没有任何睡意。</p>
<p>乘着第二天最早的一班车我就直接回到家里，去市医院前去看望了我这个辛苦劳累的老父亲，我的心在滴血啊。</p>
<p>我一直在问为什么，到底是为什么，该死的老天，为何如此对待我的父亲，就是要考验，就来考验我吧，何必针对我的父亲呢？</p>
<p>看来上天是不想让我平平淡淡走过这一生啊，这其实变相的告诉我，如果你再这样的过的平平凡凡的，那这样的事还会发生。</p>
<p>为了父母，为了梦想，为了活着。</p>
<p>我不能再这样下去了。</p>
<p>辛卯年丙申月丁未日</p>
<p>二〇一一年八月二十日星期六</p>
<p>仁佳</p>
<p>搁笔于金陵</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/父亲之我识/" data-id="ciwohfw39002j0fcyf0xknoee" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/6/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/8/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/14/CentOS-6-x-GoAccess/">CentOS 6.x GoAccess</a>
          </li>
        
          <li>
            <a href="/2016/12/14/CentOS-6-x-Logrotate/">CentOS 6.x Logrotate</a>
          </li>
        
          <li>
            <a href="/2016/12/14/CentOS-6-x-Docker-Swarm-Etcd-Cluster/">CentOS 6.x Docker + Swarm + Etcd Cluster</a>
          </li>
        
          <li>
            <a href="/2016/12/14/Ubuntu-14-04-Docker/">Ubuntu 14.04 Docker</a>
          </li>
        
          <li>
            <a href="/2016/12/14/CentOS-6-x-CAT/">CentOS 6.x CAT</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 JinYan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>