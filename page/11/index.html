<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>SanYuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="SanYuan">
<meta property="og:url" content="http://yoursite.com/page/11/index.html">
<meta property="og:site_name" content="SanYuan">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SanYuan">
  
    <link rel="alternate" href="/atom.xml" title="SanYuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SanYuan</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Bashmarks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/Bashmarks/" class="article-date">
  <time datetime="2016-12-12T09:19:35.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/Bashmarks/">Bashmarks</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>你还没有在.bashrc里使用bashmarks吗？还在等待什么？它真的非常有用。它能帮你保持历史操作，跳回到你经常使用的目录。下面是我的配置文件里脚本，但我想上面的链接能提供你更多技巧：</p>
<h1 id="USAGE"><a href="#USAGE" class="headerlink" title="USAGE:"></a>USAGE:</h1><h1 id="s-bookmarkname-saves-the-curr-dir-as-bookmarkname"><a href="#s-bookmarkname-saves-the-curr-dir-as-bookmarkname" class="headerlink" title="s bookmarkname - saves the curr dir as bookmarkname"></a>s bookmarkname - saves the curr dir as bookmarkname</h1><h1 id="g-bookmarkname-jumps-to-the-that-bookmark"><a href="#g-bookmarkname-jumps-to-the-that-bookmark" class="headerlink" title="g bookmarkname - jumps to the that bookmark"></a>g bookmarkname - jumps to the that bookmark</h1><h1 id="g-b-TAB-tab-completion-is-available"><a href="#g-b-TAB-tab-completion-is-available" class="headerlink" title="g b[TAB] - tab completion is available"></a>g b[TAB] - tab completion is available</h1><h1 id="l-list-all-bookmarks"><a href="#l-list-all-bookmarks" class="headerlink" title="l - list all bookmarks"></a>l - list all bookmarks</h1><h1 id="save-current-directory-to-bookmarks"><a href="#save-current-directory-to-bookmarks" class="headerlink" title="save current directory to bookmarks"></a>save current directory to bookmarks</h1><p>touch ~/.sdirs<br>function s {<br>cat ~/.sdirs | grep -v “export DIR<em>$1=” &gt; ~/.sdirs1<br>mv ~/.sdirs1 ~/.sdirs<br>echo “export DIR</em>$1=$PWD” &gt;&gt; ~/.sdirs<br>}</p>
<h1 id="jump-to-bookmark"><a href="#jump-to-bookmark" class="headerlink" title="jump to bookmark"></a>jump to bookmark</h1><p>function g {<br>source ~/.sdirs<br>cd $(eval $(echo echo $(echo \$DIR_$1)))<br>}</p>
<h1 id="list-bookmarks-with-dirnam"><a href="#list-bookmarks-with-dirnam" class="headerlink" title="list bookmarks with dirnam"></a>list bookmarks with dirnam</h1><p>function l {<br>source ~/.sdirs<br>env | grep “^DIR_” | cut -c5- | grep “^.*=”<br>}</p>
<h1 id="list-bookmarks-without-dirname"><a href="#list-bookmarks-without-dirname" class="headerlink" title="list bookmarks without dirname"></a>list bookmarks without dirname</h1><p>function <em>l {<br>source ~/.sdirs<br>env | grep “^DIR</em>“ | cut -c5- | grep “^.*=” | cut -f1 -d “=”<br>}</p>
<h1 id="completion-command-for-g"><a href="#completion-command-for-g" class="headerlink" title="completion command for g"></a>completion command for g</h1><p>function _gcomp {<br>local curw<br>COMPREPLY=()<br>curw=${COMP_WORDS[COMP_CWORD]}<br>COMPREPLY=($(compgen -W ‘<code>_l</code>‘ – $curw))<br>return 0<br>}</p>
<h1 id="bind-completion-command-for-g-to-gcomp"><a href="#bind-completion-command-for-g-to-gcomp" class="headerlink" title="bind completion command for g to _gcomp"></a>bind completion command for g to _gcomp</h1><p>complete -F _gcomp g</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/Bashmarks/" data-id="ciwpxfwf400014zcyi0xjsem0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-使用Linux命令行测试网速" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/使用Linux命令行测试网速/" class="article-date">
  <time datetime="2016-12-12T09:17:25.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/使用Linux命令行测试网速/">使用Linux命令行测试网速</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>当发现上网速度变慢时，人们通常会先首先测试自己的电脑到网络服务提供商（通常被称为“最后一公里”）的网络连接速度。在可用于测试宽带速度的网站中，Speedtest.net也许是使用最广泛的。</p>
<p>Speedtest.net的工作原理并不复杂：它在你的浏览器中加载JavaScript代码并自动检测离你最近的Speedtest.net服务器，然后向服务器发送HTTP GET and POST请求来测试上行/下行网速。</p>
<p>但在没有图形化桌面时（例如，当你通过命令行远程登陆服务器或使用没有图形界面的操作系统），基于flash、界面友好的Speedtest.net将无法工作。幸运的是，Speedtest.net提供了一个命令行版本——speedtest-cli。下面我将向你演示如何在Linux的命令行中使用speedtest-cli来测试宽带连接速度。</p>
<p>安装speedtest-cli</p>
<p>speedtest-cli是一个用Python编写的轻量级Linux命令行工具，在Python2.4至3.4版本下均可运行。它基于Speedtest.net的基础架构来测量网络的上/下行速率。安装speedtest-cli很简单——只需要下载其Python脚本文件。</p>
<p>$ wget <a href="https://raw.github.com/sivel/speedtest-cli/master/speedtest_cli.py" target="_blank" rel="external">https://raw.github.com/sivel/speedtest-cli/master/speedtest_cli.py</a><br>$ chmod a+rx speedtest_cli.py<br>$ sudo mv speedtest_cli.py /usr/local/bin/speedtest-cli<br>$ sudo chown root:root /usr/local/bin/speedtest-cli</p>
<p>使用speedtest-cli测试网速</p>
<p>使用speedtest-cli命令也很简单，它不需要任何参数即可工作。</p>
<p>$ speedtest-cli</p>
<p>输入这个命令后，它会自动发现离你最近的Speedtest.net服务器（地理距离），然后打印出测试的网络上/下行速率。</p>
<p>如果你愿意分享测试结果，你可以使用参数“–share”。它将会把你的测试结果上传到Speedtest.net服务器并以图形的方式分享给其他人。</p>
<p>下面是一幅由speedtest-cli自动生成并上传到Speedtest.net的测试结果：</p>
<p>如果你对目前所有可用的Speedtest.net服务器感兴趣，你可以使用参数“–list”。它会打印出所有的Speedtest.net服务器（按照离你的地理距离由近及远排序）。</p>
<p>在上面的列表中，每个服务器的前面都有一个与其对应的ID。如果想使用指定的服务器来测试你的网速，你只需要在speedtest-cli命令后指定其ID即可。例如，如果想使用在Washington DC的服务器，你只需要指定相对应的服务器ID（如935）。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/使用Linux命令行测试网速/" data-id="ciwpxfwiq002u4zcy5mlv8zte" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-给rm命令加上回收站功能" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/给rm命令加上回收站功能/" class="article-date">
  <time datetime="2016-12-12T09:11:01.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/给rm命令加上回收站功能/">给rm命令加上回收站功能</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>给rm命令加上回收站功能</p>
<p>背景：<br>在群里，总会有人聊到曾经做过的最坑的事情，其中当然少不了rm命令，比如最出名的rm -rf /*命令。<br>受HDFS回收站机制的启发，我即兴的写了一个shell脚本来实现类似的功能。</p>
<p>具体配置：<br>[dong@localhost ~]$ sudo touch /usr/bin/delete<br>[dong@localhost ~]$ sudo chmod +x /usr/bin/delete<br>[dong@localhost ~]$ sudo vim /usr/bin/delete</p>
<p>#!/bin/bash</p>
<p>trash_dir=${HOME}/.Trash/$(date +%Y%m%d%H%M%S)</p>
<p>function move_item(){<br>  item=$1<br>  full_path=$2<br>  full_dir=$(dirname ${full_path})<br>  mkdir -p ${trash_dir}${full_dir}<br>  mv ${item} ${trash_dir}${full_path}<br>  if [[ $? -eq 0 ]]; then<br>    echo “Moved ${item} to ${trash_dir}${full_path}”<br>  fi<br>}</p>
<p>if [[ $# -eq 0 ]] || $(echo “$1” |grep -Ewq ‘-h|--help’); then<br>  echo “${0} [-f] [*|FILE]”<br>  exit 2<br>fi</p>
<p>for item in $@; do<br>  if $(echo ${item} |grep -vq ‘^-‘); then<br>    if $(echo ${item} |grep -q ‘^/‘); then<br>      full_path=${item}<br>    else<br>      full_path=$(pwd)/${item}<br>    fi<br>    if $(echo $@ |grep -Ewq ‘-f|-rf|-fr’); then<br>      move_item ${item} ${full_path}<br>    else<br>      echo -n “Move ${item} to ${trash_dir}${full_path}? [y/n] “<br>      read yorn<br>      if $(echo ${yorn} |grep -Ewq ‘y|Y|yes|YES’); then<br>        move_item ${item} ${full_path}<br>      fi<br>    fi<br>  fi<br>done</p>
<p>#!/bin/bash</p>
<p>trash_dir=${HOME}/.Trash/$(date +%Y%m%d%H%M%S)</p>
<p>function move_item(){<br>  item=$1<br>  full_path=$2<br>  full_dir=$(dirname ${full_path})<br>  mkdir -p ${trash_dir}${full_dir}<br>  mv ${item} ${trash_dir}${full_path}<br>  if [[ $? -eq 0 ]]; then<br>    echo “Moved ${item} to ${trash_dir}${full_path}”<br>  fi<br>}</p>
<p>if [[ $# -eq 0 ]] || $(echo “$1” |grep -Ewq ‘-h|--help’); then<br>  echo “${0} [-f] [*|FILE]”<br>  exit 2<br>fi</p>
<p>for item in $@; do<br>  if $(echo ${item} |grep -vq ‘^-‘); then<br>    if $(echo ${item} |grep -q ‘^/‘); then<br>      full_path=${item}<br>    else<br>      full_path=$(pwd)/${item}<br>    fi<br>    if $(echo $@ |grep -Ewq ‘-f|-rf|-fr’); then<br>      move_item ${item} ${full_path}<br>    else<br>      echo -n “Move ${item} to ${trash_dir}${full_path}? [y/n] “<br>      read yorn<br>      if $(echo ${yorn} |grep -Ewq ‘y|Y|yes|YES’); then<br>        move_item ${item} ${full_path}<br>      fi<br>    fi<br>  fi<br>done<br>[dong@localhost ~]$ mkdir tmp<br>[dong@localhost ~]$ cd tmp<br>[dong@localhost tmp]$ mkdir 1 2 3<br>[dong@localhost tmp]$ echo 1 &gt; 1/1.txt<br>[dong@localhost tmp]$ echo 2 &gt; 2/2.txt<br>[dong@localhost tmp]$ echo 3 &gt; 3/3.txt<br>[dong@localhost tmp]$ touch a b c<br>[dong@localhost tmp]$ ln -s a d<br>[dong@localhost tmp]$ delete 1</p>
<p>1<br>Move 1 to /home/dong/.Trash/20160415114210/home/dong/tmp/1? [y/n] y<br>2<br>Moved 1 to /home/dong/.Trash/20160415114210/home/dong/tmp/1<br>[dong@localhost tmp]$ delete -f *</p>
<p>1<br>Moved 2 to /home/dong/.Trash/20160415114217/home/dong/tmp/2<br>2<br>Moved 3 to /home/dong/.Trash/20160415114217/home/dong/tmp/3<br>3<br>Moved a to /home/dong/.Trash/20160415114217/home/dong/tmp/a<br>4<br>Moved b to /home/dong/.Trash/20160415114217/home/dong/tmp/b<br>5<br>Moved c to /home/dong/.Trash/20160415114217/home/dong/tmp/c<br>6<br>Moved d to /home/dong/.Trash/20160415114217/home/dong/tmp/d<br>move, rm</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/给rm命令加上回收站功能/" data-id="ciwpxfwjn003x4zcybqz7bfbd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-linux的ulimit各种限制之深入分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/linux的ulimit各种限制之深入分析/" class="article-date">
  <time datetime="2016-12-12T09:09:27.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/linux的ulimit各种限制之深入分析/">linux的ulimit各种限制之深入分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一般可以通过ulimit命令或编辑/etc/security/limits.conf重新加载的方式使之生效</p>
<p>通过ulimit比较直接,但只在当前的session有效,limits.conf中可以根据用户和限制项使用户在下次登录中生效.</p>
<p>对于limits.conf的设定是通过pam_limits.so的加载生效的,比如/etc/pam.d/sshd,这样通过ssh登录时会加载limit.<br>又或者在/etc/pam.d/login加载生效.</p>
<p>下面将对各种限制进行分析</p>
<p>core file size          (blocks, -c) 0<br>data seg size           (kbytes, -d) unlimited<br>scheduling priority             (-e) 20 a<br>file size               (blocks, -f) unlimited a<br>pending signals                 (-i) 16382<br>max locked memory       (kbytes, -l) 64 a<br>max memory size         (kbytes, -m) unlimited a<br>open files                      (-n) 1024 a<br>pipe size            (512 bytes, -p) 8<br>POSIX message queues     (bytes, -q) 819200<br>real-time priority              (-r) 0<br>stack size              (kbytes, -s) 8192<br>cpu time               (seconds, -t) unlimited<br>max user processes              (-u) unlimited<br>virtual memory          (kbytes, -v) unlimited<br>file locks                      (-x) unlimited</p>
<p>一)限制进程产生的文件大小(file size)</p>
<p>先来说说ulimit的硬限制和软限制<br>硬限制用-H参数,软限制用-S参数.<br>ulimit -a看到的是软限制,通过ulimit -a -H可以看到硬限制.<br>如果ulimit不限定使用-H或-S,此时它会同时把两类限制都改掉的.<br>软限制可以限制用户/组对资源的使用,硬限制的作用是控制软限制.<br>超级用户和普通用户都可以扩大硬限制,但超级用户可以缩小硬限制,普通用户则不能缩小硬限制.<br>硬限制设定后,设定软限制时只能是小于或等于硬限制.</p>
<p>下面的测试应用于硬限制和软限制.</p>
<p>1)软限制不能超过硬限制<br>在超级用户下,同时修改硬/软限制,使当前会话只能建100KB的文件<br>ulimit -f 100</p>
<p>查看当前创建文件大小的硬限制为100KB<br>ulimit -H -f<br>100</p>
<p>此时限制当前会话的软限制为1000KB,出现不能修改的报错<br>ulimit -S -f 1000<br>-bash: ulimit: file size: cannot modify limit: Invalid argument</p>
<p>2)硬限制不能小于软限制<br>在超级用户下,用户查看当前的软限制,此时为unlmiited<br>ulimit -S -f<br>unlimited</p>
<p>此时修改当前会话创建文件大小的硬限制为1000KB,出现不能修改的报错,说明硬限制不能小于软限制<br>ulimit -H -f 1000<br>-bash: ulimit: file size: cannot modify limit: Invalid argument</p>
<p>如果我们把创建文件大小的软限制改为900KB,此后就可以修改它的硬限制了<br>ulimit -S -f 900<br>ulimit -H -f 1000</p>
<p>3)普通用户只能缩小硬限制,超级用户可以扩大硬限制</p>
<p>用普通用户进入系统<br>su – test</p>
<p>查看创建文件大小的硬限制<br>ulimit -H -f<br>unlimited</p>
<p>此时可以缩小该硬限制<br>ulimit -H -f 1000</p>
<p>但不能扩大该硬限制<br>ulimit -H -f 10000</p>
<p>4)硬限制控制软限制,软限制来限制用户对资源的使用</p>
<p>用软限制限制创建文件的大小为1000KB<br>ulimit -S -f 1000</p>
<p>用硬限制限制创建文件的大小为2000KB<br>ulimit -H -f 2000</p>
<p>创建3MB大小的文件<br>dd if=/dev/zero of=/tmp/test bs=3M count=1<br>File size limit exceeded</p>
<p>查看/tmp/test的大小为1000KB,说明软限制对资源的控制是起决定性作用的.<br>ls -lh /tmp/test<br>-rw-r–r– 1 root root 1000K 2010-10-15 23:04 /tmp/test</p>
<p>file size单位是KB.</p>
<p>二)关于进程优先级的限制(scheduling priority)<br>这里的优先级指NICE值<br>这个值只对普通用户起作用,对超级用户不起作用,这个问题是由于CAP_SYS_NICE造成的.<br>例如调整普通用户可以使用的nice值为-10到20之间.<br>硬限制nice的限制为-15到20之间.<br>ulimit -H -e 35</p>
<p>软限制nice的限制为-10到20之间<br>ulimit -S -e 30</p>
<p>用nice命令,使执行ls的nice值为-10<br>nice -n -10 ls /tmp<br>ssh-BossiP2810  ssh-KITFTp2620  ssh-vIQDXV3333</p>
<p>用nice命令,使执行ls的nice值为-11,此时超过了ulimit对nice的软限制,出现了异常.<br>nice -n -11 ls /tmp<br>nice: cannot set niceness: Permission denied</p>
<p>三)内存锁定值的限制(max locked memory)<br>这个值只对普通用户起作用,对超级用户不起作用,这个问题是由于CAP_IPC_LOCK造成的.<br>linux对内存是分页管理的,这意味着有不需要时,在物理内存的数据会被换到交换区或磁盘上.<br>有需要时会被交换到物理内存,而将数据锁定到物理内存可以避免数据的换入/换出.<br>采用锁定内存有两个理由:<br>1)由于程序设计上需要,比如oracle等软件,就需要将数据锁定到物理内存.<br>2)主要是安全上的需要,比如用户名和密码等等,被交换到swap或磁盘,有泄密的可能,所以一直将其锁定到物理内存.</p>
<p>锁定内存的动作由mlock()函数来完成<br>mlock的原型如下:<br>int mlock(const void *addr,size_t len);</p>
<p>测试程序如下:</p>
<p>#include <stdio.h></stdio.h></p>
<p>#include <sys mman.h=""></sys></p>
<p>int main(int argc, char* argv[])<br>{<br>        int array[2048];</p>
<pre><code>if (mlock((const void *)array, sizeof(array)) == -1) {
        perror(&quot;mlock: &quot;);
        return -1;
}

printf(&quot;success to lock stack mem at: %p, len=%zdn&quot;,
                array, sizeof(array));

if (munlock((const void *)array, sizeof(array)) == -1) {
        perror(&quot;munlock: &quot;);
        return -1;
}

printf(&quot;success to unlock stack mem at: %p, len=%zdn&quot;,
                array, sizeof(array));

return 0;
</code></pre><p>}</p>
<p>gcc mlock_test.c -o mlock_test</p>
<p>上面这个程序,锁定2KB的数据到物理内存中,我们调整ulimit的max locked memory.<br>ulimit -H -l 4<br>ulimit -S -l 1<br>./mlock_test<br>mlock: : Cannot allocate memory</p>
<p>我们放大max locked memory的限制到4KB,可以执行上面的程序了.<br>ulimit -S -l 4<br>./mlock_test<br>success to lock stack mem at: 0x7fff1f039500, len=2048<br>success to unlock stack mem at: 0x7fff1f039500, len=2048</p>
<p>注意:如果调整到3KB也不能执行上面的程序,原因是除了这段代码外,我们还会用其它动态链接库.</p>
<p>四)进程打开文件的限制(open files)</p>
<p>这个值针对所有用户,表示可以在进程中打开的文件数.</p>
<p>例如我们将open files的值改为3<br>ulimit -n 3</p>
<p>此时打开/etc/passwd文件时失败了.<br>cat /etc/passwd<br>-bash: start_pipeline: pgrp pipe: Too many open files<br>-bash: /bin/cat: Too many open files</p>
<p>五)信号可以被挂起的最大数(pending signals)</p>
<p>这个值针对所有用户,表示可以被挂起/阻塞的最大信号数量</p>
<p>我们用以下的程序进行测试,源程序如下:</p>
<p>#include <stdio.h></stdio.h></p>
<p>#include <string.h></string.h></p>
<p>#include <stdlib.h></stdlib.h></p>
<p>#include <signal.h></signal.h></p>
<p>#include <unistd.h></unistd.h></p>
<p>volatile int done = 0;</p>
<p>void handler (int sig)<br>{<br>  const char *str = “handled…n”;<br>  write (1, str, strlen(str));<br>  done = 1;<br>}</p>
<p>void child(void)<br>{<br>  int i;<br>  for (i = 0; i &lt; 3; i++){<br>    kill(getppid(), SIGRTMIN);<br>    printf(“child – BANG!n”);<br>  }<br>  exit (0);<br>}</p>
<p>int main (int argc, char *argv[])<br>{<br>  signal (SIGRTMIN, handler);<br>  sigset_t newset, oldset;</p>
<p>  sigfillset(&amp;newset);<br>  sigprocmask(SIG_BLOCK, &amp;newset, &amp;oldset);</p>
<p>  pid_t pid = fork();<br>  if (pid == 0)<br>  child();</p>
<p>  printf(“parent sleeping n”);</p>
<p>  int r = sleep(3);</p>
<p>  printf(“woke up! r=%dn”, r);</p>
<p>  sigprocmask(SIG_SETMASK, &amp;oldset, NULL);</p>
<p>  while (!done){<br>  };</p>
<p>  printf(“exitingn”);<br>  exit(0);<br>}</p>
<p>编译源程序:<br>gcc test.c -o test</p>
<p>执行程序test,这时子程序发送了三次SIGRTMIN信号,父程序在过3秒后,接收并处理该信号.<br>./test<br>parent sleeping<br>child – BANG!<br>child – BANG!<br>child – BANG!<br>woke up! r=0<br>handled…<br>handled…<br>handled…<br>exiting</p>
<p>注意:这里有采用的是发送实时信号(SIGRTMIN),如:kill(getppid(), SIGRTMIN);<br>如果不是实时信号,则只能接收一次.</p>
<p>如果我们将pending signals值改为2,这里将只能保证挂起两个信号,第三个信号将被忽略.如下:<br>ulimit -i 2<br>./test<br>parent sleeping<br>child – BANG!<br>child – BANG!<br>child – BANG!<br>woke up! r=0<br>handled…<br>handled…<br>exiting</p>
<p>六)可以创建使用POSIX消息队列的最大值,单位为bytes.(POSIX message queues)</p>
<p>我们用下面的程序对POSIX消息队列的限制进行测试,如下:</p>
<p>#include <stdio.h></stdio.h></p>
<p>#include <string.h></string.h></p>
<p>#include <stdlib.h></stdlib.h></p>
<p>#include <unistd.h></unistd.h></p>
<p>#include <mqueue.h></mqueue.h></p>
<p>#include <sys stat.h=""></sys></p>
<p>#include <sys wait.h=""></sys></p>
<p>struct message{<br> char mtext[128];<br>};</p>
<p>int send_msg(int qid, int pri, const char text[])<br>{<br> int r = mq_send(qid, text, strlen(text) + 1,pri);<br> if (r == -1){<br>  perror(“mq_send”);<br> }<br> return r;<br>}</p>
<p>void producer(mqd_t qid)<br>{<br> send_msg(qid, 1, “This is my first message.”);<br> send_msg(qid, 1, “This is my second message.”);</p>
<p> send_msg(qid, 3, “No more messages.”);<br>}</p>
<p>void consumer(mqd_t qid)<br>{<br> struct mq_attr mattr;<br> do{<br>  u_int pri;<br>  struct message msg;<br>  ssize_t len;</p>
<p>  len = mq_receive(qid, (char *)&amp;msg, sizeof(msg), &amp;pri);<br>  if (len == -1){<br>   perror(“mq_receive”);<br>   break;<br>  }<br>  printf(“got pri %d ‘%s’ len=%dn”, pri, msg.mtext, len);</p>
<p>  int r = mq_getattr(qid, &amp;mattr);<br>  if (r == -1){<br>   perror(“mq_getattr”);<br>   break;<br>  }<br> }while(mattr.mq_curmsgs);<br>}</p>
<p>int<br>main (int argc, char *argv[])<br>{<br> struct mq_attr mattr = {<br>  .mq_maxmsg = 10,<br>  .mq_msgsize = sizeof(struct message)<br> };</p>
<p> mqd_t mqid = mq_open(“/myq”,<br>    O_CREAT|O_RDWR,<br>    S_IREAD|S_IWRITE,<br>    &amp;mattr);<br> if (mqid == (mqd_t) -1){<br>  perror(“mq_open”);<br>  exit (1);<br> }</p>
<p> pid_t pid = fork();<br> if (pid == 0){<br>  producer(mqid);<br>  mq_close(mqid);<br>  exit(0);<br> }<br> else<br> {<br>  int status;<br>  wait(&amp;status);<br>  consumer(mqid);<br>  mq_close(mqid);<br> }<br> mq_unlink(“/myq”);<br> return 0;<br>}</p>
<p>编译:<br>gcc test.c -o test</p>
<p>限制POSIX消息队列的最大值为1000个字节<br>ulimit -q 1000</p>
<p>这里我们执行test程序<br>./test<br>mq_open: Cannot allocate memory</p>
<p>程序报告无法分配内存.</p>
<p>用strace来跟踪test的运行过程,在下面一条语句时报错.<br>mq_open(“myq”, O_RDWR|O_CREAT, 0600, {mq_maxmsg=10, mq_msgsize=128}) = -1 ENOMEM (Cannot allocate memory)</p>
<p>{mq_maxmsg=10, mq_msgsize=128}即128*10=1280个字节,说明已经超过了1000个字节的POSIX消息队列限制.</p>
<p>我们将POSIX消息队列的最大值调整为1360时,程序可以运行.<br>ulimit -q 1360<br>./test<br>got pri 3 ‘No more messages.’ len=18<br>got pri 1 ‘This is my first message.’ len=26<br>got pri 1 ‘This is my second message.’ len=27</p>
<p>七)程序占用CPU的时间,单位是秒(cpu time)</p>
<p>我们用下面的代码对程序占用CPU时间的限制进行测试</p>
<p>源程序如下：</p>
<h1 id="include"><a href="#include" class="headerlink" title="include "></a>include <stdio.h></stdio.h></h1><h1 id="include-1"><a href="#include-1" class="headerlink" title="include "></a>include <math.h></math.h></h1><p>int main (void)</p>
<p>{<br>  double pi=M_PI;<br>  double pisqrt;<br>  long i;</p>
<p>  while(1){<br>    pisqrt=sqrt(pi);<br>  }<br>  return 0;<br>}</p>
<p>编译:<br>gcc test.c -o test -lm</p>
<p>运行程序test,程序会一直循环下去,只有通过CTRL+C中断.<br>./test<br>^C</p>
<p>用ulimit将程序占用CPU的时间改为2秒,再运行程序.<br>ulimit -t 2<br>./test<br>Killed</p>
<p>程序最后被kill掉了.</p>
<p>八)限制程序实时优先级的范围,只针对普通用户.(real-time priority)</p>
<p>我们用下面的代码对程序实时优先级的范围进行测试</p>
<p>源程序如下:</p>
<h1 id="include-2"><a href="#include-2" class="headerlink" title="include "></a>include <stdio.h></stdio.h></h1><p>int main (void)</p>
<p>{<br>  int i;<br>  for (i=0;i&lt;6;i++)<br>  {<br>    printf (“%dn”,i);<br>    sleep(1);<br>  }<br>  return 0;<br>}</p>
<p>编译:<br>gcc test.c -o test</p>
<p>切换到普通用户进行测试<br>su – ckhitler</p>
<p>用实时优先级20运行test程序<br>chrt -f 20 ./test<br>chrt: failed to set pid 0’s policy: Operation not permitted</p>
<p>我们用root将ulimit的实时优先级调整为20.再进行测试.<br>su – root<br>ulimit -r 20</p>
<p>切换到普通用户,用实时优先级20运行程序,可以运行这个程序了.<br>su – ckhitler<br>chrt -r 20 ./test<br>0<br>1<br>2<br>3<br>4<br>5</p>
<p>以实时优先级50运行程序,还是报错,说明ulimit的限制起了作用.<br>chrt -r 50 ./test<br>chrt: failed to set pid 0’s policy: Operation not permitted</p>
<p>九)限制程序可以fork的进程数,只对普通用户有效(max user processes)</p>
<p>我们用下面的代码对程序的fork进程数的范围进行测试</p>
<p>源程序如下:</p>
<p>#include <unistd.h></unistd.h></p>
<p>#include <stdio.h><br>int main(void)<br>{<br>  pid_t pid;<br>  int count=0;<br>  while (count&lt;3){<br>    pid=fork();<br>    count++;<br>    printf(“count= %dn”,count);<br>  }<br>  return 0;<br>}</stdio.h></p>
<p>编译:<br>gcc test.c -o test<br>count= 1<br>count= 2<br>count= 3<br>count= 2<br>count= 3<br>count= 1<br>count= 3<br>count= 2<br>count= 3<br>count= 3<br>count= 3<br>count= 2<br>count= 3<br>count= 3</p>
<p>程序fork的进程数成倍的增加,这里是14个进程的输出.除自身外,其它13个进程都是test程序fork出来的.<br>我们将fork的限定到12,如下:<br>ulimit -u 12<br>再次执行test程序,这里只有12个进程的输出.<br>./test<br>count= 1<br>count= 2<br>count= 3<br>count= 1<br>count= 2<br>count= 3<br>count= 2<br>count= 3<br>count= 3<br>count= 2<br>count= 3<br>count= 3<br>count= 3</p>
<p>十)限制core文件的大小(core file size)</p>
<p>我们用下面的代码对程序生成core的大小进行测试</p>
<p>源代码:</p>
<p>#include <stdio.h></stdio.h></p>
<p>static void sub(void);</p>
<p>int main(void)<br>{<br>     sub();<br>     return 0;<br>}</p>
<p>static void sub(void)<br>{<br>     int <em>p = NULL;<br>     printf(“%d”, </em>p);<br>}</p>
<p>编译:<br>gcc -g test.c -o test</p>
<p>运行程序test,出现段错误.<br>./test<br>Segmentation fault (core dumped)</p>
<p>如果在当前目录下没有core文件,我们应该调整ulimit对core的大小进行限制,如果core文件大小在这里指定为0,将不会产生core文件.<br>这里设定core文件大小为10个blocks.注:一个blocks在这里为1024个字节.</p>
<p>ulimit -c 10<br>再次运行这个程序<br>./test<br>Segmentation fault (core dumped)</p>
<p>查看core文件的大小<br>ls -lh core<br>-rw——- 1 root root 12K 2011-03-08 13:54 core</p>
<p>我们设定10个blocks应该是10*1024也不是10KB,为什么它是12KB呢,因为它的递增是4KB.<br>如果调整到14个blocks，我们将最大产生16KB的core文件.</p>
<p>十一)限制进程使用数据段的大小(data seg size)</p>
<p>一般来说这个限制会影响程序调用brk(系统调用)和sbrk(库函数)<br>调用malloc时，如果发现vm不够了就会用brk去内核申请.</p>
<p>限制可以使用最大为1KB的数据段</p>
<p>ulimit -d 1</p>
<p>用norff打开/etc/passwd文件<br>nroff /etc/passwd<br>Segmentation fault</p>
<p>可以用strace来跟踪程序的运行.<br>strace nroff /etc/passwd</p>
<p>打印出如下的结果,证明程序在分配内存时不够用时,调用brk申请新的内存,而由于ulimit的限制,导致申请失败.<br>munmap(0x7fc2abf00000, 104420)          = 0<br>rt_sigprocmask(SIG_BLOCK, NULL, [], 8)  = 0<br>open(“/dev/tty”, O_RDWR|O_NONBLOCK)     = 3<br>close(3)                                = 0<br>brk(0)                                  = 0xf5b000<br>brk(0xf5c000)                           = 0xf5b000<br>brk(0xf5c000)                           = 0xf5b000<br>brk(0xf5c000)                           = 0xf5b000<br>— SIGSEGV (Segmentation fault) @ 0 (0) —<br>+++ killed by SIGSEGV +++<br>Segmentation fault</p>
<p>我们这里用一个测试程序对data segment的限制进行测试.<br>源程序如下:</p>
<p>#include <stdio.h><br>int main()<br>{</stdio.h></p>
<pre><code>int start,end;
start = sbrk(0);
(char *)malloc(32*1024);
end = sbrk(0);
printf(&quot;hello I used %d vmemoryn&quot;,end – start);
return 0;
</code></pre><p>}</p>
<p>gcc test.c -o test<br> ./test<br>hello I used 0 vmemory</p>
<p>通过ulimit将限制改为170KB<br>再次运行程序<br>./test<br>hello I used 167936 vmemory</p>
<p>十二)限制进程使用堆栈段的大小</p>
<p>我们用ulimit将堆栈段的大小调整为16,即16*1024.<br>ulimit -s 16</p>
<p>再运行命令:<br>ls -l /etc/<br>Segmentation fault (core dumped)</p>
<p>这时用strace跟踪命令的运行过程<br>strace ls -l /etc/</p>
<p>发现它调用getrlimit,这里的限制是16<em>1024,不够程序运行时用到的堆栈.<br>getrlimit(RLIMIT_STACK, {rlim_cur=16</em>1024, rlim_max=16*1024}) = 0</p>
<p>注:在2.6.32系统上ls -l /etc/并不会出现堆栈不够用的情况,这时可以用expect来触发这个问题.</p>
<p>如:<br>expect<br>Tcl_Init failed: out of stack space (infinite loop?)</p>
<p>十三)限制进程使用虚拟内存的大小</p>
<p>我们用ulimit将虚拟内存调整为8192KB<br>ulimit -v 8192</p>
<p>运行ls<br>ls<br>ls: error while loading shared libraries: libc.so.6: failed to map segment from shared object: Cannot allocate memory<br>ls在加载libc.so.6动态库的时候报了错,提示内存不足.</p>
<p>用strace跟踪ls的运行过程,看到下面的输出,说明在做mmap映射出内存时,出现内存不够用.<br>mmap(NULL, 3680296, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = -1 ENOMEM (Cannot allocate memory)<br>close(3)                                = 0<br>writev(2, [{“ls”, 2}, {“: “, 2}, {“error while loading shared libra”…, 36}, {“: “, 2}, {“libc.so.6”, 9}, {“: “, 2}, {“failed to map segment from share”…, 40}, {“: “, 2}, {“Cannot allocate memory”, 22}, {“n”, 1}], 10ls: error while loading shared libraries: libc.so.6: failed to map segment from shared object: Cannot allocate memory</p>
<p>十四)剩下的三种ulimit限制说明(file locks/max memory size/pipe size)</p>
<p>文件锁的限制只在2.4内核之前有用.<br>驻留内存的限制在很多系统里也没有作用.<br>管道的缓存不能改变,只能是8*512(bytes),也就是4096个字节.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/linux的ulimit各种限制之深入分析/" data-id="ciwpxfwi400214zcy39ardm1f" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-如何用十条命令在一分钟内检查Linux服务器性能" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/" class="article-date">
  <time datetime="2016-12-12T09:08:07.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/">如何用十条命令在一分钟内检查Linux服务器性能</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>通过执行以下命令，可以在1分钟内对系统资源使用情况有个大致的了解。</p>
<p>uptime</p>
<p>dmesg | tail</p>
<p>vmstat 1</p>
<p>mpstat -P ALL 1</p>
<p>pidstat 1</p>
<p>iostat -xz 1</p>
<p>free -m</p>
<p>sar -n DEV 1</p>
<p>sar -n TCP,ETCP 1</p>
<p>top</p>
<p>其中一些命令需要安装sysstat包，有一些由procps包提供。这些命令的输出，有助于快速定位性能瓶颈，检查出所有资源（CPU、内存、磁盘IO等）的利用率（utilization）、饱和度（saturation）和错误（error）度量，也就是所谓的USE方法。</p>
<p>下面我们来逐一介绍下这些命令，有关这些命令更多的参数和说明，请参照命令的手册。</p>
<p>uptime<br>$ uptime</p>
<p>23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02</p>
<p>这个命令可以快速查看机器的负载情况。在Linux系统中，这些数据表示等待CPU资源的进程和阻塞在不可中断IO进程（进程状态为D）的数量。这些数据可以让我们对系统资源使用有一个宏观的了解。</p>
<p>命令的输出分别表示1分钟、5分钟、15分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是趋于缓解。如果1分钟平均负载很高，而15分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查CPU资源都消耗在了哪里。反之，如果15分钟平均负载很高，1分钟平均负载较低，则有可能是CPU资源紧张时刻已经过去。</p>
<p>上面例子中的输出，可以看见最近1分钟的平均负载非常高，且远高于最近15分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的vmstat、mpstat等命令进一步排查。</p>
<p>dmesg丨tail<br>$ dmesg | tail</p>
<p>[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0</p>
<p>[…]</p>
<p>[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child</p>
<p>[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB</p>
<p>[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping</p>
<p>request.  Check SNMP counters.</p>
<p>该命令会输出系统日志的最后10行。示例中的输出，可以看见一次内核的oom kill和一次TCP丢包。这些日志可以帮助排查性能问题。千万不要忘了这一步。</p>
<p>vmstat 1<br>$ vmstat 1</p>
<p>procs ———memory———- —swap– —–io—- -system– ——cpu—–</p>
<p> r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</p>
<p>34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0</p>
<p>32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0</p>
<p>32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0</p>
<p>32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0</p>
<p>32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0</p>
<p>^C</p>
<p>vmstat(8) 命令，每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数1，表示每秒输出一次统计信息，表头提示了每一列的含义，这几介绍一些和性能调优相关的列：</p>
<p>r：等待在CPU资源的进程数。这个数据比平均负载更加能够体现CPU负载情况，数据中不包含等待IO的进程。如果这个数值大于机器CPU核数，那么机器的CPU资源已经饱和。</p>
<p>free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的free命令，可以更详细的了解系统内存的使用情况。</p>
<p>si，so：交换区写入和读取的数量。如果这个数据不为0，说明系统已经在使用交换区（swap），机器物理内存已经不足。</p>
<p>us, sy, id, wa, st：这些都代表了CPU时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。</p>
<p>上述这些CPU时间，可以让我们很快了解CPU是否出于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU出于忙于执行指令。如果IO等待时间很长，那么系统的瓶颈可能在磁盘IO。</p>
<p>示例命令的输出可以看见，大量CPU时间消耗在用户态，也就是用户应用程序消耗了CPU时间。这不一定是性能问题，需要结合r队列，一起分析。</p>
<p>mpstat-P ALL 1<br>$ mpstat -P ALL 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86<em>64</em> (32 CPU)</p>
<p>07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle</p>
<p>07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78</p>
<p>07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99</p>
<p>07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00</p>
<p>07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00</p>
<p>07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03</p>
<p>[…]</p>
<p>该命令可以显示每个CPU的占用情况，如果有一个CPU占用率特别高，那么有可能是一个单线程应用程序引起的。</p>
<p>pidstat 1<br>$ pidstat 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86<em>64</em>    (32 CPU)</p>
<p>07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</p>
<p>07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0</p>
<p>07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave</p>
<p>07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java</p>
<p>07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java</p>
<p>07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java</p>
<p>07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat</p>
<p>07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</p>
<p>07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave</p>
<p>07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java</p>
<p>07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass</p>
<p>07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat</p>
<p>^C</p>
<p>pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。</p>
<p>iostat-xz 1<br>$ iostat -xz 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86<em>64</em> (32 CPU)</p>
<p>avg-cpu:  %user   %nice %system %iowait  %steal   %idle</p>
<pre><code>73.96    0.00    3.73    0.03    0.06   22.21
</code></pre><p>Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</p>
<p>xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09</p>
<p>xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25</p>
<p>xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26</p>
<p>dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04</p>
<p>dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00</p>
<p>dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03</p>
<p>[…]</p>
<p>^C</p>
<p>iostat命令主要用于查看机器磁盘IO情况。该命令输出的列，主要含义是：</p>
<p>r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。</p>
<p>await：IO操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括IO等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。</p>
<p>avgqu-sz：向设备发出的请求平均数量。如果这个数值大于1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。</p>
<p>%util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过60，可能会影响IO性能（可以参照IO操作平均等待时间）。如果到达100%，说明硬件设备已经饱和。</p>
<p>如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使IO性能不理想，也不一定意味这应用程序性能会不好，可以利用诸如预读取、写缓存等策略提升应用性能。</p>
<p>free -m<br>$ free -m</p>
<pre><code>total       used       free     shared    buffers     cached
</code></pre><p>Mem:        245998      24545     221453         83         59        541</p>
<p>-/+ buffers/cache:      23944     222053</p>
<p>Swap:            0          0          0</p>
<p>free命令可以查看系统内存的使用情况，-m参数表示按照兆字节展示。最后两列分别表示用于IO缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行-/+ buffers/cache，看上去缓存占用了大量内存空间。</p>
<p>这是Linux系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。</p>
<p>如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加IO开销（可以在iostat命令中提现），降低系统性能。</p>
<p>sar -n DEV 1<br>$ sar -n DEV 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86<em>64</em>    (32 CPU)</p>
<p>12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</p>
<p>12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</p>
<p>12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil</p>
<p>12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00</p>
<p>12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00</p>
<p>12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</p>
<p>^C</p>
<p>sar命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0网卡设备，吞吐率大概在22 Mbytes/s，既176 Mbits/sec，没有达到1Gbit/sec的硬件上限。</p>
<p>sar -n TCP,ETCP 1<br>$ sar -n TCP,ETCP 1</p>
<p>Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86<em>64</em>    (32 CPU)</p>
<p>12:17:19 AM  active/s passive/s    iseg/s    oseg/s</p>
<p>12:17:20 AM      1.00      0.00  10233.00  18846.00</p>
<p>12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</p>
<p>12:17:20 AM      0.00      0.00      0.00      0.00      0.00</p>
<p>12:17:20 AM  active/s passive/s    iseg/s    oseg/s</p>
<p>12:17:21 AM      1.00      0.00   8359.00   6039.00</p>
<p>12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</p>
<p>12:17:21 AM      0.00      0.00      0.00      0.00      0.00</p>
<p>^C</p>
<p>sar命令在这里用于查看TCP连接状态，其中包括：</p>
<p>active/s：每秒本地发起的TCP连接数，既通过connect调用创建的TCP连接；</p>
<p>passive/s：每秒远程发起的TCP连接数，即通过accept调用创建的TCP连接；</p>
<p>retrans/s：每秒TCP重传数量；</p>
<p>TCP连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。</p>
<p>top<br>$ top</p>
<p>top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92</p>
<p>Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie</p>
<p>%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st</p>
<p>KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers</p>
<p>KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem</p>
<p>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</p>
<p> 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java</p>
<p>  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave</p>
<p> 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top</p>
<p>  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java</p>
<p>  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init</p>
<pre><code>2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd

3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0

5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H

6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0

8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched
</code></pre><p>top命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统CPU使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU占用率最高的进程等。</p>
<p>但是，top命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停top命令刷新，来记录和比对数据。</p>
<p>总结</p>
<p>排查Linux服务器性能问题还有很多工具，上面介绍的一些命令，可以帮助我们快速的定位问题。例如前面的示例输出，多个证据证明有JAVA进程占用了大量CPU资源，之后的性能调优就可以针对应用程序进行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/如何用十条命令在一分钟内检查Linux服务器性能/" data-id="ciwpxfwj1003b4zcyee42t9le" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据工程师常用的-Shell-命令" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/数据工程师常用的-Shell-命令/" class="article-date">
  <time datetime="2016-12-12T09:04:24.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/数据工程师常用的-Shell-命令/">数据工程师常用的 Shell 命令</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Linux以其强大的命令行称霸江湖，Shell命令是数据极客的必修兵器。探索性数据分析，在需求和数据都不太明确的环境下，使用各种命令进行一次探索与挖掘。从基础的文件查看到简单的统计，再到一些常用的探索性分析命令，其目的都只是为了更好的做数据分析与挖掘而已。<br>01 Shell命令行</p>
<p>对于经常和数据打交道的人来说，数据工程师应该也是常常和Linux打交道。Linux以其强大的命令行称霸江湖，因此，Shell命令也是数据极客的必修兵器。</p>
<p>利用Linux命令行的几个命令，就可以完成一些简单的统计分析工作，比如利用wc命令统计文件行，单词数，字符数，利用sort排序和去重，再结合uniq可以进行词频统计。比如：<br>$ cat file.txt<br>yunjie<br>yunjie-talk<br>yunjie-yun<br>yunjie<br>yunjie-shuo<br>$ sort file.txt | uniq -c | sort -nr | head -5<br>   2 yunjie<br>   1 yunjie-shuo<br>   1 yunjie-talk<br>   1 yunjie-yun</p>
<p>先用cat命令，了解一下文件的大概格式与内容，发现每行为一个单词。现在需要统计这些单词出现的频率，以及显示出现次数最多的5个单词。</p>
<p>先对文件进行排序，这样相同的单词在紧挨着的行，再后uniq -c 命令，统计不同的单词及各个单词出现的次数。这样得到的结果就是次数后面紧接着单词，然后使用sort -nr对次数进行排序，并逆序显示，最后head命令显示结果的前5行。</p>
<p>非常简单的一种方式，读取文件，排序，统计，再对统计结果进行逆序，最后只显示前几个结果。</p>
<p>类似于sql语句：</p>
<p>select word,count(1) cnt<br>from file<br>group by word<br>order by cnt desc<br>limit 5;</p>
<p>如果对sql语句熟悉的话，上面的形式应该更容易理解。虽然实现的思想和方式非常简单，但在实际的探索性数据分析中使用却非常频繁。</p>
<p>02 探索性分析</p>
<p>比如在日志分析中，有时并没有非常明确的目标，或者即使有明确的目标，通常各种数据也并没有明确的定义。比如，别人丢给你一个压缩文件，说想分析一下里面有哪些是异常的访问请求。任务描述就是这样，没有更明确的了。</p>
<p>拿到日志文件和这样的分析任务，就需要进行各种可能的探索性分析。先看一下文件的格式，是否压缩过，使用gzip压缩还是tar压缩。解压后，需要先大概了解一下，文件是什么样的格式。对于网络请求的日志文件，是一行一个请求和响应，还是多行一个请求和响应。查看文件有多少行，查看文件占用空间大小。如果解压后包含多个目录或者文件，同样的一个命令，更能发挥强大效果。此时，通常需要如下命令：</p>
<p>gzip/tar：压缩/解压<br>cat/zcat：文件查看<br>less/more：文件查看，支持gz压缩格式直接查看<br>head/tail：查看文件前/后10行<br>wc：统计行数、单词数、字符数<br>du -h -c -s：查看空间占用</p>
<p>上面有一个比较有趣的命令组，less和more，这两个都可以分页查看文件。最开始有的more命令，好像是当时more不支持向后翻页。于是一帮人就在此基础上进行了改进，直接叫less，和more同样的功能只是更强大些。因此，也发展出了“less is more”的哲学，“少即是多”，而且少比多更好。这种思想，在产品设计与代码优化中都有体现。</p>
<p>了解文件的大概信息后，可能需要提取一行中某个字段的内容，或者需要搜索某些行出来，或者需要对某些字符或者行进行一定的修改操作，或者需要在众多的目录和文件中找出某此天的日志（甚至找到后需要对这些天的日志进行统一处理），此时下面这些命令可以帮你：</p>
<p>awk：命令行下的数据库操作工具<br>join/cut/paste：关联文件/切分字段/合并文件<br>fgrep/grep/egrep：全局正则表达式查找<br>find：查找文件，并且对查找结果批量化执行任务<br>sed：流编辑器，批量修改、替换文件<br>split：对大文件进行切分处理，按多少行一个文件，或者多少字节一个文件<br>rename：批量重命名(Ubuntu上带的perl脚本，其它系统需要安装)，使用-n命令进行测试</p>
<p>如：</p>
<h1 id="解压缩日志"><a href="#解压缩日志" class="headerlink" title="解压缩日志"></a>解压缩日志</h1><p>$ gzip -d a.gz<br>$ tar zcvf/jcvf one.tar.bz2 one</p>
<h1 id="直接查看压缩日志"><a href="#直接查看压缩日志" class="headerlink" title="直接查看压缩日志"></a>直接查看压缩日志</h1><p>$ less a.gz  </p>
<h1 id="无需先解压"><a href="#无需先解压" class="headerlink" title="无需先解压"></a>无需先解压</h1><p>另外，以z开头的几个命令可以简单处理gzip压缩文件, 如zcat：直接打印压缩文件，还有zgrep/zfgrep/zegrep，在压缩文件中直接查找。</p>
<h1 id="查询字符串，并显示匹配行的前3行和后3行内容"><a href="#查询字符串，并显示匹配行的前3行和后3行内容" class="headerlink" title="查询字符串，并显示匹配行的前3行和后3行内容"></a>查询字符串，并显示匹配行的前3行和后3行内容</h1><p>fgrep ‘yunjie-talk’ -A 3 -B 3 log.txt</p>
<h1 id="在当前目前-及子目录-下，所有的log文件中搜索字符串hacked-by"><a href="#在当前目前-及子目录-下，所有的log文件中搜索字符串hacked-by" class="headerlink" title="在当前目前(及子目录)下，所有的log文件中搜索字符串hacked by:"></a>在当前目前(及子目录)下，所有的log文件中搜索字符串hacked by:</h1><p>$ find . -name “*.log” | xargs fgrep “hacked by”</p>
<p>fgrep, grep, egrep的一些区别：</p>
<p>fgrep按字符串的本来意思完全匹配，里面的正则元字符当成普通字符解析， 如： fgrep “1.2.3.4″ 则只匹配ip地址： 1.2.3.4, 其中的.不会匹配任意字符。fgrep当然会比grep快多了。写起来又简单，不用转义。<br>grep只使用普通的一些正则，egrep或者grep -E使用扩展的正则，如</p>
<p>egrep “one|two”, 匹配one或者two<br>grep -E -v “.jpg|.png|.gif|.css|.js” log.txt |wc -l</p>
<p>查找所有来自日本的ip的请求，先把所有来源ip取出来，去重，找出日本的ip，放入文件japan.ip，再使用命令：</p>
<p>$ cat log.gz | gzip -d | fgrep -f japan.ip &gt; japan.log</p>
<p>对hive中导出的文件，替换01</p>
<p>cat 0000* | sed ‘s/x1/ /g’ &gt; log.txt<br>03 其它常用命令</p>
<p>如果文件编码是从windows上传过来的gb2312编码，需要处理成utf8的编码，或者某个日志被黑客后来修改过了，需要和原来的备份数据进行对比，这些工作都是需要数据工程师自己能熟悉的掌握。</p>
<p>假如日志文件是最近一年的请求日志，那么可能是按天或者按小时进行单独存放，此时如果只需要提取某些天（比如周末）的数据，很可能需要处理时间。</p>
<p>因此，下面的一些命令或者工具就很有用了：</p>
<p>date：命令行时间操作函数<br>sort/uniq：排序、去重、统计<br>comm：对两个排序文件进行按行比较（共同行、只出现在左边文件、只出现在右边文件）<br>diff：逐字符比较文件的异同，配合cdiff，类似于github的显示效果<br>curl/w3m/httpie：命令行下进行网络请求<br>iconv：文件编码转换，如：iconv -f GB2312 -t UTF8 1.csv &gt; 2.csv<br>seq：产生连续的序列，配合for循环使用</p>
<p>输出今天/昨天的日期字符串</p>
<p>$ date -d today +%Y%m%d<br>20160320<br>$ date -d yesterday +%Y%m%d<br>20160319</p>
<p>对unix秒的处理</p>
<h1 id="当前的时间"><a href="#当前的时间" class="headerlink" title="当前的时间"></a>当前的时间</h1><p>$ date +%s<br>1458484275<br>$date -d @1458484275<br>Sun Mar 20 22:31:15 CST 2016</p>
<p>两个文件a.txt, b.txt求只出现在a.txt中的数据：</p>
<h1 id="排序两个文件"><a href="#排序两个文件" class="headerlink" title="排序两个文件"></a>排序两个文件</h1><p>$ sort a.txt &gt; a.txt.sort<br>$ sort b.txt &gt; b.txt.sort</p>
<h1 id="求只出现在c-sh中的内容"><a href="#求只出现在c-sh中的内容" class="headerlink" title="求只出现在c.sh中的内容"></a>求只出现在c.sh中的内容</h1><p>$ comm -2 -3 a.txt.sort b.txt.sort</p>
<p>04 批量操作</p>
<p>对上面的文件进行了一番探索分析后，可能已经有一定的线索或者眉目了，需要更进一步的处理大量的文件或者字段了。此时的步骤也许是一个消耗时间的过程，也许是一个需要看缘分的过程。总之，可能需要综合上面的一些命令，并且对大量的日志进行处理。</p>
<p>这也是体现Shell更强大的一面——批量化的功能了。命令比图形界面的最大优势就是，只需熟悉了，就很容易实现批量化操作，将这些批量化的命令组合成一个文件，于是便产生了脚本。</p>
<p>批量化命令或者脚本，熟悉几个常用的流程控制，就能发挥出强大的性能：</p>
<p>if条件判断：</p>
<p>if [ -d ${base_d} ];<br>    then mkdir -p ${base_d};<br>fi</p>
<p>while循环：</p>
<p>while<br>do<br>    do_something;<br>done</p>
<p>for循环（用得很多）：</p>
<p>for x in *.log.gz;<br>do<br>    gzip -d ${x};<br>done</p>
<p>这几个条件判断与循环，也可以直接在命令行下使用，区别是多加几个分号隔开即可。</p>
<p>另外，执行长时间的任务，最好直接用nohup来操作。</p>
<p>生成过去8天的日期序列：</p>
<p>$for num in <code>seq 8 -1 1</code>;do dd=<code>date --date=&quot;${num} day ago&quot; +%Y%m%d</code>;echo ${dd};done<br>20160312<br>20160313<br>20160314<br>20160315<br>20160316<br>20160317<br>20160318<br>20160319</p>
<p>有目录和文件如下：</p>
<p>20160320 目录<br>    10.1.0.1_20160320<em>.log.gz   目录<br>        201603200000.log.gz          文件<br>        201603200010.log.gz          文件<br>    10.1.0.2_20160320</em>.log.gz   目录<br>        201603200000.log.gz         文件<br>        201603200010.log.gz         文件</p>
<p>需求：去掉目录中的*.log.gz，这样很容易让人误解为文件。 rename -n为测试，rename使用和sed相同的语法。</p>
<p>$ for d in 201603??;do echo ${d}; cd ${d}; rename -n ‘s/<em>.log.gz//‘ </em>.log.gz ; cd ..;done</p>
<p>测试完成后，使用rename不加-n为真正执行重命名操作。</p>
<p>05 结尾</p>
<p>这儿只是简单列举了一些数据分析或者数据处理相关的命令，只能算是Linux的Shell那博大精深的命令中的冰山一角。</p>
<p>但如果能把这些相关的命令融会贯通，并且能实际使用的话，也算是在数据极客之路上多走了一步。</p>
<p>从基础的文件查看到简单的统计，再到一些常用的探索性分析命令，其目的都只是为了更好的做数据分析与挖掘而已。能综合这些命令，并组合起来使用，将命令存放到文件，即产生了Shell脚本。Shell脚本本身也是一门强大的学问了，其中各个命令还有每个命令支持的参数，值得慢慢研究。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/数据工程师常用的-Shell-命令/" data-id="ciwpxfwjb003m4zcymnmdj0ue" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-awk" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/awk/" class="article-date">
  <time datetime="2016-12-12T08:21:51.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/awk/">awk</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div></pre></td><td class="code"><pre><div class="line">awk 数据流处理工具</div><div class="line"></div><div class="line">awk脚本结构</div><div class="line">awk &apos; BEGIN&#123; statements &#125; statements2 END&#123; statements &#125; &apos;</div><div class="line"></div><div class="line">工作方式</div><div class="line">1.执行begin中语句块；</div><div class="line">2.从文件或stdin中读入一行，然后执行statements2，重复这个过程，直到文件全部被读取完毕；</div><div class="line">3.执行end语句块；</div><div class="line"></div><div class="line">print 打印当前行</div><div class="line"></div><div class="line">使用不带参数的print时，会打印当前行;</div><div class="line"></div><div class="line">  echo -e &quot;line1\nline2&quot; | awk &apos;BEGIN&#123;print &quot;start&quot;&#125; &#123;print &#125; END&#123; print &quot;End&quot; &#125;&apos;</div><div class="line"></div><div class="line">print 以逗号分割时，参数以空格定界;</div><div class="line"></div><div class="line">echo | awk &apos; &#123;var1 = &quot;v1&quot; ; var2 = &quot;V2&quot;; var3=&quot;v3&quot;; \</div><div class="line">print var1, var2 , var3; &#125;&apos;</div><div class="line">$&gt;v1 V2 v3</div><div class="line"></div><div class="line">使用-拼接符的方式（&quot;&quot;作为拼接符）;</div><div class="line"></div><div class="line">echo | awk &apos; &#123;var1 = &quot;v1&quot; ; var2 = &quot;V2&quot;; var3=&quot;v3&quot;; \</div><div class="line">print var1&quot;-&quot;var2&quot;-&quot;var3; &#125;&apos;</div><div class="line">$&gt;v1-V2-v3</div><div class="line"></div><div class="line">特殊变量： NR NF $0 $1 $2</div><div class="line"></div><div class="line">NR:表示记录数量，在执行过程中对应当前行号；</div><div class="line">NF:表示字段数量，在执行过程总对应当前行的字段数；</div><div class="line">$0:这个变量包含执行过程中当前行的文本内容；</div><div class="line">$1:第一个字段的文本内容；</div><div class="line">$2:第二个字段的文本内容；</div><div class="line"></div><div class="line">echo -e &quot;line1 f2 f3\n line2 \n line 3&quot; | awk &apos;&#123;print NR&quot;:&quot;$0&quot;-&quot;$1&quot;-&quot;$2&#125;&apos;</div><div class="line"></div><div class="line">打印每一行的第二和第三个字段：</div><div class="line">  awk &apos;&#123;print $2, $3&#125;&apos; file</div><div class="line"></div><div class="line">统计文件的行数：</div><div class="line">  awk &apos; END &#123;print NR&#125;&apos; file</div><div class="line"></div><div class="line">累加每一行的第一个字段：</div><div class="line">  echo -e &quot;1\n 2\n 3\n 4\n&quot; | awk &apos;BEGIN&#123;num = 0 ;</div><div class="line">  print &quot;begin&quot;;&#125; &#123;sum += $1;&#125; END &#123;print &quot;==&quot;; print sum &#125;&apos;</div><div class="line"></div><div class="line">传递外部变量</div><div class="line"></div><div class="line">var=1000</div><div class="line">echo | awk &apos;&#123;print vara&#125;&apos; vara=$var #  输入来自stdin</div><div class="line">awk &apos;&#123;print vara&#125;&apos; vara=$var file # 输入来自文件</div><div class="line"></div><div class="line">用样式对awk处理的行进行过滤</div><div class="line"></div><div class="line">awk &apos;NR &lt; 5&apos; #行号小于5</div><div class="line">awk &apos;NR==1,NR==4 &#123;print&#125;&apos; file #行号等于1和4的打印出来</div><div class="line">awk &apos;/linux/&apos; #包含linux文本的行（可以用正则表达式来指定，超级强大）</div><div class="line">awk &apos;!/linux/&apos; #不包含linux文本的行</div><div class="line"></div><div class="line">设置定界符</div><div class="line"></div><div class="line">使用-F来设置定界符（默认为空格）</div><div class="line">awk -F: &apos;&#123;print $NF&#125;&apos; /etc/passwd</div><div class="line"></div><div class="line">读取命令输出</div><div class="line"></div><div class="line">使用getline，将外部shell命令的输出读入到变量cmdout中；</div><div class="line"></div><div class="line">echo | awk &apos;&#123;&quot;grep root /etc/passwd&quot; | getline cmdout; print cmdout &#125;&apos;</div><div class="line"></div><div class="line">在awk中使用循环</div><div class="line"></div><div class="line">for(i=0;i&lt;10;i++)&#123;print $i;&#125;</div><div class="line">for(i in array)&#123;print array[i];&#125;</div><div class="line"></div><div class="line">eg:</div><div class="line">以逆序的形式打印行：(tac命令的实现）</div><div class="line"></div><div class="line">seq 9| \</div><div class="line">awk &apos;&#123;lifo[NR] = $0; lno=NR&#125; \</div><div class="line">END&#123; for(;lno&gt;-1;lno--)&#123;print lifo[lno];&#125;</div><div class="line">&#125; &apos;</div><div class="line"></div><div class="line">awk实现head、tail命令</div><div class="line"></div><div class="line">head:</div><div class="line">  awk &apos;NR&lt;=10&#123;print&#125;&apos; filename</div><div class="line"></div><div class="line">tail:</div><div class="line">  awk &apos;&#123;buffer[NR%10] = $0;&#125; END&#123;for(i=0;i&lt;11;i++)&#123; \</div><div class="line">  print buffer[i %10]&#125; &#125; &apos; filename</div><div class="line"></div><div class="line">打印指定列</div><div class="line"></div><div class="line">awk方式实现：</div><div class="line">  ls -lrt | awk &apos;&#123;print $6&#125;&apos;</div><div class="line"></div><div class="line">cut方式实现</div><div class="line">  ls -lrt | cut -f6</div><div class="line"></div><div class="line">打印指定文本区域</div><div class="line"></div><div class="line">确定行号</div><div class="line">  seq 100| awk &apos;NR==4,NR==6&#123;print&#125;&apos;</div><div class="line"></div><div class="line">确定文本</div><div class="line">打印处于start_pattern 和end_pattern之间的文本；</div><div class="line">  awk &apos;/start_pattern/, /end_pattern/&apos; filename</div><div class="line"></div><div class="line">eg:</div><div class="line">seq 100 | awk &apos;/13/,/15/&apos;</div><div class="line">cat /etc/passwd| awk &apos;/mai.*mail/,/news.*news/&apos;</div><div class="line"></div><div class="line">awk常用内建函数</div><div class="line"></div><div class="line">index(string,search_string):返回search_string在string中出现的位置</div><div class="line">sub(regex,replacement_str,string):将正则匹配到的第一处内容替换为replacement_str;</div><div class="line">match(regex,string):检查正则表达式是否能够匹配字符串；</div><div class="line">length(string)：返回字符串长度</div><div class="line"></div><div class="line">echo | awk &apos;&#123;&quot;grep root /etc/passwd&quot; | getline cmdout; print length(cmdout) &#125;&apos;</div><div class="line"></div><div class="line">printf 类似c语言中的printf，对输出进行格式化</div><div class="line">eg：</div><div class="line"></div><div class="line">seq 10 | awk &apos;&#123;printf &quot;-&gt;%4s\n&quot;, $1&#125;&apos;</div><div class="line"></div><div class="line">迭代文件中的行、单词和字符</div><div class="line"></div><div class="line">1. 迭代文件中的每一行</div><div class="line"></div><div class="line">while 循环法</div><div class="line"></div><div class="line">while read line;</div><div class="line">do</div><div class="line">echo $line;</div><div class="line">done &lt; file.txt</div><div class="line"></div><div class="line">改成子shell:</div><div class="line">cat file.txt | (while read line;do echo $line;done)</div><div class="line"></div><div class="line">awk法：</div><div class="line">cat file.txt| awk &apos;&#123;print&#125;&apos;</div><div class="line"></div><div class="line">2.迭代一行中的每一个单词</div><div class="line"></div><div class="line">for word in $line;</div><div class="line">do</div><div class="line">echo $word;</div><div class="line">done</div><div class="line"></div><div class="line">3. 迭代每一个字符</div><div class="line"></div><div class="line">$&#123;string:start_pos:num_of_chars&#125;：从字符串中提取一个字符；(bash文本切片）</div><div class="line">$&#123;#word&#125;:返回变量word的长度</div><div class="line"></div><div class="line">for((i=0;i&lt;$&#123;#word&#125;;i++))</div><div class="line">do</div><div class="line">echo $&#123;word:i:1);</div><div class="line">done</div><div class="line"></div><div class="line">从格式化输出里提取一列(我最常使用的awk技巧)</div><div class="line"></div><div class="line">我几乎天天都会使用它。真的。经常会有一些输出，我只需要其中的第二列，或第三列，下面这个命令就能做到这些：</div><div class="line">#Sample output of git status -s command:</div><div class="line"></div><div class="line">$ git status -s</div><div class="line"></div><div class="line">M .bashrc</div><div class="line">?? .vim/bundle/extempore/</div><div class="line"></div><div class="line"># Remove status code from git status and just get the file names</div><div class="line">$ git status -s | awk &apos;&#123;print $2&#125;&apos;</div><div class="line"></div><div class="line">.bashrc</div><div class="line">.vim/bundle/extempore/</div><div class="line">为什么不写个函数，让我们随时都可以用呢？</div><div class="line">function col &#123;</div><div class="line">awk -v col=$1 &apos;&#123;print $col&#125;&apos;</div><div class="line">&#125;</div><div class="line">这使得提取列非常容易，比如，你不想要第一列？简单：</div><div class="line">$ git status -s | col 2</div><div class="line"></div><div class="line">.bashrc</div><div class="line">.vim/bundle/extempore/</div></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/awk/" data-id="ciwpxfwhw001u4zcyavkfd3ol" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-sed" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/sed/" class="article-date">
  <time datetime="2016-12-12T08:09:38.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/sed/">sed</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>sed 文本替换利器</p>
<p>用命令行往文件的顶部添加文字</p>
<p>每次我都会重新寻找这个命令的写法。下面就是如何使用sed往一个文件顶部添加一行的方法：<br>sed -i ‘1s/^/line to insert\n/‘ path/to/file/you/want/to/change.txt</p>
<p>首处替换<br>  seg ‘s/text/replace_text/‘ file   //替换每一行的第一处匹配的text</p>
<p>全局替换<br>   seg ‘s/text/replace_text/g’ file</p>
<p>默认替换后，输出替换后的内容，如果需要直接替换原文件,使用-i：<br>  seg -i ‘s/text/repalce_text/g’ file</p>
<p>移除空白行：<br>  sed ‘/^$/d’ file</p>
<p>变量转换<br>已匹配的字符串通过标记&amp;来引用.<br>echo this is en example | seg ‘s/\w+/[&amp;]/g’<br>$&gt;[this]  [is] [en] [example]</p>
<p>子串匹配标记<br>第一个匹配的括号内容使用标记 \1 来引用<br>  sed ‘s/hello([0-9])/\1/‘</p>
<p>双引号求值<br>sed通常用单引号来引用；也可使用双引号，使用双引号后，双引号会对表达式求值：<br>  sed ‘s/$var/HLLOE/‘</p>
<p>当使用双引号时，我们可以在sed样式和替换字符串中指定变量；<br>eg:<br>p=patten<br>r=replaced<br>echo “line con a patten” | sed “s/$p/$r/g”<br>$&gt;line con a replaced</p>
<p>其它示例<br>字符串插入字符：将文本中每行内容（PEKSHA） 转换为 PEK/SHA<br>  sed ‘s/^.{3}/&amp;\//g’ file</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/sed/" data-id="ciwpxfwia00274zcyb3cs4mkp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-umount" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/umount/" class="article-date">
  <time datetime="2016-12-12T08:09:03.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/umount/">umount</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>原来umount 还有一个-l选项，作用是当需卸载文件系统的引用不繁忙时直接卸载：<br>umount -l directoryname</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/umount/" data-id="ciwpxfwif002g4zcy2quapraq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-uniq" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/12/uniq/" class="article-date">
  <time datetime="2016-12-12T08:07:25.000Z" itemprop="datePublished">2016-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/12/uniq/">uniq</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>uniq 消除重复行</p>
<p>消除重复行<br>  sort unsort.txt | uniq</p>
<p>统计各行在文件中出现的次数<br>  sort unsort.txt | uniq -c</p>
<p>找出重复行<br>  sort unsort.txt | uniq -d</p>
<p>可指定每行中需要比较的重复内容：-s 开始位置 -w 比较字符数</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/12/12/uniq/" data-id="ciwpxfwih002h4zcyxji4yn8l" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/10/">&laquo; __('prev')</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/12/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/12/15/ubuntu-12-04网络设置/">ubuntu 12.04网络设置</a>
          </li>
        
          <li>
            <a href="/2016/12/15/Ubuntu-用vsftpd-配置FTP服务器/">Ubuntu 用vsftpd 配置FTP服务器</a>
          </li>
        
          <li>
            <a href="/2016/12/15/ubuntu下允许root用户ssh远程登录/">ubuntu下允许root用户ssh远程登录</a>
          </li>
        
          <li>
            <a href="/2016/12/15/ubuntu用root登录后没法使用chromium/">ubuntu用root登录后没法使用chromium</a>
          </li>
        
          <li>
            <a href="/2016/12/15/vsftpd安装以及配置FTP虚拟用户实践/">vsftpd安装以及配置FTP虚拟用户实践</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 JinYan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>